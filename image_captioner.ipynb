{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQnm12NRwzB1"
   },
   "source": [
    "## Image Caption Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1LDt60jwzB7",
    "outputId": "6002c02f-a2b4-4a91-817c-64135274d831"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pycocoevalcap\n",
    "from ultralytics import YOLO\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "from collections import Counter\n",
    "# for metrics, COCO API metrics is used\n",
    "import json\n",
    "from pycocoevalcap import bleu, meteor, rouge, spice\n",
    "#from pycocoevalcap.evalcap import COCOEvalCap\n",
    "\n",
    "# Load YOLOv5 for feature extraction\n",
    "import torch.hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-uX4UDUw3Nt"
   },
   "outputs": [],
   "source": [
    "# setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIzkhVwfwzB_",
    "outputId": "4e87cf17-ad05-49c5-b54c-b60f7fc59f13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/pokepe/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-12-17 Python-3.10.15 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained YOLOv5 model from Torch Hub\n",
    "yolov5 = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pdEPXli8wzCA"
   },
   "outputs": [],
   "source": [
    "# Define transformations for image preprocessing\n",
    "# !!!!! NOTE chatgpt says this is not needed in yolov5\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary, will be used later.\n",
    "vocabulary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W_cYJu5QwzCB"
   },
   "outputs": [],
   "source": [
    "# \"annotations\": [{\"image_id\": 179765,\"id\": 38,\"caption\": \"A black Honda motorcycle parked in front of a garage.\"},...}\n",
    "class CocoDataset(Dataset): # <start> cat sat on the mat <end> -> {0 32 24 34 3 3 1 }\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")  # Tokenizer from torchtext\n",
    "        self.annotations = self.coco_data['annotations']\n",
    "        # Build vocabulary\n",
    "        self.vocab = self.build_vocab()\n",
    "        self.image_id_to_file = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
    "        self.image_id_to_img = {}\n",
    "\n",
    "\n",
    "    def build_vocab(self):\n",
    "        counter = Counter()\n",
    "        for annotation in tqdm(self.annotations):\n",
    "            caption = annotation['caption']\n",
    "            tokens = self.tokenizer(caption.lower())\n",
    "            counter.update(tokens)\n",
    "        vocab = build_vocab_from_iterator([counter], specials=[\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"])\n",
    "        vocab.set_default_index(vocab[\"<unk>\"])  # Out-of-vocabulary words will be mapped to <unk>\n",
    "        global vocabulary\n",
    "        vocabulary = vocab\n",
    "        return vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.annotations[idx]['image_id']\n",
    "\n",
    "        file_name = self.image_id_to_file.get(image_id)\n",
    "        img_path = os.path.join(self.root_dir, file_name)\n",
    "\n",
    "        try:\n",
    "          image = Image.open(img_path).convert('RGB')\n",
    "          self.image_id_to_img[image_id] = image # NOTE\n",
    "        except Exception as e:\n",
    "          print(f\"Error opening image: {file_name}\")\n",
    "          raise e\n",
    "\n",
    "        caption = self.annotations[idx]['caption']\n",
    "        tokens = self.tokenizer(caption.lower())\n",
    "\n",
    "        # Convert caption tokens to indices\n",
    "        caption_indices = [self.vocab['<bos>']] + [self.vocab[token] for token in tokens] + [self.vocab['<eos>']]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, {'image_id': image_id,'captions': torch.tensor(caption_indices, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_mq_mUVUwzCC"
   },
   "outputs": [],
   "source": [
    "#MAINNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.cnn = models.resnet50(pretrained=True).to(device)\n",
    "        self.backbone = nn.Sequential(*list(self.cnn.children())[:-1])  # Get everything except the last detection layer\n",
    "        self.fc = nn.Linear(self.cnn.fc.in_features, embed_size)  # Linear layer to resize\n",
    "\n",
    "    def forward(self, images):\n",
    "        with torch.no_grad():  # Freeze CNN parameters\n",
    "            features = self.backbone(images)\n",
    "        features = features.view(features.size(0), -1)  # Flatten\n",
    "        features = self.fc(features)\n",
    "        return features\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        embeddings = self.embedding(captions)\n",
    "        inputs = torch.cat((features.unsqueeze(1), embeddings), dim=1)\n",
    "        lstm_out, _ = self.lstm(inputs)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        features = self.encoder(images)\n",
    "        outputs = self.decoder(features, captions)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.cnn = models.resnet50(pretrained=True).to(device)\n",
    "        self.backbone = nn.Sequential(*list(self.cnn.children())[:-1])  # Get everything except the last detection layer\n",
    "        self.fc = nn.Linear(self.cnn.fc.in_features, embed_size)  # Linear layer to resize\n",
    "        self.dropout = nn.Dropout(0.3)  # Add dropout to the encoder\n",
    "\n",
    "    def forward(self, images):\n",
    "        with torch.no_grad():  # Freeze CNN parameters\n",
    "            features = self.backbone(images)\n",
    "        features = features.view(features.size(0), -1)  # Flatten\n",
    "        features = self.fc(features)\n",
    "        features = self.dropout(features)  # Apply dropout to the feature vector\n",
    "        return features\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1, dropout_prob=0.3):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Embedding layer to convert words to a vector representation\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Bidirectional LSTM with dropout\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout_prob)\n",
    "        # Linear layer: multiply hidden_size by 2 because of the bidirectional LSTM\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        # Add a dropout layer after the LSTM output before the final linear layer\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        # Convert captions to embeddings\n",
    "        embeddings = self.embedding(captions)\n",
    "        # Concatenate features and embeddings along the sequence dimension\n",
    "        inputs = torch.cat((features.unsqueeze(1), embeddings), dim=1)\n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(inputs)\n",
    "        # Apply dropout after LSTM output\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        # Pass through fully connected layer to generate vocabulary scores\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        features = self.encoder(images)\n",
    "        outputs = self.decoder(features, captions)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hb3E8-q3wzCA",
    "outputId": "a7b21fa8-345f-4e1f-ab01-e86c464284b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591753/591753 [00:03<00:00, 185451.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891],\n",
      "         [2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891],\n",
      "         [2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891],\n",
      "         ...,\n",
      "         [2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891],\n",
      "         [2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891],\n",
      "         [2.24891, 2.24891, 2.24891,  ..., 2.24891, 2.24891, 2.24891]],\n",
      "\n",
      "        [[2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857],\n",
      "         [2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857],\n",
      "         [2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857],\n",
      "         ...,\n",
      "         [2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857],\n",
      "         [2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857],\n",
      "         [2.42857, 2.42857, 2.42857,  ..., 2.42857, 2.42857, 2.42857]],\n",
      "\n",
      "        [[2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000],\n",
      "         [2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000],\n",
      "         [2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000],\n",
      "         ...,\n",
      "         [2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000],\n",
      "         [2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000],\n",
      "         [2.64000, 2.64000, 2.64000,  ..., 2.64000, 2.64000, 2.64000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25014/25014 [00:00<00:00, 187834.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "import random \n",
    "\n",
    "train_image_number = 20000\n",
    "val_image_number = 4000\n",
    "\n",
    "train_images_path = './coco/train2017'\n",
    "train_annotations_path = './coco/annotations/captions_train2017.json'\n",
    "val_images_path = './coco/val2017'\n",
    "val_annotations_path = './coco/annotations/captions_val2017.json'\n",
    "\n",
    "# Load COCO Dataset (captions and images) using\n",
    "train_dataset = CocoDataset(train_images_path, train_annotations_path, transform=transform)\n",
    "\n",
    "# Example: Fetch an image and its caption\n",
    "image, caption = train_dataset[0]\n",
    "print(image)  # Prints the caption token indices\n",
    "\n",
    "val_dataset = CocoDataset(val_images_path, val_annotations_path, transform=transform)\n",
    "\n",
    "subset_indices = [i for i in range(4000)]\n",
    "\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "val_subset = Subset(val_dataset, subset_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-k5OuGe-BEpM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fibMtjjW5bBm"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collates a batch of (image, caption) pairs and pads captions.\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    image_ids = [target[\"image_id\"] for target in targets]\n",
    "    captions = [target[\"captions\"] for target in targets]\n",
    "    # Pad captions to have the same length in the batch\n",
    "    padded_captions = pad_sequence(captions, batch_first=True, padding_value=0)  # <pad> token is 0\n",
    "\n",
    "    # Stack images into a batch\n",
    "    images = torch.stack(images, 0) # dim: The dimension along which to stack. If dim=0, it adds a new first dimension to the tensors.\n",
    "   # NO NEED FOR padded_captions = torch.stack(padded_captions, 0) , padded_captions are already stacked\n",
    "\n",
    "    return images, image_ids, padded_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibJfgKj2wzCC"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    for images, image_ids, captions in dataloader:\n",
    "        #captions = targets['captions']\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        #print(len(captions))\n",
    "        #print(len(images))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, captions[:, :-1])  # Exclude last token in captions\n",
    "\n",
    "        batch_size, seq_len, vocab_size = outputs.size()\n",
    "        outputs = outputs.view(-1, vocab_size)  # Flattens outputs\n",
    "        captions = captions.view(-1)\n",
    "        loss = criterion(outputs, captions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print the current loss for monitoring the training progress\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids, captions in dataloader:\n",
    "            #captions = targets['captions']\n",
    "            images = images.to(device)\n",
    "            captions = captions.to(device)\n",
    "\n",
    "            #TODO DIMENSIONALITY PROBLEM\n",
    "            outputs = model(images, captions[:, :-1])  # Exclude last token in captions\n",
    "            batch_size, seq_len, vocab_size = outputs.size()\n",
    "            outputs = outputs.view(-1, vocab_size)  # Flattens outputs\n",
    "            captions = captions.view(-1)\n",
    "            loss = criterion(outputs, captions)  # Teacher forcing\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for checkpoints -> this can be used for storing state of the model in the midst of the training.\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok= True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "jLqqdHQkwzCD",
    "outputId": "1a25e518-6499-4b0e-93ed-426e8d1219b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591753/591753 [00:03<00:00, 180057.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_layers = 1\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Vocab\n",
    "train_dataset.vocab = train_dataset.build_vocab()\n",
    "# Instantiate Encoder, Decoder, and Model\n",
    "encoder = EncoderCNN(embed_size).to(device)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, len(train_dataset.vocab), num_layers=num_layers).to(device) # TODO\n",
    "model = ImageCaptioningModel(encoder, decoder).to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.303236961364746\n",
      "Loss: 9.765588760375977\n",
      "Loss: 9.63361644744873\n",
      "Loss: 8.469826698303223\n",
      "Loss: 8.934879302978516\n",
      "Loss: 8.609504699707031\n",
      "Loss: 7.357395648956299\n",
      "Loss: 3.458204507827759\n",
      "Loss: 5.4030303955078125\n",
      "Loss: 5.59335470199585\n",
      "Loss: 3.741607666015625\n",
      "Loss: 4.528093338012695\n",
      "Loss: 3.055696964263916\n",
      "Loss: 3.767695903778076\n",
      "Loss: 4.262363910675049\n",
      "Loss: 3.697359085083008\n",
      "Loss: 3.659416913986206\n",
      "Loss: 3.507753610610962\n",
      "Loss: 3.8023314476013184\n",
      "Loss: 2.6519644260406494\n",
      "Loss: 2.4620091915130615\n",
      "Loss: 3.209965944290161\n",
      "Loss: 2.9807045459747314\n",
      "Loss: 2.321748733520508\n",
      "Loss: 3.3059980869293213\n",
      "Loss: 3.7758474349975586\n",
      "Loss: 3.577812910079956\n",
      "Loss: 3.366856098175049\n",
      "Loss: 2.9022982120513916\n",
      "Loss: 3.3959171772003174\n",
      "Loss: 2.109205722808838\n",
      "Loss: 3.089293956756592\n",
      "Loss: 3.2200818061828613\n",
      "Loss: 2.431415319442749\n",
      "Loss: 3.783979892730713\n",
      "Loss: 3.1795654296875\n",
      "Loss: 3.107797145843506\n",
      "Loss: 3.337613344192505\n",
      "Loss: 3.935781955718994\n",
      "Loss: 3.344294548034668\n",
      "Loss: 2.5701756477355957\n",
      "Loss: 2.7572484016418457\n",
      "Loss: 3.205781936645508\n",
      "Loss: 3.288064956665039\n",
      "Loss: 2.142245054244995\n",
      "Loss: 3.077392339706421\n",
      "Loss: 2.499800682067871\n",
      "Loss: 2.9863619804382324\n",
      "Loss: 3.305281639099121\n",
      "Loss: 2.3666059970855713\n",
      "Loss: 2.714181661605835\n",
      "Loss: 3.116767168045044\n",
      "Loss: 2.6721150875091553\n",
      "Loss: 3.1203184127807617\n",
      "Loss: 3.2786622047424316\n",
      "Loss: 2.992720603942871\n",
      "Loss: 2.533628463745117\n",
      "Loss: 3.0355167388916016\n",
      "Loss: 2.5187489986419678\n",
      "Loss: 2.8235058784484863\n",
      "Loss: 2.806830406188965\n",
      "Loss: 3.1666200160980225\n",
      "Loss: 3.1120171546936035\n",
      "Loss: 2.369302272796631\n",
      "Loss: 3.3958699703216553\n",
      "Loss: 2.9170172214508057\n",
      "Loss: 3.1721715927124023\n",
      "Loss: 3.288254737854004\n",
      "Loss: 2.725015163421631\n",
      "Loss: 2.9558234214782715\n",
      "Loss: 2.792293071746826\n",
      "Loss: 2.994363784790039\n",
      "Loss: 2.6997923851013184\n",
      "Loss: 2.2342612743377686\n",
      "Loss: 2.9796080589294434\n",
      "Loss: 2.5115365982055664\n",
      "Loss: 2.143451452255249\n",
      "Loss: 2.7177631855010986\n",
      "Loss: 2.944845199584961\n",
      "Loss: 3.2732133865356445\n",
      "Loss: 3.455787420272827\n",
      "Loss: 3.228994607925415\n",
      "Loss: 2.868543863296509\n",
      "Loss: 3.2360429763793945\n",
      "Loss: 3.350085973739624\n",
      "Loss: 2.7865471839904785\n",
      "Loss: 1.683548927307129\n",
      "Loss: 3.0816543102264404\n",
      "Loss: 2.478768825531006\n",
      "Loss: 2.7390236854553223\n",
      "Loss: 2.566633939743042\n",
      "Loss: 2.3911383152008057\n",
      "Loss: 2.117551326751709\n",
      "Loss: 2.6560468673706055\n",
      "Loss: 3.052582263946533\n",
      "Loss: 2.540945529937744\n",
      "Loss: 2.386219024658203\n",
      "Loss: 2.9719345569610596\n",
      "Loss: 2.362354040145874\n",
      "Loss: 2.3655223846435547\n",
      "Loss: 2.2809553146362305\n",
      "Loss: 2.6993863582611084\n",
      "Loss: 2.9704432487487793\n",
      "Loss: 2.57438588142395\n",
      "Loss: 3.322563409805298\n",
      "Loss: 2.260672092437744\n",
      "Loss: 2.912611961364746\n",
      "Loss: 3.262864828109741\n",
      "Loss: 2.1165380477905273\n",
      "Loss: 2.6942451000213623\n",
      "Loss: 3.0176732540130615\n",
      "Loss: 2.201190710067749\n",
      "Loss: 2.3507726192474365\n",
      "Loss: 2.949739456176758\n",
      "Loss: 2.920970916748047\n",
      "Loss: 2.6959686279296875\n",
      "Loss: 2.9003913402557373\n",
      "Loss: 2.6845052242279053\n",
      "Loss: 2.7815287113189697\n",
      "Loss: 2.455083131790161\n",
      "Loss: 2.0918798446655273\n",
      "Loss: 3.0526955127716064\n",
      "Loss: 1.8985719680786133\n",
      "Loss: 2.1761231422424316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:57<18:17, 57.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.903203248977661\n",
      "Training for epoch 1/20 completed.\n",
      "Loss: 2.283644199371338\n",
      "Loss: 2.926236391067505\n",
      "Loss: 1.938520908355713\n",
      "Loss: 2.3469133377075195\n",
      "Loss: 2.7200067043304443\n",
      "Loss: 2.664088249206543\n",
      "Loss: 2.7759318351745605\n",
      "Loss: 2.4772658348083496\n",
      "Loss: 2.664966583251953\n",
      "Loss: 2.2136499881744385\n",
      "Loss: 1.8992018699645996\n",
      "Loss: 2.3496780395507812\n",
      "Loss: 2.274320363998413\n",
      "Loss: 2.446026086807251\n",
      "Loss: 2.324126958847046\n",
      "Loss: 2.1978394985198975\n",
      "Loss: 2.5261402130126953\n",
      "Loss: 2.349794626235962\n",
      "Loss: 2.6232335567474365\n",
      "Loss: 2.4349141120910645\n",
      "Loss: 1.8419959545135498\n",
      "Loss: 2.1446473598480225\n",
      "Loss: 2.6375203132629395\n",
      "Loss: 2.434880495071411\n",
      "Loss: 2.520979166030884\n",
      "Loss: 2.477773666381836\n",
      "Loss: 2.5511157512664795\n",
      "Loss: 1.643232822418213\n",
      "Loss: 2.7238476276397705\n",
      "Loss: 2.4706547260284424\n",
      "Loss: 2.8832101821899414\n",
      "Loss: 2.2659056186676025\n",
      "Loss: 2.6295204162597656\n",
      "Loss: 2.3754796981811523\n",
      "Loss: 2.525576591491699\n",
      "Loss: 2.821744441986084\n",
      "Loss: 2.236917734146118\n",
      "Loss: 2.3979809284210205\n",
      "Loss: 2.541949510574341\n",
      "Loss: 2.0205438137054443\n",
      "Loss: 2.4204964637756348\n",
      "Loss: 2.6140620708465576\n",
      "Loss: 2.0933375358581543\n",
      "Loss: 1.3573631048202515\n",
      "Loss: 2.4599316120147705\n",
      "Loss: 2.678267240524292\n",
      "Loss: 1.9928735494613647\n",
      "Loss: 2.286593198776245\n",
      "Loss: 1.5165024995803833\n",
      "Loss: 2.1346116065979004\n",
      "Loss: 2.568510055541992\n",
      "Loss: 2.908933639526367\n",
      "Loss: 2.336010694503784\n",
      "Loss: 1.5615681409835815\n",
      "Loss: 2.732447385787964\n",
      "Loss: 2.4113430976867676\n",
      "Loss: 2.729746103286743\n",
      "Loss: 2.0360240936279297\n",
      "Loss: 2.049640417098999\n",
      "Loss: 1.7666378021240234\n",
      "Loss: 1.9090745449066162\n",
      "Loss: 2.709420919418335\n",
      "Loss: 1.7463228702545166\n",
      "Loss: 2.6078286170959473\n",
      "Loss: 2.37674617767334\n",
      "Loss: 2.647778272628784\n",
      "Loss: 2.6244428157806396\n",
      "Loss: 2.260697841644287\n",
      "Loss: 2.1815595626831055\n",
      "Loss: 2.5357394218444824\n",
      "Loss: 2.5546584129333496\n",
      "Loss: 2.172414779663086\n",
      "Loss: 2.3817875385284424\n",
      "Loss: 2.4905519485473633\n",
      "Loss: 2.9860198497772217\n",
      "Loss: 3.0130996704101562\n",
      "Loss: 1.5460249185562134\n",
      "Loss: 2.404529333114624\n",
      "Loss: 2.4423060417175293\n",
      "Loss: 2.2268898487091064\n",
      "Loss: 2.7956039905548096\n",
      "Loss: 2.348024845123291\n",
      "Loss: 2.6737685203552246\n",
      "Loss: 2.717332124710083\n",
      "Loss: 2.5997366905212402\n",
      "Loss: 2.2247819900512695\n",
      "Loss: 2.251617670059204\n",
      "Loss: 2.441319704055786\n",
      "Loss: 1.5944528579711914\n",
      "Loss: 2.322150945663452\n",
      "Loss: 1.9562945365905762\n",
      "Loss: 2.140354871749878\n",
      "Loss: 2.1291611194610596\n",
      "Loss: 2.79268217086792\n",
      "Loss: 2.435811996459961\n",
      "Loss: 2.6562891006469727\n",
      "Loss: 2.7562999725341797\n",
      "Loss: 2.57067608833313\n",
      "Loss: 2.1649317741394043\n",
      "Loss: 2.4287257194519043\n",
      "Loss: 2.6460821628570557\n",
      "Loss: 2.0479629039764404\n",
      "Loss: 2.7025294303894043\n",
      "Loss: 2.7961761951446533\n",
      "Loss: 1.7043406963348389\n",
      "Loss: 2.1286544799804688\n",
      "Loss: 1.7125513553619385\n",
      "Loss: 2.291693687438965\n",
      "Loss: 2.6789376735687256\n",
      "Loss: 1.8271206617355347\n",
      "Loss: 1.7625248432159424\n",
      "Loss: 2.4558775424957275\n",
      "Loss: 2.52107572555542\n",
      "Loss: 2.0775983333587646\n",
      "Loss: 2.0224783420562744\n",
      "Loss: 1.9545763731002808\n",
      "Loss: 2.5024361610412598\n",
      "Loss: 1.446134090423584\n",
      "Loss: 2.4623630046844482\n",
      "Loss: 1.4153516292572021\n",
      "Loss: 2.4585442543029785\n",
      "Loss: 2.1028079986572266\n",
      "Loss: 2.2014944553375244\n",
      "Loss: 2.209254264831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [01:54<17:08, 57.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6155879497528076\n",
      "Training for epoch 2/20 completed.\n",
      "Loss: 2.135232448577881\n",
      "Loss: 1.4719494581222534\n",
      "Loss: 1.4447453022003174\n",
      "Loss: 2.145150899887085\n",
      "Loss: 2.4998040199279785\n",
      "Loss: 2.1977577209472656\n",
      "Loss: 2.3376100063323975\n",
      "Loss: 2.3836827278137207\n",
      "Loss: 2.1681954860687256\n",
      "Loss: 2.279686450958252\n",
      "Loss: 2.5275020599365234\n",
      "Loss: 2.42924427986145\n",
      "Loss: 2.029277801513672\n",
      "Loss: 2.0721263885498047\n",
      "Loss: 2.041142225265503\n",
      "Loss: 1.9536534547805786\n",
      "Loss: 1.950884222984314\n",
      "Loss: 1.8921024799346924\n",
      "Loss: 1.6811708211898804\n",
      "Loss: 2.514660120010376\n",
      "Loss: 2.316126823425293\n",
      "Loss: 1.520200490951538\n",
      "Loss: 2.097724676132202\n",
      "Loss: 2.088435649871826\n",
      "Loss: 2.0740814208984375\n",
      "Loss: 1.6526646614074707\n",
      "Loss: 2.169065475463867\n",
      "Loss: 1.910798192024231\n",
      "Loss: 2.180478572845459\n",
      "Loss: 2.18224835395813\n",
      "Loss: 1.406362533569336\n",
      "Loss: 1.8615151643753052\n",
      "Loss: 1.5467772483825684\n",
      "Loss: 1.9669660329818726\n",
      "Loss: 2.7429232597351074\n",
      "Loss: 1.7559759616851807\n",
      "Loss: 2.1327197551727295\n",
      "Loss: 2.101102590560913\n",
      "Loss: 2.4294517040252686\n",
      "Loss: 2.313988208770752\n",
      "Loss: 2.426605463027954\n",
      "Loss: 1.847993016242981\n",
      "Loss: 1.8870301246643066\n",
      "Loss: 1.7972612380981445\n",
      "Loss: 2.1748111248016357\n",
      "Loss: 1.626168966293335\n",
      "Loss: 1.7774732112884521\n",
      "Loss: 2.3025965690612793\n",
      "Loss: 2.385016679763794\n",
      "Loss: 2.6315712928771973\n",
      "Loss: 2.548426389694214\n",
      "Loss: 2.149517059326172\n",
      "Loss: 2.0482406616210938\n",
      "Loss: 2.397923469543457\n",
      "Loss: 1.9945050477981567\n",
      "Loss: 1.2469735145568848\n",
      "Loss: 1.9524818658828735\n",
      "Loss: 2.3852596282958984\n",
      "Loss: 2.115051031112671\n",
      "Loss: 2.3815832138061523\n",
      "Loss: 2.1990127563476562\n",
      "Loss: 2.5390474796295166\n",
      "Loss: 2.5300638675689697\n",
      "Loss: 1.729865312576294\n",
      "Loss: 2.0714762210845947\n",
      "Loss: 2.2752890586853027\n",
      "Loss: 1.3876805305480957\n",
      "Loss: 2.2933549880981445\n",
      "Loss: 1.753909945487976\n",
      "Loss: 2.544804811477661\n",
      "Loss: 1.9969475269317627\n",
      "Loss: 2.506681203842163\n",
      "Loss: 2.258009672164917\n",
      "Loss: 2.0329785346984863\n",
      "Loss: 2.0882105827331543\n",
      "Loss: 2.3159077167510986\n",
      "Loss: 1.4291883707046509\n",
      "Loss: 2.041647434234619\n",
      "Loss: 2.3040964603424072\n",
      "Loss: 1.3396130800247192\n",
      "Loss: 2.2317960262298584\n",
      "Loss: 2.3879191875457764\n",
      "Loss: 2.068683385848999\n",
      "Loss: 1.9592759609222412\n",
      "Loss: 2.241773843765259\n",
      "Loss: 1.983993411064148\n",
      "Loss: 1.95815908908844\n",
      "Loss: 2.249216079711914\n",
      "Loss: 2.2238292694091797\n",
      "Loss: 2.0691869258880615\n",
      "Loss: 2.5522518157958984\n",
      "Loss: 2.218377113342285\n",
      "Loss: 2.4919824600219727\n",
      "Loss: 1.9529510736465454\n",
      "Loss: 2.050736665725708\n",
      "Loss: 2.2764334678649902\n",
      "Loss: 2.331937551498413\n",
      "Loss: 1.7405831813812256\n",
      "Loss: 2.1791770458221436\n",
      "Loss: 2.1981453895568848\n",
      "Loss: 2.551567792892456\n",
      "Loss: 2.5374202728271484\n",
      "Loss: 2.1479384899139404\n",
      "Loss: 1.9368717670440674\n",
      "Loss: 1.465667724609375\n",
      "Loss: 2.3084311485290527\n",
      "Loss: 2.258535861968994\n",
      "Loss: 2.1675515174865723\n",
      "Loss: 1.4770305156707764\n",
      "Loss: 2.1508352756500244\n",
      "Loss: 1.7102651596069336\n",
      "Loss: 2.2409591674804688\n",
      "Loss: 2.090205430984497\n",
      "Loss: 1.7157841920852661\n",
      "Loss: 1.622017741203308\n",
      "Loss: 1.8084845542907715\n",
      "Loss: 2.172607898712158\n",
      "Loss: 1.5941225290298462\n",
      "Loss: 2.2368061542510986\n",
      "Loss: 1.8238279819488525\n",
      "Loss: 2.0834689140319824\n",
      "Loss: 1.6491769552230835\n",
      "Loss: 1.983705997467041\n",
      "Loss: 1.774781584739685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [02:51<16:13, 57.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2554898262023926\n",
      "Training for epoch 3/20 completed.\n",
      "Loss: 1.7696681022644043\n",
      "Loss: 2.0841763019561768\n",
      "Loss: 1.7276802062988281\n",
      "Loss: 1.0350818634033203\n",
      "Loss: 2.071413993835449\n",
      "Loss: 1.5036183595657349\n",
      "Loss: 2.038670778274536\n",
      "Loss: 2.3130295276641846\n",
      "Loss: 1.8785425424575806\n",
      "Loss: 1.9975738525390625\n",
      "Loss: 1.5842801332473755\n",
      "Loss: 1.4596294164657593\n",
      "Loss: 2.166879653930664\n",
      "Loss: 2.017914056777954\n",
      "Loss: 1.730704426765442\n",
      "Loss: 2.115539073944092\n",
      "Loss: 1.7619354724884033\n",
      "Loss: 1.8080488443374634\n",
      "Loss: 1.8648821115493774\n",
      "Loss: 2.4638123512268066\n",
      "Loss: 1.4483741521835327\n",
      "Loss: 1.9282692670822144\n",
      "Loss: 1.3949732780456543\n",
      "Loss: 1.7495168447494507\n",
      "Loss: 1.500714659690857\n",
      "Loss: 1.880820393562317\n",
      "Loss: 1.6420012712478638\n",
      "Loss: 1.3934117555618286\n",
      "Loss: 2.0787439346313477\n",
      "Loss: 2.0282955169677734\n",
      "Loss: 2.0675411224365234\n",
      "Loss: 1.5672264099121094\n",
      "Loss: 1.6363236904144287\n",
      "Loss: 1.3549281358718872\n",
      "Loss: 1.6020143032073975\n",
      "Loss: 1.986546516418457\n",
      "Loss: 2.271732807159424\n",
      "Loss: 1.7830485105514526\n",
      "Loss: 2.1651668548583984\n",
      "Loss: 2.384514808654785\n",
      "Loss: 2.105501413345337\n",
      "Loss: 1.9756978750228882\n",
      "Loss: 1.6358836889266968\n",
      "Loss: 1.5350925922393799\n",
      "Loss: 1.9509280920028687\n",
      "Loss: 1.276482343673706\n",
      "Loss: 1.3142229318618774\n",
      "Loss: 1.6418710947036743\n",
      "Loss: 2.0672333240509033\n",
      "Loss: 2.1044259071350098\n",
      "Loss: 2.008228302001953\n",
      "Loss: 2.045919895172119\n",
      "Loss: 1.6124441623687744\n",
      "Loss: 2.032132863998413\n",
      "Loss: 2.293247938156128\n",
      "Loss: 2.023905038833618\n",
      "Loss: 1.895078182220459\n",
      "Loss: 2.372685670852661\n",
      "Loss: 1.9242511987686157\n",
      "Loss: 2.108856439590454\n",
      "Loss: 2.1246421337127686\n",
      "Loss: 1.5802769660949707\n",
      "Loss: 2.2341361045837402\n",
      "Loss: 1.9817314147949219\n",
      "Loss: 1.7359559535980225\n",
      "Loss: 2.024616003036499\n",
      "Loss: 1.9385570287704468\n",
      "Loss: 2.1006221771240234\n",
      "Loss: 1.9195165634155273\n",
      "Loss: 1.7506340742111206\n",
      "Loss: 1.9106643199920654\n",
      "Loss: 1.9626051187515259\n",
      "Loss: 2.3053476810455322\n",
      "Loss: 1.7599371671676636\n",
      "Loss: 1.8884656429290771\n",
      "Loss: 1.9856741428375244\n",
      "Loss: 2.201061964035034\n",
      "Loss: 2.112962245941162\n",
      "Loss: 1.700520396232605\n",
      "Loss: 1.9885694980621338\n",
      "Loss: 1.9276612997055054\n",
      "Loss: 1.9994922876358032\n",
      "Loss: 1.7516231536865234\n",
      "Loss: 2.0998964309692383\n",
      "Loss: 1.7958372831344604\n",
      "Loss: 1.5882511138916016\n",
      "Loss: 1.5512076616287231\n",
      "Loss: 2.0735864639282227\n",
      "Loss: 1.8945693969726562\n",
      "Loss: 1.9512722492218018\n",
      "Loss: 1.8855345249176025\n",
      "Loss: 1.625402569770813\n",
      "Loss: 1.6397866010665894\n",
      "Loss: 2.1031155586242676\n",
      "Loss: 1.655909538269043\n",
      "Loss: 2.1826677322387695\n",
      "Loss: 1.9437860250473022\n",
      "Loss: 1.981900691986084\n",
      "Loss: 2.265451431274414\n",
      "Loss: 1.9390345811843872\n",
      "Loss: 1.932064175605774\n",
      "Loss: 1.4054423570632935\n",
      "Loss: 2.2898974418640137\n",
      "Loss: 2.3340632915496826\n",
      "Loss: 1.9573218822479248\n",
      "Loss: 2.214290142059326\n",
      "Loss: 1.864795446395874\n",
      "Loss: 1.3461012840270996\n",
      "Loss: 2.2157633304595947\n",
      "Loss: 2.085329294204712\n",
      "Loss: 1.9837524890899658\n",
      "Loss: 2.088514804840088\n",
      "Loss: 1.9254205226898193\n",
      "Loss: 2.2629928588867188\n",
      "Loss: 1.788498044013977\n",
      "Loss: 1.8026323318481445\n",
      "Loss: 1.7962158918380737\n",
      "Loss: 1.784538745880127\n",
      "Loss: 1.8296623229980469\n",
      "Loss: 1.9052952527999878\n",
      "Loss: 2.01700496673584\n",
      "Loss: 1.2366149425506592\n",
      "Loss: 1.6217490434646606\n",
      "Loss: 2.0569562911987305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [03:49<15:17, 57.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4539144039154053\n",
      "Training for epoch 4/20 completed.\n",
      "Loss: 1.9471547603607178\n",
      "Loss: 1.8197799921035767\n",
      "Loss: 1.857600450515747\n",
      "Loss: 1.7659292221069336\n",
      "Loss: 1.6599135398864746\n",
      "Loss: 1.4964687824249268\n",
      "Loss: 1.5009453296661377\n",
      "Loss: 1.6548056602478027\n",
      "Loss: 1.7211157083511353\n",
      "Loss: 1.6107888221740723\n",
      "Loss: 1.8777656555175781\n",
      "Loss: 1.7438950538635254\n",
      "Loss: 1.5801095962524414\n",
      "Loss: 1.2517006397247314\n",
      "Loss: 1.6474435329437256\n",
      "Loss: 1.1039535999298096\n",
      "Loss: 1.5770840644836426\n",
      "Loss: 1.9414658546447754\n",
      "Loss: 2.039097785949707\n",
      "Loss: 1.7698482275009155\n",
      "Loss: 1.773969054222107\n",
      "Loss: 1.9833285808563232\n",
      "Loss: 1.3790072202682495\n",
      "Loss: 1.8081508874893188\n",
      "Loss: 2.1207756996154785\n",
      "Loss: 2.0475635528564453\n",
      "Loss: 1.6014577150344849\n",
      "Loss: 1.6102700233459473\n",
      "Loss: 2.0546483993530273\n",
      "Loss: 1.3837813138961792\n",
      "Loss: 1.7449028491973877\n",
      "Loss: 1.9524307250976562\n",
      "Loss: 1.0001447200775146\n",
      "Loss: 1.6193443536758423\n",
      "Loss: 1.8289375305175781\n",
      "Loss: 1.961186408996582\n",
      "Loss: 1.7525615692138672\n",
      "Loss: 1.5298352241516113\n",
      "Loss: 1.8532243967056274\n",
      "Loss: 1.895562767982483\n",
      "Loss: 1.4494577646255493\n",
      "Loss: 1.7256534099578857\n",
      "Loss: 1.6799814701080322\n",
      "Loss: 1.9748698472976685\n",
      "Loss: 1.3151826858520508\n",
      "Loss: 1.7750574350357056\n",
      "Loss: 1.8397448062896729\n",
      "Loss: 1.608642339706421\n",
      "Loss: 2.0201330184936523\n",
      "Loss: 1.928086519241333\n",
      "Loss: 1.8150644302368164\n",
      "Loss: 2.1897404193878174\n",
      "Loss: 1.2752071619033813\n",
      "Loss: 1.9464694261550903\n",
      "Loss: 1.8382184505462646\n",
      "Loss: 1.9582979679107666\n",
      "Loss: 1.637162685394287\n",
      "Loss: 1.596623420715332\n",
      "Loss: 2.0536253452301025\n",
      "Loss: 1.5440157651901245\n",
      "Loss: 1.4502248764038086\n",
      "Loss: 2.0746963024139404\n",
      "Loss: 2.054488182067871\n",
      "Loss: 1.6576976776123047\n",
      "Loss: 1.7864748239517212\n",
      "Loss: 2.0262463092803955\n",
      "Loss: 1.6913063526153564\n",
      "Loss: 1.7732073068618774\n",
      "Loss: 1.481526494026184\n",
      "Loss: 1.7241690158843994\n",
      "Loss: 2.2007439136505127\n",
      "Loss: 1.6182900667190552\n",
      "Loss: 1.9421952962875366\n",
      "Loss: 1.556899070739746\n",
      "Loss: 1.8940911293029785\n",
      "Loss: 1.48153817653656\n",
      "Loss: 1.6364909410476685\n",
      "Loss: 1.9901299476623535\n",
      "Loss: 1.313926339149475\n",
      "Loss: 1.5249167680740356\n",
      "Loss: 1.5521143674850464\n",
      "Loss: 1.6791136264801025\n",
      "Loss: 1.8696871995925903\n",
      "Loss: 1.938942790031433\n",
      "Loss: 2.0919525623321533\n",
      "Loss: 1.6738568544387817\n",
      "Loss: 2.0884251594543457\n",
      "Loss: 2.1323323249816895\n",
      "Loss: 1.813368320465088\n",
      "Loss: 1.6082628965377808\n",
      "Loss: 1.750914216041565\n",
      "Loss: 1.9725662469863892\n",
      "Loss: 1.7580281496047974\n",
      "Loss: 1.7819358110427856\n",
      "Loss: 1.502792477607727\n",
      "Loss: 1.3190803527832031\n",
      "Loss: 1.958569884300232\n",
      "Loss: 1.9687232971191406\n",
      "Loss: 1.9968209266662598\n",
      "Loss: 1.6841633319854736\n",
      "Loss: 1.5540709495544434\n",
      "Loss: 1.709238052368164\n",
      "Loss: 1.6074581146240234\n",
      "Loss: 1.7189375162124634\n",
      "Loss: 1.7496436834335327\n",
      "Loss: 1.3886618614196777\n",
      "Loss: 1.4816447496414185\n",
      "Loss: 1.3865931034088135\n",
      "Loss: 1.604108452796936\n",
      "Loss: 1.6904375553131104\n",
      "Loss: 1.1812442541122437\n",
      "Loss: 1.7231045961380005\n",
      "Loss: 1.8754286766052246\n",
      "Loss: 1.393618106842041\n",
      "Loss: 1.1740503311157227\n",
      "Loss: 1.4356945753097534\n",
      "Loss: 1.9440574645996094\n",
      "Loss: 1.803210973739624\n",
      "Loss: 2.1397464275360107\n",
      "Loss: 1.768520712852478\n",
      "Loss: 1.7070624828338623\n",
      "Loss: 1.8253713846206665\n",
      "Loss: 1.3303170204162598\n",
      "Loss: 1.772682785987854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [04:46<14:21, 57.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.437455415725708\n",
      "Training for epoch 5/20 completed.\n",
      "Loss: 1.6122967004776\n",
      "Loss: 1.3551443815231323\n",
      "Loss: 1.7806012630462646\n",
      "Loss: 1.5500743389129639\n",
      "Loss: 1.3419013023376465\n",
      "Loss: 1.902029275894165\n",
      "Loss: 1.3262566328048706\n",
      "Loss: 1.551301121711731\n",
      "Loss: 1.3603719472885132\n",
      "Loss: 1.767556071281433\n",
      "Loss: 1.7359060049057007\n",
      "Loss: 1.8900842666625977\n",
      "Loss: 1.697970986366272\n",
      "Loss: 1.535747766494751\n",
      "Loss: 1.4168975353240967\n",
      "Loss: 1.4873687028884888\n",
      "Loss: 1.2438056468963623\n",
      "Loss: 1.48582124710083\n",
      "Loss: 1.7005817890167236\n",
      "Loss: 1.5185723304748535\n",
      "Loss: 1.4996329545974731\n",
      "Loss: 1.647178053855896\n",
      "Loss: 1.3181856870651245\n",
      "Loss: 1.6992663145065308\n",
      "Loss: 1.6895904541015625\n",
      "Loss: 1.0334407091140747\n",
      "Loss: 1.64697265625\n",
      "Loss: 1.4826563596725464\n",
      "Loss: 1.858628273010254\n",
      "Loss: 1.5483884811401367\n",
      "Loss: 1.6166282892227173\n",
      "Loss: 1.722256064414978\n",
      "Loss: 1.306017518043518\n",
      "Loss: 1.786978840827942\n",
      "Loss: 1.7673736810684204\n",
      "Loss: 1.7118313312530518\n",
      "Loss: 1.9943206310272217\n",
      "Loss: 1.6068626642227173\n",
      "Loss: 1.630780816078186\n",
      "Loss: 1.6211992502212524\n",
      "Loss: 1.7364262342453003\n",
      "Loss: 1.6607458591461182\n",
      "Loss: 1.9955017566680908\n",
      "Loss: 1.5040606260299683\n",
      "Loss: 1.896683931350708\n",
      "Loss: 1.6969928741455078\n",
      "Loss: 1.5554168224334717\n",
      "Loss: 1.8080711364746094\n",
      "Loss: 1.6896941661834717\n",
      "Loss: 1.4949089288711548\n",
      "Loss: 1.5275582075119019\n",
      "Loss: 2.0417206287384033\n",
      "Loss: 1.777304768562317\n",
      "Loss: 1.8111871480941772\n",
      "Loss: 1.822094202041626\n",
      "Loss: 1.9097294807434082\n",
      "Loss: 1.5163098573684692\n",
      "Loss: 1.0790989398956299\n",
      "Loss: 1.6768132448196411\n",
      "Loss: 1.8340176343917847\n",
      "Loss: 1.5128390789031982\n",
      "Loss: 1.6063874959945679\n",
      "Loss: 1.296692132949829\n",
      "Loss: 1.385223388671875\n",
      "Loss: 1.3825122117996216\n",
      "Loss: 1.367963433265686\n",
      "Loss: 1.5961904525756836\n",
      "Loss: 2.0100769996643066\n",
      "Loss: 1.4005149602890015\n",
      "Loss: 1.4876521825790405\n",
      "Loss: 1.5231062173843384\n",
      "Loss: 1.6906893253326416\n",
      "Loss: 1.2854863405227661\n",
      "Loss: 2.0148420333862305\n",
      "Loss: 1.7835222482681274\n",
      "Loss: 1.5120277404785156\n",
      "Loss: 1.5085258483886719\n",
      "Loss: 1.421900749206543\n",
      "Loss: 1.897402286529541\n",
      "Loss: 1.4661281108856201\n",
      "Loss: 1.5310380458831787\n",
      "Loss: 1.5291787385940552\n",
      "Loss: 1.0749307870864868\n",
      "Loss: 1.5378174781799316\n",
      "Loss: 1.7591619491577148\n",
      "Loss: 2.0012669563293457\n",
      "Loss: 1.2829197645187378\n",
      "Loss: 1.7360285520553589\n",
      "Loss: 1.6449989080429077\n",
      "Loss: 1.1116448640823364\n",
      "Loss: 1.1303966045379639\n",
      "Loss: 1.8408331871032715\n",
      "Loss: 1.041061282157898\n",
      "Loss: 1.6263923645019531\n",
      "Loss: 1.2174291610717773\n",
      "Loss: 1.7658591270446777\n",
      "Loss: 1.451837420463562\n",
      "Loss: 1.5892014503479004\n",
      "Loss: 1.5880013704299927\n",
      "Loss: 1.4262480735778809\n",
      "Loss: 1.375084400177002\n",
      "Loss: 1.3439072370529175\n",
      "Loss: 1.8933875560760498\n",
      "Loss: 1.4475356340408325\n",
      "Loss: 1.541406273841858\n",
      "Loss: 1.7732843160629272\n",
      "Loss: 1.4393327236175537\n",
      "Loss: 1.888364553451538\n",
      "Loss: 1.789947748184204\n",
      "Loss: 1.3290940523147583\n",
      "Loss: 1.5219876766204834\n",
      "Loss: 1.6829376220703125\n",
      "Loss: 1.4113727807998657\n",
      "Loss: 1.9507907629013062\n",
      "Loss: 1.8498365879058838\n",
      "Loss: 1.8767166137695312\n",
      "Loss: 2.0868382453918457\n",
      "Loss: 1.2645963430404663\n",
      "Loss: 1.6435946226119995\n",
      "Loss: 1.0754189491271973\n",
      "Loss: 1.6038413047790527\n",
      "Loss: 1.5821317434310913\n",
      "Loss: 1.4807531833648682\n",
      "Loss: 1.946319341659546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [05:44<13:23, 57.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6624833345413208\n",
      "Training for epoch 6/20 completed.\n",
      "Loss: 1.3264330625534058\n",
      "Loss: 1.4279636144638062\n",
      "Loss: 1.610304355621338\n",
      "Loss: 1.2838664054870605\n",
      "Loss: 1.5177114009857178\n",
      "Loss: 1.2408463954925537\n",
      "Loss: 1.4480712413787842\n",
      "Loss: 1.7518548965454102\n",
      "Loss: 1.6398365497589111\n",
      "Loss: 1.3939167261123657\n",
      "Loss: 1.6035652160644531\n",
      "Loss: 1.2232953310012817\n",
      "Loss: 1.0007364749908447\n",
      "Loss: 1.463964581489563\n",
      "Loss: 1.4084689617156982\n",
      "Loss: 1.2034322023391724\n",
      "Loss: 1.2888566255569458\n",
      "Loss: 1.4936527013778687\n",
      "Loss: 1.100463628768921\n",
      "Loss: 1.1568061113357544\n",
      "Loss: 1.5811781883239746\n",
      "Loss: 1.5344425439834595\n",
      "Loss: 1.126524567604065\n",
      "Loss: 1.5811363458633423\n",
      "Loss: 1.3262921571731567\n",
      "Loss: 1.2304400205612183\n",
      "Loss: 0.9674520492553711\n",
      "Loss: 1.2364797592163086\n",
      "Loss: 1.368921160697937\n",
      "Loss: 1.6670787334442139\n",
      "Loss: 1.6584367752075195\n",
      "Loss: 1.523141622543335\n",
      "Loss: 0.9713083505630493\n",
      "Loss: 1.0072708129882812\n",
      "Loss: 1.1731629371643066\n",
      "Loss: 1.6153396368026733\n",
      "Loss: 1.5087814331054688\n",
      "Loss: 1.5717412233352661\n",
      "Loss: 1.661657691001892\n",
      "Loss: 1.6145089864730835\n",
      "Loss: 1.5992610454559326\n",
      "Loss: 1.5685551166534424\n",
      "Loss: 1.4304242134094238\n",
      "Loss: 1.5338404178619385\n",
      "Loss: 1.776072382926941\n",
      "Loss: 1.2251745462417603\n",
      "Loss: 1.3239129781723022\n",
      "Loss: 1.2653698921203613\n",
      "Loss: 1.6367783546447754\n",
      "Loss: 1.4435880184173584\n",
      "Loss: 1.380033016204834\n",
      "Loss: 1.349367380142212\n",
      "Loss: 1.3552641868591309\n",
      "Loss: 0.7903677821159363\n",
      "Loss: 1.4996336698532104\n",
      "Loss: 1.7600350379943848\n",
      "Loss: 1.559195876121521\n",
      "Loss: 1.257325291633606\n",
      "Loss: 1.758500337600708\n",
      "Loss: 1.5953361988067627\n",
      "Loss: 1.4629422426223755\n",
      "Loss: 0.983254075050354\n",
      "Loss: 1.708616018295288\n",
      "Loss: 1.5141738653182983\n",
      "Loss: 1.402928113937378\n",
      "Loss: 1.7453490495681763\n",
      "Loss: 1.3736238479614258\n",
      "Loss: 1.5562903881072998\n",
      "Loss: 1.4514126777648926\n",
      "Loss: 1.245421290397644\n",
      "Loss: 1.2575868368148804\n",
      "Loss: 1.396938681602478\n",
      "Loss: 1.3625819683074951\n",
      "Loss: 1.4421228170394897\n",
      "Loss: 1.550022840499878\n",
      "Loss: 1.5554674863815308\n",
      "Loss: 1.657542109489441\n",
      "Loss: 1.6059948205947876\n",
      "Loss: 1.70516037940979\n",
      "Loss: 1.3388304710388184\n",
      "Loss: 1.294991135597229\n",
      "Loss: 1.0358712673187256\n",
      "Loss: 1.7284393310546875\n",
      "Loss: 1.5612881183624268\n",
      "Loss: 1.4579627513885498\n",
      "Loss: 1.3024731874465942\n",
      "Loss: 1.3706125020980835\n",
      "Loss: 1.6894086599349976\n",
      "Loss: 1.6474263668060303\n",
      "Loss: 1.649192214012146\n",
      "Loss: 1.308112621307373\n",
      "Loss: 1.4086806774139404\n",
      "Loss: 1.5851445198059082\n",
      "Loss: 1.5111652612686157\n",
      "Loss: 1.6415464878082275\n",
      "Loss: 1.6713850498199463\n",
      "Loss: 1.6114721298217773\n",
      "Loss: 1.5520695447921753\n",
      "Loss: 1.5952214002609253\n",
      "Loss: 1.653912901878357\n",
      "Loss: 1.4654574394226074\n",
      "Loss: 1.4947031736373901\n",
      "Loss: 1.2160553932189941\n",
      "Loss: 1.5396479368209839\n",
      "Loss: 1.6317057609558105\n",
      "Loss: 1.6093637943267822\n",
      "Loss: 0.9911831617355347\n",
      "Loss: 1.4768649339675903\n",
      "Loss: 1.2278871536254883\n",
      "Loss: 1.8681399822235107\n",
      "Loss: 1.62582266330719\n",
      "Loss: 1.2049260139465332\n",
      "Loss: 1.4094314575195312\n",
      "Loss: 1.5270551443099976\n",
      "Loss: 1.5815155506134033\n",
      "Loss: 1.52078378200531\n",
      "Loss: 1.561566710472107\n",
      "Loss: 1.4193812608718872\n",
      "Loss: 1.3909422159194946\n",
      "Loss: 1.5688127279281616\n",
      "Loss: 1.3523255586624146\n",
      "Loss: 1.360264539718628\n",
      "Loss: 1.1886786222457886\n",
      "Loss: 1.6889842748641968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [06:43<12:33, 57.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4920684099197388\n",
      "Training for epoch 7/20 completed.\n",
      "Loss: 0.8348223567008972\n",
      "Loss: 1.335086703300476\n",
      "Loss: 1.240159511566162\n",
      "Loss: 1.3457976579666138\n",
      "Loss: 1.3619840145111084\n",
      "Loss: 1.074265718460083\n",
      "Loss: 1.1825796365737915\n",
      "Loss: 1.3839818239212036\n",
      "Loss: 1.4781519174575806\n",
      "Loss: 1.3032886981964111\n",
      "Loss: 1.3959436416625977\n",
      "Loss: 1.2174861431121826\n",
      "Loss: 0.9714825749397278\n",
      "Loss: 1.3115917444229126\n",
      "Loss: 1.464302659034729\n",
      "Loss: 1.3618404865264893\n",
      "Loss: 0.9795985817909241\n",
      "Loss: 1.2726407051086426\n",
      "Loss: 1.243410587310791\n",
      "Loss: 1.3986691236495972\n",
      "Loss: 1.4551721811294556\n",
      "Loss: 1.1959834098815918\n",
      "Loss: 1.2643851041793823\n",
      "Loss: 1.3267383575439453\n",
      "Loss: 1.459643006324768\n",
      "Loss: 1.2884000539779663\n",
      "Loss: 1.2041434049606323\n",
      "Loss: 1.34604811668396\n",
      "Loss: 0.9686623215675354\n",
      "Loss: 1.399109125137329\n",
      "Loss: 1.185205101966858\n",
      "Loss: 1.1417046785354614\n",
      "Loss: 1.28189218044281\n",
      "Loss: 1.1929852962493896\n",
      "Loss: 1.1195076704025269\n",
      "Loss: 1.2141902446746826\n",
      "Loss: 1.5317553281784058\n",
      "Loss: 1.0702526569366455\n",
      "Loss: 1.4242609739303589\n",
      "Loss: 1.2058117389678955\n",
      "Loss: 1.6114474534988403\n",
      "Loss: 1.0911978483200073\n",
      "Loss: 1.4468576908111572\n",
      "Loss: 1.6262798309326172\n",
      "Loss: 1.3573287725448608\n",
      "Loss: 1.0642757415771484\n",
      "Loss: 1.3186205625534058\n",
      "Loss: 1.6865041255950928\n",
      "Loss: 1.4404990673065186\n",
      "Loss: 1.1759785413742065\n",
      "Loss: 1.2575401067733765\n",
      "Loss: 1.313267469406128\n",
      "Loss: 1.2537752389907837\n",
      "Loss: 1.0921177864074707\n",
      "Loss: 1.0678093433380127\n",
      "Loss: 1.5089138746261597\n",
      "Loss: 1.0141676664352417\n",
      "Loss: 1.520261526107788\n",
      "Loss: 1.3011935949325562\n",
      "Loss: 0.9506673812866211\n",
      "Loss: 1.4722305536270142\n",
      "Loss: 1.1089770793914795\n",
      "Loss: 1.4175037145614624\n",
      "Loss: 1.4295579195022583\n",
      "Loss: 1.059281587600708\n",
      "Loss: 1.3417000770568848\n",
      "Loss: 1.4371137619018555\n",
      "Loss: 1.090454339981079\n",
      "Loss: 1.1822824478149414\n",
      "Loss: 0.9465323090553284\n",
      "Loss: 1.5951776504516602\n",
      "Loss: 1.2032583951950073\n",
      "Loss: 1.5686103105545044\n",
      "Loss: 1.3126602172851562\n",
      "Loss: 1.51007080078125\n",
      "Loss: 0.7377605438232422\n",
      "Loss: 1.555317997932434\n",
      "Loss: 1.315143346786499\n",
      "Loss: 1.3715983629226685\n",
      "Loss: 1.349463701248169\n",
      "Loss: 1.1940572261810303\n",
      "Loss: 1.4761097431182861\n",
      "Loss: 1.3601115942001343\n",
      "Loss: 1.3578318357467651\n",
      "Loss: 1.6216717958450317\n",
      "Loss: 1.6462407112121582\n",
      "Loss: 1.2936896085739136\n",
      "Loss: 1.4278538227081299\n",
      "Loss: 1.26337730884552\n",
      "Loss: 0.8986294865608215\n",
      "Loss: 1.6303378343582153\n",
      "Loss: 1.2245808839797974\n",
      "Loss: 1.5218383073806763\n",
      "Loss: 1.353851318359375\n",
      "Loss: 1.3500405550003052\n",
      "Loss: 1.0426223278045654\n",
      "Loss: 1.129310131072998\n",
      "Loss: 1.2679363489151\n",
      "Loss: 1.414201021194458\n",
      "Loss: 1.337613821029663\n",
      "Loss: 1.5533668994903564\n",
      "Loss: 1.3560640811920166\n",
      "Loss: 1.364262580871582\n",
      "Loss: 1.469576358795166\n",
      "Loss: 1.2008018493652344\n",
      "Loss: 1.153875470161438\n",
      "Loss: 0.8706918954849243\n",
      "Loss: 1.457350730895996\n",
      "Loss: 1.165097951889038\n",
      "Loss: 1.4681873321533203\n",
      "Loss: 1.0372644662857056\n",
      "Loss: 1.405604362487793\n",
      "Loss: 1.5090796947479248\n",
      "Loss: 1.5879921913146973\n",
      "Loss: 1.118843913078308\n",
      "Loss: 1.5283762216567993\n",
      "Loss: 1.503637671470642\n",
      "Loss: 1.1855902671813965\n",
      "Loss: 1.369493007659912\n",
      "Loss: 1.0817872285842896\n",
      "Loss: 1.349556803703308\n",
      "Loss: 1.1316839456558228\n",
      "Loss: 1.4706718921661377\n",
      "Loss: 1.5819058418273926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [07:40<11:33, 57.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3970311880111694\n",
      "Training for epoch 8/20 completed.\n",
      "Loss: 0.9038370251655579\n",
      "Loss: 1.0662157535552979\n",
      "Loss: 1.2349399328231812\n",
      "Loss: 1.2796319723129272\n",
      "Loss: 0.9843257665634155\n",
      "Loss: 1.116329550743103\n",
      "Loss: 1.458113193511963\n",
      "Loss: 1.35286283493042\n",
      "Loss: 1.2838107347488403\n",
      "Loss: 1.1197211742401123\n",
      "Loss: 1.0994386672973633\n",
      "Loss: 1.3183056116104126\n",
      "Loss: 0.9087726473808289\n",
      "Loss: 0.9840123653411865\n",
      "Loss: 1.3307558298110962\n",
      "Loss: 0.7631388902664185\n",
      "Loss: 1.0958775281906128\n",
      "Loss: 1.392417073249817\n",
      "Loss: 1.4192967414855957\n",
      "Loss: 1.2631064653396606\n",
      "Loss: 1.2753623723983765\n",
      "Loss: 1.1114391088485718\n",
      "Loss: 1.2083463668823242\n",
      "Loss: 0.9434276819229126\n",
      "Loss: 1.1279581785202026\n",
      "Loss: 0.9445687532424927\n",
      "Loss: 1.2080062627792358\n",
      "Loss: 1.1316207647323608\n",
      "Loss: 1.1118632555007935\n",
      "Loss: 1.2372629642486572\n",
      "Loss: 1.1299630403518677\n",
      "Loss: 1.159907579421997\n",
      "Loss: 1.131993055343628\n",
      "Loss: 1.3990144729614258\n",
      "Loss: 1.2150505781173706\n",
      "Loss: 1.480776071548462\n",
      "Loss: 1.3357268571853638\n",
      "Loss: 1.2607731819152832\n",
      "Loss: 1.1026822328567505\n",
      "Loss: 1.3679978847503662\n",
      "Loss: 1.4632896184921265\n",
      "Loss: 1.3436144590377808\n",
      "Loss: 0.945508599281311\n",
      "Loss: 1.2832527160644531\n",
      "Loss: 1.103684425354004\n",
      "Loss: 1.229976773262024\n",
      "Loss: 1.2394933700561523\n",
      "Loss: 1.426196575164795\n",
      "Loss: 0.8949249386787415\n",
      "Loss: 1.3329635858535767\n",
      "Loss: 0.7994616031646729\n",
      "Loss: 1.2223546504974365\n",
      "Loss: 1.2333736419677734\n",
      "Loss: 1.3195016384124756\n",
      "Loss: 1.2554082870483398\n",
      "Loss: 0.9928888082504272\n",
      "Loss: 0.7761795520782471\n",
      "Loss: 1.2210992574691772\n",
      "Loss: 1.0054967403411865\n",
      "Loss: 1.3235633373260498\n",
      "Loss: 1.006988525390625\n",
      "Loss: 1.255966305732727\n",
      "Loss: 1.140699028968811\n",
      "Loss: 1.4295300245285034\n",
      "Loss: 1.5149377584457397\n",
      "Loss: 1.4146921634674072\n",
      "Loss: 1.3244869709014893\n",
      "Loss: 1.3459672927856445\n",
      "Loss: 0.983056366443634\n",
      "Loss: 1.2660263776779175\n",
      "Loss: 1.1810107231140137\n",
      "Loss: 1.314096450805664\n",
      "Loss: 1.0781023502349854\n",
      "Loss: 1.2543433904647827\n",
      "Loss: 1.2736860513687134\n",
      "Loss: 1.3239569664001465\n",
      "Loss: 1.097413182258606\n",
      "Loss: 1.162959098815918\n",
      "Loss: 0.9192990660667419\n",
      "Loss: 1.0069339275360107\n",
      "Loss: 1.3795959949493408\n",
      "Loss: 1.1714354753494263\n",
      "Loss: 1.212954044342041\n",
      "Loss: 1.5006896257400513\n",
      "Loss: 0.9679769277572632\n",
      "Loss: 1.332749366760254\n",
      "Loss: 0.8083837032318115\n",
      "Loss: 1.5144400596618652\n",
      "Loss: 1.348353624343872\n",
      "Loss: 1.1680079698562622\n",
      "Loss: 1.192919373512268\n",
      "Loss: 1.1931787729263306\n",
      "Loss: 1.3164881467819214\n",
      "Loss: 1.4335201978683472\n",
      "Loss: 1.3131157159805298\n",
      "Loss: 0.7960211038589478\n",
      "Loss: 1.442126989364624\n",
      "Loss: 1.068473219871521\n",
      "Loss: 1.3791061639785767\n",
      "Loss: 1.0341506004333496\n",
      "Loss: 0.6976558566093445\n",
      "Loss: 1.0104396343231201\n",
      "Loss: 1.406620979309082\n",
      "Loss: 0.9318532347679138\n",
      "Loss: 1.0606626272201538\n",
      "Loss: 1.2669885158538818\n",
      "Loss: 0.9567880034446716\n",
      "Loss: 1.0373464822769165\n",
      "Loss: 1.081611156463623\n",
      "Loss: 1.2690308094024658\n",
      "Loss: 1.2044498920440674\n",
      "Loss: 1.0828064680099487\n",
      "Loss: 1.239269733428955\n",
      "Loss: 1.2835984230041504\n",
      "Loss: 1.4491276741027832\n",
      "Loss: 1.2157920598983765\n",
      "Loss: 1.1405346393585205\n",
      "Loss: 1.2962173223495483\n",
      "Loss: 1.1108129024505615\n",
      "Loss: 1.1965216398239136\n",
      "Loss: 1.0642389059066772\n",
      "Loss: 1.3660964965820312\n",
      "Loss: 1.1823493242263794\n",
      "Loss: 1.016963005065918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [08:37<10:32, 57.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5144495964050293\n",
      "Training for epoch 9/20 completed.\n",
      "Loss: 1.2245491743087769\n",
      "Loss: 1.2552987337112427\n",
      "Loss: 1.198824167251587\n",
      "Loss: 0.8747392892837524\n",
      "Loss: 1.03768789768219\n",
      "Loss: 0.5882848501205444\n",
      "Loss: 1.1621941328048706\n",
      "Loss: 1.1988184452056885\n",
      "Loss: 1.0728538036346436\n",
      "Loss: 1.1622657775878906\n",
      "Loss: 0.9663501977920532\n",
      "Loss: 1.0447447299957275\n",
      "Loss: 0.8703034520149231\n",
      "Loss: 1.145530104637146\n",
      "Loss: 0.6845554709434509\n",
      "Loss: 1.2733697891235352\n",
      "Loss: 0.9908967018127441\n",
      "Loss: 0.8269729614257812\n",
      "Loss: 0.9640638828277588\n",
      "Loss: 1.0510482788085938\n",
      "Loss: 0.9717980027198792\n",
      "Loss: 0.9689153432846069\n",
      "Loss: 1.0026711225509644\n",
      "Loss: 0.9483258724212646\n",
      "Loss: 1.0367181301116943\n",
      "Loss: 1.2308608293533325\n",
      "Loss: 0.8665789365768433\n",
      "Loss: 0.8863940834999084\n",
      "Loss: 1.0916087627410889\n",
      "Loss: 1.0487347841262817\n",
      "Loss: 1.0094618797302246\n",
      "Loss: 0.9486490488052368\n",
      "Loss: 1.2387429475784302\n",
      "Loss: 1.2478731870651245\n",
      "Loss: 1.277565836906433\n",
      "Loss: 1.2094942331314087\n",
      "Loss: 1.157456636428833\n",
      "Loss: 1.0731070041656494\n",
      "Loss: 1.1994761228561401\n",
      "Loss: 1.0662482976913452\n",
      "Loss: 0.825799286365509\n",
      "Loss: 0.9942412376403809\n",
      "Loss: 0.7926753759384155\n",
      "Loss: 1.0274475812911987\n",
      "Loss: 0.9601521492004395\n",
      "Loss: 1.0864555835723877\n",
      "Loss: 1.0854274034500122\n",
      "Loss: 1.0574300289154053\n",
      "Loss: 1.1028343439102173\n",
      "Loss: 0.8868655562400818\n",
      "Loss: 1.2237656116485596\n",
      "Loss: 1.1034982204437256\n",
      "Loss: 0.9658300876617432\n",
      "Loss: 1.2869057655334473\n",
      "Loss: 1.1028952598571777\n",
      "Loss: 1.0551828145980835\n",
      "Loss: 1.3739550113677979\n",
      "Loss: 1.2321609258651733\n",
      "Loss: 1.1839399337768555\n",
      "Loss: 0.9396833777427673\n",
      "Loss: 1.216607928276062\n",
      "Loss: 0.7444252371788025\n",
      "Loss: 1.123244047164917\n",
      "Loss: 1.205989122390747\n",
      "Loss: 0.8598951697349548\n",
      "Loss: 1.2110265493392944\n",
      "Loss: 1.3216029405593872\n",
      "Loss: 1.0903096199035645\n",
      "Loss: 1.2154124975204468\n",
      "Loss: 0.7998660802841187\n",
      "Loss: 1.3600200414657593\n",
      "Loss: 1.2903668880462646\n",
      "Loss: 1.1423219442367554\n",
      "Loss: 1.1466373205184937\n",
      "Loss: 1.1660773754119873\n",
      "Loss: 1.3342821598052979\n",
      "Loss: 1.0798537731170654\n",
      "Loss: 1.1653724908828735\n",
      "Loss: 1.2745648622512817\n",
      "Loss: 1.193755030632019\n",
      "Loss: 0.7144214510917664\n",
      "Loss: 1.1511926651000977\n",
      "Loss: 1.1604748964309692\n",
      "Loss: 1.072356939315796\n",
      "Loss: 0.7697428464889526\n",
      "Loss: 0.8931583166122437\n",
      "Loss: 1.1141889095306396\n",
      "Loss: 0.931268036365509\n",
      "Loss: 0.7636733055114746\n",
      "Loss: 1.119381308555603\n",
      "Loss: 1.15835440158844\n",
      "Loss: 1.089276909828186\n",
      "Loss: 1.1474888324737549\n",
      "Loss: 0.8962401747703552\n",
      "Loss: 0.9591806530952454\n",
      "Loss: 1.0264256000518799\n",
      "Loss: 0.7403067946434021\n",
      "Loss: 0.9157367944717407\n",
      "Loss: 0.9682161808013916\n",
      "Loss: 1.1300525665283203\n",
      "Loss: 1.3311749696731567\n",
      "Loss: 1.0279693603515625\n",
      "Loss: 1.2034732103347778\n",
      "Loss: 0.9201782941818237\n",
      "Loss: 1.3053765296936035\n",
      "Loss: 0.9377642869949341\n",
      "Loss: 1.021090030670166\n",
      "Loss: 1.0380363464355469\n",
      "Loss: 1.129753589630127\n",
      "Loss: 1.3130836486816406\n",
      "Loss: 1.1747077703475952\n",
      "Loss: 1.0882747173309326\n",
      "Loss: 0.9818378686904907\n",
      "Loss: 1.285176396369934\n",
      "Loss: 1.253857135772705\n",
      "Loss: 0.9918935894966125\n",
      "Loss: 1.0871186256408691\n",
      "Loss: 1.223509430885315\n",
      "Loss: 1.0325102806091309\n",
      "Loss: 0.8102428913116455\n",
      "Loss: 1.3523783683776855\n",
      "Loss: 1.0285650491714478\n",
      "Loss: 1.1311057806015015\n",
      "Loss: 1.2734687328338623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [09:35<09:34, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1137278079986572\n",
      "Training for epoch 10/20 completed.\n",
      "Loss: 0.8735116720199585\n",
      "Loss: 0.969809353351593\n",
      "Loss: 0.766646683216095\n",
      "Loss: 1.0660628080368042\n",
      "Loss: 0.9033779501914978\n",
      "Loss: 1.1410820484161377\n",
      "Loss: 0.7732274532318115\n",
      "Loss: 0.9580475687980652\n",
      "Loss: 0.8015791177749634\n",
      "Loss: 0.9698168039321899\n",
      "Loss: 0.8904579877853394\n",
      "Loss: 0.9262308478355408\n",
      "Loss: 0.7234194874763489\n",
      "Loss: 0.9022526741027832\n",
      "Loss: 0.9537334442138672\n",
      "Loss: 0.7884479761123657\n",
      "Loss: 0.9100027680397034\n",
      "Loss: 1.0469768047332764\n",
      "Loss: 0.6260789632797241\n",
      "Loss: 1.094545602798462\n",
      "Loss: 1.0231691598892212\n",
      "Loss: 0.9903561472892761\n",
      "Loss: 0.9914488792419434\n",
      "Loss: 0.9678760170936584\n",
      "Loss: 0.8026531934738159\n",
      "Loss: 1.0027824640274048\n",
      "Loss: 1.0967947244644165\n",
      "Loss: 1.0951868295669556\n",
      "Loss: 1.0293279886245728\n",
      "Loss: 0.9095494151115417\n",
      "Loss: 0.9618173241615295\n",
      "Loss: 0.835662841796875\n",
      "Loss: 1.02528715133667\n",
      "Loss: 0.939609169960022\n",
      "Loss: 0.8960994482040405\n",
      "Loss: 1.2548985481262207\n",
      "Loss: 1.0363342761993408\n",
      "Loss: 0.9237062931060791\n",
      "Loss: 1.0097159147262573\n",
      "Loss: 1.1058176755905151\n",
      "Loss: 1.062082290649414\n",
      "Loss: 1.007863998413086\n",
      "Loss: 0.5967064499855042\n",
      "Loss: 0.9455105066299438\n",
      "Loss: 0.7637328505516052\n",
      "Loss: 0.9703492522239685\n",
      "Loss: 0.9938476085662842\n",
      "Loss: 0.6242269277572632\n",
      "Loss: 1.2703853845596313\n",
      "Loss: 0.7658209800720215\n",
      "Loss: 0.8793928027153015\n",
      "Loss: 0.9727474451065063\n",
      "Loss: 0.8683065176010132\n",
      "Loss: 0.752170979976654\n",
      "Loss: 1.0042357444763184\n",
      "Loss: 0.9544209837913513\n",
      "Loss: 0.9982781410217285\n",
      "Loss: 1.1075021028518677\n",
      "Loss: 0.9451261758804321\n",
      "Loss: 0.7515055537223816\n",
      "Loss: 0.8161324858665466\n",
      "Loss: 0.6286519169807434\n",
      "Loss: 1.0782843828201294\n",
      "Loss: 0.9232540726661682\n",
      "Loss: 1.0980300903320312\n",
      "Loss: 0.7495623230934143\n",
      "Loss: 0.8886957764625549\n",
      "Loss: 1.0111478567123413\n",
      "Loss: 1.0927026271820068\n",
      "Loss: 1.002782940864563\n",
      "Loss: 1.0543521642684937\n",
      "Loss: 1.0188400745391846\n",
      "Loss: 0.7743488550186157\n",
      "Loss: 0.9556959271430969\n",
      "Loss: 1.1516966819763184\n",
      "Loss: 0.9658999443054199\n",
      "Loss: 0.9672818779945374\n",
      "Loss: 0.683516263961792\n",
      "Loss: 1.0197832584381104\n",
      "Loss: 0.9029561877250671\n",
      "Loss: 0.9325109124183655\n",
      "Loss: 0.9798576235771179\n",
      "Loss: 0.9608622789382935\n",
      "Loss: 1.0742076635360718\n",
      "Loss: 0.8575770258903503\n",
      "Loss: 1.0131170749664307\n",
      "Loss: 1.157670259475708\n",
      "Loss: 0.9720083475112915\n",
      "Loss: 1.2073309421539307\n",
      "Loss: 0.8149823546409607\n",
      "Loss: 1.034969687461853\n",
      "Loss: 0.862579345703125\n",
      "Loss: 1.0324928760528564\n",
      "Loss: 1.1638879776000977\n",
      "Loss: 0.9921262860298157\n",
      "Loss: 0.7880346775054932\n",
      "Loss: 0.8145011067390442\n",
      "Loss: 0.9934919476509094\n",
      "Loss: 1.0144160985946655\n",
      "Loss: 1.0780339241027832\n",
      "Loss: 1.0058493614196777\n",
      "Loss: 0.8307652473449707\n",
      "Loss: 1.1729358434677124\n",
      "Loss: 0.7778497934341431\n",
      "Loss: 1.0339453220367432\n",
      "Loss: 1.1388516426086426\n",
      "Loss: 0.9614254236221313\n",
      "Loss: 0.9830067753791809\n",
      "Loss: 1.2340136766433716\n",
      "Loss: 0.9725978374481201\n",
      "Loss: 0.7939158082008362\n",
      "Loss: 0.9051436185836792\n",
      "Loss: 0.8254371285438538\n",
      "Loss: 0.9519941210746765\n",
      "Loss: 1.1325749158859253\n",
      "Loss: 1.1666713953018188\n",
      "Loss: 0.9987574219703674\n",
      "Loss: 1.0347833633422852\n",
      "Loss: 1.0234161615371704\n",
      "Loss: 0.8263912200927734\n",
      "Loss: 1.0854328870773315\n",
      "Loss: 1.0367405414581299\n",
      "Loss: 0.6375324726104736\n",
      "Loss: 0.7975779175758362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [10:31<08:35, 57.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9178515076637268\n",
      "Training for epoch 11/20 completed.\n",
      "Loss: 0.8312145471572876\n",
      "Loss: 0.980207622051239\n",
      "Loss: 0.8121345639228821\n",
      "Loss: 0.786509096622467\n",
      "Loss: 0.9155299663543701\n",
      "Loss: 1.0179243087768555\n",
      "Loss: 0.7286046743392944\n",
      "Loss: 0.6594154834747314\n",
      "Loss: 0.9426072239875793\n",
      "Loss: 0.9201928377151489\n",
      "Loss: 0.7364159226417542\n",
      "Loss: 0.8295145630836487\n",
      "Loss: 0.8715540170669556\n",
      "Loss: 0.8062383532524109\n",
      "Loss: 0.7366161942481995\n",
      "Loss: 0.9110913872718811\n",
      "Loss: 0.8512378931045532\n",
      "Loss: 0.7534313201904297\n",
      "Loss: 0.7988302707672119\n",
      "Loss: 0.9630758762359619\n",
      "Loss: 0.9426370859146118\n",
      "Loss: 0.883995532989502\n",
      "Loss: 0.9587497711181641\n",
      "Loss: 0.6680932641029358\n",
      "Loss: 0.6626421213150024\n",
      "Loss: 0.8082929253578186\n",
      "Loss: 0.9081289172172546\n",
      "Loss: 0.9040498733520508\n",
      "Loss: 0.8911315202713013\n",
      "Loss: 0.6590617895126343\n",
      "Loss: 0.7358447313308716\n",
      "Loss: 0.8455418944358826\n",
      "Loss: 0.7819992899894714\n",
      "Loss: 1.0076119899749756\n",
      "Loss: 0.8803702592849731\n",
      "Loss: 1.050864577293396\n",
      "Loss: 0.8175356388092041\n",
      "Loss: 0.8202269673347473\n",
      "Loss: 0.8211850523948669\n",
      "Loss: 0.7195674777030945\n",
      "Loss: 1.099729061126709\n",
      "Loss: 0.6641764640808105\n",
      "Loss: 0.659369170665741\n",
      "Loss: 0.7696084380149841\n",
      "Loss: 0.9389212727546692\n",
      "Loss: 0.8377562165260315\n",
      "Loss: 0.9748818278312683\n",
      "Loss: 0.8462704420089722\n",
      "Loss: 0.9284297823905945\n",
      "Loss: 0.9030683636665344\n",
      "Loss: 0.8118677735328674\n",
      "Loss: 0.93207848072052\n",
      "Loss: 1.0327258110046387\n",
      "Loss: 0.6546143293380737\n",
      "Loss: 0.9000751376152039\n",
      "Loss: 0.9108465909957886\n",
      "Loss: 0.8941632509231567\n",
      "Loss: 0.6403235197067261\n",
      "Loss: 1.0205596685409546\n",
      "Loss: 1.0234999656677246\n",
      "Loss: 0.9827151894569397\n",
      "Loss: 0.8896452784538269\n",
      "Loss: 0.7777462005615234\n",
      "Loss: 1.0186630487442017\n",
      "Loss: 0.9422953724861145\n",
      "Loss: 0.8944668769836426\n",
      "Loss: 0.8232071399688721\n",
      "Loss: 0.8460984230041504\n",
      "Loss: 0.9481348991394043\n",
      "Loss: 1.033666968345642\n",
      "Loss: 1.003770351409912\n",
      "Loss: 0.6852738261222839\n",
      "Loss: 0.5819579362869263\n",
      "Loss: 0.8863964676856995\n",
      "Loss: 0.5797644257545471\n",
      "Loss: 0.5575641989707947\n",
      "Loss: 0.8434444665908813\n",
      "Loss: 0.822506308555603\n",
      "Loss: 1.0500743389129639\n",
      "Loss: 1.007907509803772\n",
      "Loss: 0.7228385210037231\n",
      "Loss: 1.0501384735107422\n",
      "Loss: 0.8946899175643921\n",
      "Loss: 0.8496425747871399\n",
      "Loss: 1.0614430904388428\n",
      "Loss: 0.9371606707572937\n",
      "Loss: 0.8581286072731018\n",
      "Loss: 0.8706147074699402\n",
      "Loss: 0.9425443410873413\n",
      "Loss: 1.1292204856872559\n",
      "Loss: 0.8404529690742493\n",
      "Loss: 0.8022555708885193\n",
      "Loss: 0.6385074853897095\n",
      "Loss: 0.9608942270278931\n",
      "Loss: 0.9299347996711731\n",
      "Loss: 0.9398784637451172\n",
      "Loss: 0.535373330116272\n",
      "Loss: 0.9325488209724426\n",
      "Loss: 0.8983283042907715\n",
      "Loss: 0.9239768981933594\n",
      "Loss: 0.7511488795280457\n",
      "Loss: 0.83945631980896\n",
      "Loss: 0.7952476143836975\n",
      "Loss: 0.6261263489723206\n",
      "Loss: 0.74144446849823\n",
      "Loss: 0.94620281457901\n",
      "Loss: 0.9288802146911621\n",
      "Loss: 1.062086582183838\n",
      "Loss: 0.8153120279312134\n",
      "Loss: 0.9926431775093079\n",
      "Loss: 0.8134475946426392\n",
      "Loss: 0.8703707456588745\n",
      "Loss: 0.8966355323791504\n",
      "Loss: 0.9619042277336121\n",
      "Loss: 0.8745372295379639\n",
      "Loss: 0.8829673528671265\n",
      "Loss: 0.8583230972290039\n",
      "Loss: 1.062943458557129\n",
      "Loss: 1.1114078760147095\n",
      "Loss: 0.8599687814712524\n",
      "Loss: 1.0809857845306396\n",
      "Loss: 0.8210813999176025\n",
      "Loss: 0.9279200434684753\n",
      "Loss: 0.8444764018058777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [11:28<07:36, 57.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0065834522247314\n",
      "Training for epoch 12/20 completed.\n",
      "Loss: 0.5088280439376831\n",
      "Loss: 0.611611545085907\n",
      "Loss: 0.9065206050872803\n",
      "Loss: 0.7046988606452942\n",
      "Loss: 0.733473539352417\n",
      "Loss: 0.9169486165046692\n",
      "Loss: 0.8093717694282532\n",
      "Loss: 0.8161312341690063\n",
      "Loss: 0.6357094049453735\n",
      "Loss: 0.965101957321167\n",
      "Loss: 0.8318338394165039\n",
      "Loss: 0.8707458972930908\n",
      "Loss: 0.856526792049408\n",
      "Loss: 0.5536171793937683\n",
      "Loss: 0.8559227585792542\n",
      "Loss: 0.7247717380523682\n",
      "Loss: 0.8093843460083008\n",
      "Loss: 0.6051395535469055\n",
      "Loss: 0.7692160606384277\n",
      "Loss: 0.6118781566619873\n",
      "Loss: 0.63841313123703\n",
      "Loss: 0.7397124767303467\n",
      "Loss: 0.9665504693984985\n",
      "Loss: 0.890221893787384\n",
      "Loss: 0.8451602458953857\n",
      "Loss: 0.7002806067466736\n",
      "Loss: 0.6865993142127991\n",
      "Loss: 0.7694782018661499\n",
      "Loss: 0.7367793917655945\n",
      "Loss: 0.7379729747772217\n",
      "Loss: 0.893670380115509\n",
      "Loss: 0.7251977920532227\n",
      "Loss: 0.8438502550125122\n",
      "Loss: 0.7130379676818848\n",
      "Loss: 0.7018370628356934\n",
      "Loss: 0.8150073289871216\n",
      "Loss: 0.5966081023216248\n",
      "Loss: 0.9353898167610168\n",
      "Loss: 0.8320016264915466\n",
      "Loss: 0.7587334513664246\n",
      "Loss: 0.6494078636169434\n",
      "Loss: 0.8712568879127502\n",
      "Loss: 0.8704102039337158\n",
      "Loss: 0.9451202154159546\n",
      "Loss: 0.8394850492477417\n",
      "Loss: 0.8011108636856079\n",
      "Loss: 0.9240400791168213\n",
      "Loss: 0.7953387498855591\n",
      "Loss: 0.6662916541099548\n",
      "Loss: 0.7211859226226807\n",
      "Loss: 0.695068895816803\n",
      "Loss: 1.0653588771820068\n",
      "Loss: 1.0036019086837769\n",
      "Loss: 0.9188294410705566\n",
      "Loss: 0.5592988133430481\n",
      "Loss: 0.7547861933708191\n",
      "Loss: 0.7905057668685913\n",
      "Loss: 0.8814002871513367\n",
      "Loss: 0.8153281807899475\n",
      "Loss: 0.6298238635063171\n",
      "Loss: 0.7085842490196228\n",
      "Loss: 0.6709557175636292\n",
      "Loss: 0.7654647827148438\n",
      "Loss: 0.7607009410858154\n",
      "Loss: 0.7624910473823547\n",
      "Loss: 0.8285000324249268\n",
      "Loss: 0.8796414732933044\n",
      "Loss: 0.7312564849853516\n",
      "Loss: 0.8654990196228027\n",
      "Loss: 0.780405580997467\n",
      "Loss: 0.7616377472877502\n",
      "Loss: 0.7668958902359009\n",
      "Loss: 0.8892979025840759\n",
      "Loss: 0.7859167456626892\n",
      "Loss: 0.7969890832901001\n",
      "Loss: 0.7952628135681152\n",
      "Loss: 0.7050784230232239\n",
      "Loss: 1.104596734046936\n",
      "Loss: 0.7471864819526672\n",
      "Loss: 0.9391658902168274\n",
      "Loss: 0.8875344395637512\n",
      "Loss: 0.7627038359642029\n",
      "Loss: 0.8908519744873047\n",
      "Loss: 0.8697477579116821\n",
      "Loss: 0.7322473526000977\n",
      "Loss: 0.8761524558067322\n",
      "Loss: 0.7130201458930969\n",
      "Loss: 0.7804834246635437\n",
      "Loss: 1.034313440322876\n",
      "Loss: 0.6907666325569153\n",
      "Loss: 0.7730528712272644\n",
      "Loss: 0.8738070130348206\n",
      "Loss: 1.0198653936386108\n",
      "Loss: 0.7145753502845764\n",
      "Loss: 0.723131537437439\n",
      "Loss: 0.7863125801086426\n",
      "Loss: 0.7422657608985901\n",
      "Loss: 0.9626905918121338\n",
      "Loss: 0.8570291996002197\n",
      "Loss: 0.8359835743904114\n",
      "Loss: 0.619168758392334\n",
      "Loss: 0.7156052589416504\n",
      "Loss: 0.9452044367790222\n",
      "Loss: 0.9450112581253052\n",
      "Loss: 0.5903472900390625\n",
      "Loss: 0.9855890274047852\n",
      "Loss: 0.7581905722618103\n",
      "Loss: 0.5718885660171509\n",
      "Loss: 0.4924117922782898\n",
      "Loss: 0.6506907343864441\n",
      "Loss: 0.7959415912628174\n",
      "Loss: 0.8536428213119507\n",
      "Loss: 0.8126505017280579\n",
      "Loss: 0.8996129035949707\n",
      "Loss: 0.830477237701416\n",
      "Loss: 0.8451966643333435\n",
      "Loss: 0.7029173374176025\n",
      "Loss: 0.6421738266944885\n",
      "Loss: 0.7629112601280212\n",
      "Loss: 0.6870554685592651\n",
      "Loss: 0.6377292275428772\n",
      "Loss: 0.8884918689727783\n",
      "Loss: 0.5754125714302063\n",
      "Loss: 0.7820798754692078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [12:25<06:39, 57.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9462502598762512\n",
      "Training for epoch 13/20 completed.\n",
      "Loss: 0.706486701965332\n",
      "Loss: 0.646699845790863\n",
      "Loss: 0.7967525124549866\n",
      "Loss: 0.4504604935646057\n",
      "Loss: 0.4728926420211792\n",
      "Loss: 0.6845601797103882\n",
      "Loss: 0.6817191243171692\n",
      "Loss: 0.9026537537574768\n",
      "Loss: 0.7999178171157837\n",
      "Loss: 0.6506499648094177\n",
      "Loss: 0.7307261228561401\n",
      "Loss: 0.819068193435669\n",
      "Loss: 0.594143807888031\n",
      "Loss: 0.528573215007782\n",
      "Loss: 0.9359986186027527\n",
      "Loss: 0.6913900375366211\n",
      "Loss: 0.542145311832428\n",
      "Loss: 0.4886474311351776\n",
      "Loss: 0.7650473117828369\n",
      "Loss: 0.8277038931846619\n",
      "Loss: 0.8013221621513367\n",
      "Loss: 0.705682098865509\n",
      "Loss: 0.6742092967033386\n",
      "Loss: 0.772634744644165\n",
      "Loss: 0.7562857270240784\n",
      "Loss: 0.691334068775177\n",
      "Loss: 0.7007625699043274\n",
      "Loss: 0.8544331192970276\n",
      "Loss: 0.6727510690689087\n",
      "Loss: 0.736060380935669\n",
      "Loss: 0.6207637190818787\n",
      "Loss: 0.8753424882888794\n",
      "Loss: 0.6282373666763306\n",
      "Loss: 0.9247085452079773\n",
      "Loss: 0.8549631237983704\n",
      "Loss: 0.8086532354354858\n",
      "Loss: 0.6425784230232239\n",
      "Loss: 0.6352203488349915\n",
      "Loss: 0.7205033898353577\n",
      "Loss: 0.7645648717880249\n",
      "Loss: 0.6686615943908691\n",
      "Loss: 0.643950879573822\n",
      "Loss: 0.7536507844924927\n",
      "Loss: 0.7660173177719116\n",
      "Loss: 0.47041454911231995\n",
      "Loss: 0.8770514130592346\n",
      "Loss: 0.7163029313087463\n",
      "Loss: 0.6784145832061768\n",
      "Loss: 0.8119698166847229\n",
      "Loss: 0.8369699120521545\n",
      "Loss: 0.6422669291496277\n",
      "Loss: 0.6098471283912659\n",
      "Loss: 0.8357096314430237\n",
      "Loss: 0.7587127685546875\n",
      "Loss: 0.6614037156105042\n",
      "Loss: 0.7509212493896484\n",
      "Loss: 0.707963228225708\n",
      "Loss: 0.6802841424942017\n",
      "Loss: 0.6501738429069519\n",
      "Loss: 0.7973843216896057\n",
      "Loss: 0.6799390912055969\n",
      "Loss: 0.5782305002212524\n",
      "Loss: 0.8016918897628784\n",
      "Loss: 0.6792487502098083\n",
      "Loss: 0.6880056858062744\n",
      "Loss: 0.7865256667137146\n",
      "Loss: 0.46177908778190613\n",
      "Loss: 0.7652761936187744\n",
      "Loss: 0.7711129188537598\n",
      "Loss: 0.5952396392822266\n",
      "Loss: 0.6785234808921814\n",
      "Loss: 0.7714882493019104\n",
      "Loss: 0.9144822955131531\n",
      "Loss: 0.7994553446769714\n",
      "Loss: 0.5834022760391235\n",
      "Loss: 0.7788323760032654\n",
      "Loss: 0.6993491649627686\n",
      "Loss: 0.750252902507782\n",
      "Loss: 0.7651550769805908\n",
      "Loss: 0.7649959325790405\n",
      "Loss: 0.4231685698032379\n",
      "Loss: 0.8531355857849121\n",
      "Loss: 0.8220489025115967\n",
      "Loss: 0.7086229920387268\n",
      "Loss: 0.8578991293907166\n",
      "Loss: 0.6652470827102661\n",
      "Loss: 0.70303875207901\n",
      "Loss: 0.6008906364440918\n",
      "Loss: 0.5712229609489441\n",
      "Loss: 0.9038189053535461\n",
      "Loss: 0.8816462755203247\n",
      "Loss: 0.6866952180862427\n",
      "Loss: 0.641424834728241\n",
      "Loss: 0.7721430063247681\n",
      "Loss: 0.7145397663116455\n",
      "Loss: 0.7540866136550903\n",
      "Loss: 0.5540083050727844\n",
      "Loss: 0.7661203145980835\n",
      "Loss: 0.793429434299469\n",
      "Loss: 0.834293782711029\n",
      "Loss: 0.7685437798500061\n",
      "Loss: 0.6790160536766052\n",
      "Loss: 0.5863988995552063\n",
      "Loss: 0.824852705001831\n",
      "Loss: 0.8614894151687622\n",
      "Loss: 0.48344099521636963\n",
      "Loss: 0.6144291758537292\n",
      "Loss: 0.9724549055099487\n",
      "Loss: 0.7209483981132507\n",
      "Loss: 0.6370776295661926\n",
      "Loss: 0.9067553281784058\n",
      "Loss: 0.8179506063461304\n",
      "Loss: 0.5103052854537964\n",
      "Loss: 0.8523993492126465\n",
      "Loss: 0.6817370057106018\n",
      "Loss: 0.7980040311813354\n",
      "Loss: 0.8131204843521118\n",
      "Loss: 0.8489127159118652\n",
      "Loss: 0.8229246735572815\n",
      "Loss: 0.7429952025413513\n",
      "Loss: 0.6562924981117249\n",
      "Loss: 0.7703016996383667\n",
      "Loss: 0.633668839931488\n",
      "Loss: 0.690051794052124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [13:22<05:43, 57.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5702903270721436\n",
      "Training for epoch 14/20 completed.\n",
      "Loss: 0.594262957572937\n",
      "Loss: 0.4040023386478424\n",
      "Loss: 0.6184923648834229\n",
      "Loss: 0.8171519041061401\n",
      "Loss: 0.7337793707847595\n",
      "Loss: 0.7189821004867554\n",
      "Loss: 0.6124460101127625\n",
      "Loss: 0.6874768733978271\n",
      "Loss: 0.6483497619628906\n",
      "Loss: 0.6769912838935852\n",
      "Loss: 0.5473714470863342\n",
      "Loss: 0.6190892457962036\n",
      "Loss: 0.8183560967445374\n",
      "Loss: 0.662368655204773\n",
      "Loss: 0.4823402762413025\n",
      "Loss: 0.5098415613174438\n",
      "Loss: 0.7209383249282837\n",
      "Loss: 0.4367368519306183\n",
      "Loss: 0.5037466883659363\n",
      "Loss: 0.57541424036026\n",
      "Loss: 0.5377852320671082\n",
      "Loss: 0.5386519432067871\n",
      "Loss: 0.5852541327476501\n",
      "Loss: 0.6513530015945435\n",
      "Loss: 0.6986162066459656\n",
      "Loss: 0.3931148052215576\n",
      "Loss: 0.5374906659126282\n",
      "Loss: 0.49530354142189026\n",
      "Loss: 0.6746878027915955\n",
      "Loss: 0.47646480798721313\n",
      "Loss: 0.6613060235977173\n",
      "Loss: 0.6496604084968567\n",
      "Loss: 0.6649014353752136\n",
      "Loss: 0.6805303692817688\n",
      "Loss: 0.7554482817649841\n",
      "Loss: 0.5402862429618835\n",
      "Loss: 0.6348165273666382\n",
      "Loss: 0.6124373078346252\n",
      "Loss: 0.5346383452415466\n",
      "Loss: 0.7058517336845398\n",
      "Loss: 0.5608721375465393\n",
      "Loss: 0.7449651956558228\n",
      "Loss: 0.6064871549606323\n",
      "Loss: 0.6600965261459351\n",
      "Loss: 0.6893908381462097\n",
      "Loss: 0.6731224656105042\n",
      "Loss: 0.683057427406311\n",
      "Loss: 0.6014288663864136\n",
      "Loss: 0.6930360198020935\n",
      "Loss: 0.6951556205749512\n",
      "Loss: 0.6008117198944092\n",
      "Loss: 0.6328401565551758\n",
      "Loss: 0.6474112868309021\n",
      "Loss: 0.5934650301933289\n",
      "Loss: 0.7032958269119263\n",
      "Loss: 0.6183803677558899\n",
      "Loss: 0.586742103099823\n",
      "Loss: 0.5264338254928589\n",
      "Loss: 0.7323193550109863\n",
      "Loss: 0.7717024087905884\n",
      "Loss: 0.5894638299942017\n",
      "Loss: 0.7047072649002075\n",
      "Loss: 0.6870412826538086\n",
      "Loss: 0.7404844164848328\n",
      "Loss: 0.6114165782928467\n",
      "Loss: 0.6359848380088806\n",
      "Loss: 0.598057746887207\n",
      "Loss: 0.5116278529167175\n",
      "Loss: 0.6155436038970947\n",
      "Loss: 0.6888057589530945\n",
      "Loss: 0.639182984828949\n",
      "Loss: 0.7934788465499878\n",
      "Loss: 0.6913460493087769\n",
      "Loss: 0.6041861176490784\n",
      "Loss: 0.7140756249427795\n",
      "Loss: 0.45810702443122864\n",
      "Loss: 0.5972064733505249\n",
      "Loss: 0.6328809261322021\n",
      "Loss: 0.4536278247833252\n",
      "Loss: 0.7231631875038147\n",
      "Loss: 0.6257513761520386\n",
      "Loss: 0.6202520132064819\n",
      "Loss: 0.5007181167602539\n",
      "Loss: 0.636803150177002\n",
      "Loss: 0.8428387641906738\n",
      "Loss: 0.658183217048645\n",
      "Loss: 0.7541756629943848\n",
      "Loss: 0.5363476872444153\n",
      "Loss: 0.5252665877342224\n",
      "Loss: 0.48202478885650635\n",
      "Loss: 0.7536653280258179\n",
      "Loss: 0.8720677495002747\n",
      "Loss: 0.5214205384254456\n",
      "Loss: 0.7001404762268066\n",
      "Loss: 0.5553362965583801\n",
      "Loss: 0.36937999725341797\n",
      "Loss: 0.7240760326385498\n",
      "Loss: 0.6701249480247498\n",
      "Loss: 0.7792398929595947\n",
      "Loss: 0.611107587814331\n",
      "Loss: 0.6688308119773865\n",
      "Loss: 0.7530672550201416\n",
      "Loss: 0.5255650877952576\n",
      "Loss: 0.5304423570632935\n",
      "Loss: 0.6647576689720154\n",
      "Loss: 0.5822713971138\n",
      "Loss: 0.7259070873260498\n",
      "Loss: 0.729205310344696\n",
      "Loss: 0.7627361416816711\n",
      "Loss: 0.8242141604423523\n",
      "Loss: 0.6638430953025818\n",
      "Loss: 0.8873754739761353\n",
      "Loss: 0.7281115055084229\n",
      "Loss: 0.7413225769996643\n",
      "Loss: 0.6579758524894714\n",
      "Loss: 0.8802591562271118\n",
      "Loss: 0.7211480736732483\n",
      "Loss: 0.6606041193008423\n",
      "Loss: 0.641719400882721\n",
      "Loss: 0.5490598082542419\n",
      "Loss: 0.7597988843917847\n",
      "Loss: 0.6688942909240723\n",
      "Loss: 0.6949496269226074\n",
      "Loss: 0.750443160533905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [14:19<04:44, 56.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6221263408660889\n",
      "Training for epoch 15/20 completed.\n",
      "Loss: 0.5557713508605957\n",
      "Loss: 0.5769983530044556\n",
      "Loss: 0.5272520184516907\n",
      "Loss: 0.6533177495002747\n",
      "Loss: 0.7448930144309998\n",
      "Loss: 0.7013372778892517\n",
      "Loss: 0.5944256782531738\n",
      "Loss: 0.5302544832229614\n",
      "Loss: 0.5755730271339417\n",
      "Loss: 0.5118703246116638\n",
      "Loss: 0.5469719171524048\n",
      "Loss: 0.5117856860160828\n",
      "Loss: 0.6123226284980774\n",
      "Loss: 0.5674293041229248\n",
      "Loss: 0.7028522491455078\n",
      "Loss: 0.514717161655426\n",
      "Loss: 0.4598684012889862\n",
      "Loss: 0.6634965538978577\n",
      "Loss: 0.44643205404281616\n",
      "Loss: 0.6977081894874573\n",
      "Loss: 0.6162223219871521\n",
      "Loss: 0.620979905128479\n",
      "Loss: 0.64249187707901\n",
      "Loss: 0.49491333961486816\n",
      "Loss: 0.5962654948234558\n",
      "Loss: 0.7043567895889282\n",
      "Loss: 0.6753487586975098\n",
      "Loss: 0.6524402499198914\n",
      "Loss: 0.44908761978149414\n",
      "Loss: 0.5729437470436096\n",
      "Loss: 0.6004294753074646\n",
      "Loss: 0.636594295501709\n",
      "Loss: 0.5413053631782532\n",
      "Loss: 0.464236855506897\n",
      "Loss: 0.6071351766586304\n",
      "Loss: 0.5497872233390808\n",
      "Loss: 0.5573252439498901\n",
      "Loss: 0.4667416512966156\n",
      "Loss: 0.41499409079551697\n",
      "Loss: 0.5261116623878479\n",
      "Loss: 0.5600979924201965\n",
      "Loss: 0.6421663165092468\n",
      "Loss: 0.6867333054542542\n",
      "Loss: 0.5673717260360718\n",
      "Loss: 0.7085490822792053\n",
      "Loss: 0.5258114337921143\n",
      "Loss: 0.5873087644577026\n",
      "Loss: 0.6188978552818298\n",
      "Loss: 0.37280774116516113\n",
      "Loss: 0.725740373134613\n",
      "Loss: 0.5250380635261536\n",
      "Loss: 0.5390912890434265\n",
      "Loss: 0.649581253528595\n",
      "Loss: 0.6167905330657959\n",
      "Loss: 0.6161516308784485\n",
      "Loss: 0.6749850511550903\n",
      "Loss: 0.4099370539188385\n",
      "Loss: 0.5561639070510864\n",
      "Loss: 0.6239101886749268\n",
      "Loss: 0.7396339774131775\n",
      "Loss: 0.4876207113265991\n",
      "Loss: 0.43586254119873047\n",
      "Loss: 0.713729739189148\n",
      "Loss: 0.5536783337593079\n",
      "Loss: 0.6019300222396851\n",
      "Loss: 0.740099310874939\n",
      "Loss: 0.6814287304878235\n",
      "Loss: 0.6453801393508911\n",
      "Loss: 0.5755704641342163\n",
      "Loss: 0.6005026698112488\n",
      "Loss: 0.6985839605331421\n",
      "Loss: 0.6810191869735718\n",
      "Loss: 0.6080907583236694\n",
      "Loss: 0.7660031914710999\n",
      "Loss: 0.6774662137031555\n",
      "Loss: 0.47587522864341736\n",
      "Loss: 0.7093860507011414\n",
      "Loss: 0.7507814764976501\n",
      "Loss: 0.7463822364807129\n",
      "Loss: 0.6358183026313782\n",
      "Loss: 0.549360990524292\n",
      "Loss: 0.572576105594635\n",
      "Loss: 0.4907073378562927\n",
      "Loss: 0.6509873867034912\n",
      "Loss: 0.6015864610671997\n",
      "Loss: 0.6487849354743958\n",
      "Loss: 0.37904536724090576\n",
      "Loss: 0.5086686015129089\n",
      "Loss: 0.5406769514083862\n",
      "Loss: 0.628453254699707\n",
      "Loss: 0.6657653450965881\n",
      "Loss: 0.7229310274124146\n",
      "Loss: 0.6879074573516846\n",
      "Loss: 0.6981616020202637\n",
      "Loss: 0.5252241492271423\n",
      "Loss: 0.5148075222969055\n",
      "Loss: 0.6337013244628906\n",
      "Loss: 0.5170453786849976\n",
      "Loss: 0.6011607646942139\n",
      "Loss: 0.7037271857261658\n",
      "Loss: 0.6753311157226562\n",
      "Loss: 0.7499765157699585\n",
      "Loss: 0.5886437892913818\n",
      "Loss: 0.6163904666900635\n",
      "Loss: 0.6535333395004272\n",
      "Loss: 0.41392236948013306\n",
      "Loss: 0.6209826469421387\n",
      "Loss: 0.6940768361091614\n",
      "Loss: 0.6568827629089355\n",
      "Loss: 0.5118140578269958\n",
      "Loss: 0.7042248249053955\n",
      "Loss: 0.6707721948623657\n",
      "Loss: 0.6637043356895447\n",
      "Loss: 0.5889174938201904\n",
      "Loss: 0.36359724402427673\n",
      "Loss: 0.6311135292053223\n",
      "Loss: 0.541118860244751\n",
      "Loss: 0.7380049824714661\n",
      "Loss: 0.5859842300415039\n",
      "Loss: 0.7589876055717468\n",
      "Loss: 0.657335638999939\n",
      "Loss: 0.674945056438446\n",
      "Loss: 0.5701411962509155\n",
      "Loss: 0.6940027475357056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [15:16<03:47, 56.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.44602566957473755\n",
      "Training for epoch 16/20 completed.\n",
      "Loss: 0.6308956146240234\n",
      "Loss: 0.631583571434021\n",
      "Loss: 0.5479777455329895\n",
      "Loss: 0.5257661938667297\n",
      "Loss: 0.5560868382453918\n",
      "Loss: 0.5615657567977905\n",
      "Loss: 0.46143361926078796\n",
      "Loss: 0.4682648181915283\n",
      "Loss: 0.587077260017395\n",
      "Loss: 0.3758333921432495\n",
      "Loss: 0.5504461526870728\n",
      "Loss: 0.5755209922790527\n",
      "Loss: 0.3013230562210083\n",
      "Loss: 0.49715760350227356\n",
      "Loss: 0.41956186294555664\n",
      "Loss: 0.5269845724105835\n",
      "Loss: 0.6260808110237122\n",
      "Loss: 0.5577893257141113\n",
      "Loss: 0.6854280233383179\n",
      "Loss: 0.4375481903553009\n",
      "Loss: 0.5338658094406128\n",
      "Loss: 0.635415256023407\n",
      "Loss: 0.5003035664558411\n",
      "Loss: 0.33763667941093445\n",
      "Loss: 0.4663233160972595\n",
      "Loss: 0.5508321523666382\n",
      "Loss: 0.5950608253479004\n",
      "Loss: 0.5303947329521179\n",
      "Loss: 0.5516262650489807\n",
      "Loss: 0.36119017004966736\n",
      "Loss: 0.6324134469032288\n",
      "Loss: 0.5597353577613831\n",
      "Loss: 0.5755230188369751\n",
      "Loss: 0.46198445558547974\n",
      "Loss: 0.5815666317939758\n",
      "Loss: 0.503441333770752\n",
      "Loss: 0.7526502013206482\n",
      "Loss: 0.4783831834793091\n",
      "Loss: 0.4165826737880707\n",
      "Loss: 0.5605313181877136\n",
      "Loss: 0.3747006356716156\n",
      "Loss: 0.5568857789039612\n",
      "Loss: 0.4589584469795227\n",
      "Loss: 0.5054664611816406\n",
      "Loss: 0.6001996397972107\n",
      "Loss: 0.5488560795783997\n",
      "Loss: 0.49800968170166016\n",
      "Loss: 0.4495750069618225\n",
      "Loss: 0.5173551440238953\n",
      "Loss: 0.6116423606872559\n",
      "Loss: 0.5394211411476135\n",
      "Loss: 0.49399223923683167\n",
      "Loss: 0.5299370884895325\n",
      "Loss: 0.3982309103012085\n",
      "Loss: 0.5855807662010193\n",
      "Loss: 0.34729328751564026\n",
      "Loss: 0.630347490310669\n",
      "Loss: 0.4754256308078766\n",
      "Loss: 0.5711012482643127\n",
      "Loss: 0.5921539068222046\n",
      "Loss: 0.5601546168327332\n",
      "Loss: 0.581445574760437\n",
      "Loss: 0.6388031840324402\n",
      "Loss: 0.5163495540618896\n",
      "Loss: 0.5117530822753906\n",
      "Loss: 0.5473377108573914\n",
      "Loss: 0.585792601108551\n",
      "Loss: 0.5278177261352539\n",
      "Loss: 0.6470552086830139\n",
      "Loss: 0.6283215284347534\n",
      "Loss: 0.6633651256561279\n",
      "Loss: 0.5142995119094849\n",
      "Loss: 0.6291528940200806\n",
      "Loss: 0.6235411167144775\n",
      "Loss: 0.7020350098609924\n",
      "Loss: 0.49611300230026245\n",
      "Loss: 0.42787882685661316\n",
      "Loss: 0.6122509241104126\n",
      "Loss: 0.6450862884521484\n",
      "Loss: 0.5195364952087402\n",
      "Loss: 0.6620662212371826\n",
      "Loss: 0.5136058926582336\n",
      "Loss: 0.6862367391586304\n",
      "Loss: 0.6189601421356201\n",
      "Loss: 0.49676498770713806\n",
      "Loss: 0.4475085437297821\n",
      "Loss: 0.6068037152290344\n",
      "Loss: 0.6065129637718201\n",
      "Loss: 0.4614054560661316\n",
      "Loss: 0.5911613702774048\n",
      "Loss: 0.6075718998908997\n",
      "Loss: 0.5065871477127075\n",
      "Loss: 0.5291125178337097\n",
      "Loss: 0.6504427194595337\n",
      "Loss: 0.5061173439025879\n",
      "Loss: 0.5331717133522034\n",
      "Loss: 0.5460850596427917\n",
      "Loss: 0.41032880544662476\n",
      "Loss: 0.6082962155342102\n",
      "Loss: 0.46700727939605713\n",
      "Loss: 0.65884929895401\n",
      "Loss: 0.4213501513004303\n",
      "Loss: 0.5079106688499451\n",
      "Loss: 0.644486665725708\n",
      "Loss: 0.6487547755241394\n",
      "Loss: 0.7052478194236755\n",
      "Loss: 0.5857692956924438\n",
      "Loss: 0.6358142495155334\n",
      "Loss: 0.6395116448402405\n",
      "Loss: 0.5477758049964905\n",
      "Loss: 0.6522685885429382\n",
      "Loss: 0.6866590976715088\n",
      "Loss: 0.6114498972892761\n",
      "Loss: 0.5318092107772827\n",
      "Loss: 0.6190248727798462\n",
      "Loss: 0.5059577822685242\n",
      "Loss: 0.5409190654754639\n",
      "Loss: 0.4588589668273926\n",
      "Loss: 0.5491455793380737\n",
      "Loss: 0.4791870713233948\n",
      "Loss: 0.6019079089164734\n",
      "Loss: 0.38210561871528625\n",
      "Loss: 0.6302477121353149\n",
      "Loss: 0.4843836724758148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [16:13<02:51, 57.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5396349430084229\n",
      "Training for epoch 17/20 completed.\n",
      "Loss: 0.6161797642707825\n",
      "Loss: 0.4035584628582001\n",
      "Loss: 0.5075555443763733\n",
      "Loss: 0.4963674545288086\n",
      "Loss: 0.535139262676239\n",
      "Loss: 0.37108930945396423\n",
      "Loss: 0.4082365334033966\n",
      "Loss: 0.5585090517997742\n",
      "Loss: 0.5114308595657349\n",
      "Loss: 0.4842778742313385\n",
      "Loss: 0.5863111019134521\n",
      "Loss: 0.5568817257881165\n",
      "Loss: 0.34671908617019653\n",
      "Loss: 0.4977073073387146\n",
      "Loss: 0.5894880890846252\n",
      "Loss: 0.5642631649971008\n",
      "Loss: 0.4849368929862976\n",
      "Loss: 0.38924071192741394\n",
      "Loss: 0.46960899233818054\n",
      "Loss: 0.3146933615207672\n",
      "Loss: 0.4168439209461212\n",
      "Loss: 0.5116803646087646\n",
      "Loss: 0.5541884303092957\n",
      "Loss: 0.5836654901504517\n",
      "Loss: 0.5645782947540283\n",
      "Loss: 0.482900470495224\n",
      "Loss: 0.599270761013031\n",
      "Loss: 0.5166884064674377\n",
      "Loss: 0.5089482069015503\n",
      "Loss: 0.591561496257782\n",
      "Loss: 0.5199607014656067\n",
      "Loss: 0.44378146529197693\n",
      "Loss: 0.6200149059295654\n",
      "Loss: 0.4431939125061035\n",
      "Loss: 0.6219499707221985\n",
      "Loss: 0.40320703387260437\n",
      "Loss: 0.3737047016620636\n",
      "Loss: 0.4491429924964905\n",
      "Loss: 0.4530700743198395\n",
      "Loss: 0.41258570551872253\n",
      "Loss: 0.5055697560310364\n",
      "Loss: 0.5387185215950012\n",
      "Loss: 0.4686790704727173\n",
      "Loss: 0.6058025360107422\n",
      "Loss: 0.4820021688938141\n",
      "Loss: 0.5820220708847046\n",
      "Loss: 0.4479331970214844\n",
      "Loss: 0.44657090306282043\n",
      "Loss: 0.49544385075569153\n",
      "Loss: 0.5677168369293213\n",
      "Loss: 0.5493597388267517\n",
      "Loss: 0.5291781425476074\n",
      "Loss: 0.5575999021530151\n",
      "Loss: 0.29724493622779846\n",
      "Loss: 0.5385518670082092\n",
      "Loss: 0.3720603585243225\n",
      "Loss: 0.5248504281044006\n",
      "Loss: 0.5102044343948364\n",
      "Loss: 0.5767251253128052\n",
      "Loss: 0.5664412975311279\n",
      "Loss: 0.6201906800270081\n",
      "Loss: 0.3522343635559082\n",
      "Loss: 0.5690836906433105\n",
      "Loss: 0.49126937985420227\n",
      "Loss: 0.584175169467926\n",
      "Loss: 0.5395888090133667\n",
      "Loss: 0.6113765239715576\n",
      "Loss: 0.5359876155853271\n",
      "Loss: 0.5018122792243958\n",
      "Loss: 0.669489324092865\n",
      "Loss: 0.5850374698638916\n",
      "Loss: 0.3956739902496338\n",
      "Loss: 0.5723952651023865\n",
      "Loss: 0.5444612503051758\n",
      "Loss: 0.49161672592163086\n",
      "Loss: 0.4946030080318451\n",
      "Loss: 0.4669592082500458\n",
      "Loss: 0.5676267743110657\n",
      "Loss: 0.4696617126464844\n",
      "Loss: 0.520811915397644\n",
      "Loss: 0.3396206796169281\n",
      "Loss: 0.4530107378959656\n",
      "Loss: 0.5601873993873596\n",
      "Loss: 0.5352245569229126\n",
      "Loss: 0.5499194264411926\n",
      "Loss: 0.533650279045105\n",
      "Loss: 0.564109206199646\n",
      "Loss: 0.402148962020874\n",
      "Loss: 0.6237188577651978\n",
      "Loss: 0.584922194480896\n",
      "Loss: 0.47124233841896057\n",
      "Loss: 0.41433462500572205\n",
      "Loss: 0.4436260461807251\n",
      "Loss: 0.6455987095832825\n",
      "Loss: 0.654793918132782\n",
      "Loss: 0.5004358887672424\n",
      "Loss: 0.43074339628219604\n",
      "Loss: 0.40503647923469543\n",
      "Loss: 0.484032541513443\n",
      "Loss: 0.5428687930107117\n",
      "Loss: 0.3627057671546936\n",
      "Loss: 0.5748717188835144\n",
      "Loss: 0.6092807054519653\n",
      "Loss: 0.5023622512817383\n",
      "Loss: 0.6984258890151978\n",
      "Loss: 0.5330974459648132\n",
      "Loss: 0.5458978414535522\n",
      "Loss: 0.5161290168762207\n",
      "Loss: 0.5780262351036072\n",
      "Loss: 0.6002174019813538\n",
      "Loss: 0.46671804785728455\n",
      "Loss: 0.5454791188240051\n",
      "Loss: 0.5519671440124512\n",
      "Loss: 0.5800357460975647\n",
      "Loss: 0.5798827409744263\n",
      "Loss: 0.49233394861221313\n",
      "Loss: 0.503835141658783\n",
      "Loss: 0.5308047533035278\n",
      "Loss: 0.48529475927352905\n",
      "Loss: 0.6007916927337646\n",
      "Loss: 0.5034005641937256\n",
      "Loss: 0.6702480316162109\n",
      "Loss: 0.631315290927887\n",
      "Loss: 0.5023388266563416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [17:13<01:55, 57.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4487525224685669\n",
      "Training for epoch 18/20 completed.\n",
      "Loss: 0.4672106206417084\n",
      "Loss: 0.5506153702735901\n",
      "Loss: 0.3618931770324707\n",
      "Loss: 0.28554290533065796\n",
      "Loss: 0.5415396094322205\n",
      "Loss: 0.45187491178512573\n",
      "Loss: 0.5154229998588562\n",
      "Loss: 0.41303393244743347\n",
      "Loss: 0.5730336904525757\n",
      "Loss: 0.4838342070579529\n",
      "Loss: 0.49102285504341125\n",
      "Loss: 0.47674936056137085\n",
      "Loss: 0.5744675397872925\n",
      "Loss: 0.4146616458892822\n",
      "Loss: 0.5081989169120789\n",
      "Loss: 0.4972776174545288\n",
      "Loss: 0.5610988140106201\n",
      "Loss: 0.528190016746521\n",
      "Loss: 0.5436177849769592\n",
      "Loss: 0.40899458527565\n",
      "Loss: 0.47426751255989075\n",
      "Loss: 0.43283215165138245\n",
      "Loss: 0.35027503967285156\n",
      "Loss: 0.519888699054718\n",
      "Loss: 0.5689070820808411\n",
      "Loss: 0.40842950344085693\n",
      "Loss: 0.43705084919929504\n",
      "Loss: 0.4790489971637726\n",
      "Loss: 0.482715904712677\n",
      "Loss: 0.4859209954738617\n",
      "Loss: 0.4964331090450287\n",
      "Loss: 0.5019394755363464\n",
      "Loss: 0.32184457778930664\n",
      "Loss: 0.4433518350124359\n",
      "Loss: 0.4760717451572418\n",
      "Loss: 0.5729319453239441\n",
      "Loss: 0.558347761631012\n",
      "Loss: 0.523039698600769\n",
      "Loss: 0.41877174377441406\n",
      "Loss: 0.5264187455177307\n",
      "Loss: 0.4341285526752472\n",
      "Loss: 0.4682287573814392\n",
      "Loss: 0.43110963702201843\n",
      "Loss: 0.44315239787101746\n",
      "Loss: 0.5888482332229614\n",
      "Loss: 0.5388197302818298\n",
      "Loss: 0.5405009984970093\n",
      "Loss: 0.5828216075897217\n",
      "Loss: 0.38859668374061584\n",
      "Loss: 0.4951421320438385\n",
      "Loss: 0.5071168541908264\n",
      "Loss: 0.3857150673866272\n",
      "Loss: 0.5676104426383972\n",
      "Loss: 0.37065115571022034\n",
      "Loss: 0.4899713099002838\n",
      "Loss: 0.4482618570327759\n",
      "Loss: 0.3940261900424957\n",
      "Loss: 0.32479676604270935\n",
      "Loss: 0.5016406178474426\n",
      "Loss: 0.49423933029174805\n",
      "Loss: 0.5163446664810181\n",
      "Loss: 0.4367910921573639\n",
      "Loss: 0.4059116244316101\n",
      "Loss: 0.601076602935791\n",
      "Loss: 0.4504275619983673\n",
      "Loss: 0.5342100262641907\n",
      "Loss: 0.606941819190979\n",
      "Loss: 0.38553211092948914\n",
      "Loss: 0.363978773355484\n",
      "Loss: 0.5384725332260132\n",
      "Loss: 0.5805026888847351\n",
      "Loss: 0.5412178635597229\n",
      "Loss: 0.5571280717849731\n",
      "Loss: 0.400232195854187\n",
      "Loss: 0.4345412850379944\n",
      "Loss: 0.45985478162765503\n",
      "Loss: 0.46150627732276917\n",
      "Loss: 0.3968158960342407\n",
      "Loss: 0.316053181886673\n",
      "Loss: 0.5265592336654663\n",
      "Loss: 0.5472328662872314\n",
      "Loss: 0.2794155180454254\n",
      "Loss: 0.535357654094696\n",
      "Loss: 0.4751037359237671\n",
      "Loss: 0.38941362500190735\n",
      "Loss: 0.44575774669647217\n",
      "Loss: 0.38531550765037537\n",
      "Loss: 0.5400186777114868\n",
      "Loss: 0.4754759967327118\n",
      "Loss: 0.508345365524292\n",
      "Loss: 0.3955141007900238\n",
      "Loss: 0.6653376817703247\n",
      "Loss: 0.5473912358283997\n",
      "Loss: 0.5753991007804871\n",
      "Loss: 0.4957950711250305\n",
      "Loss: 0.3840814232826233\n",
      "Loss: 0.4719175398349762\n",
      "Loss: 0.5825738310813904\n",
      "Loss: 0.47840747237205505\n",
      "Loss: 0.3928057551383972\n",
      "Loss: 0.5652756690979004\n",
      "Loss: 0.5144010782241821\n",
      "Loss: 0.5248709917068481\n",
      "Loss: 0.5550893545150757\n",
      "Loss: 0.4336874783039093\n",
      "Loss: 0.48777222633361816\n",
      "Loss: 0.48317134380340576\n",
      "Loss: 0.5059332251548767\n",
      "Loss: 0.5014467239379883\n",
      "Loss: 0.5158065557479858\n",
      "Loss: 0.6299428939819336\n",
      "Loss: 0.47291529178619385\n",
      "Loss: 0.3941291272640228\n",
      "Loss: 0.48442885279655457\n",
      "Loss: 0.4509274661540985\n",
      "Loss: 0.5964900255203247\n",
      "Loss: 0.6339836716651917\n",
      "Loss: 0.5142331719398499\n",
      "Loss: 0.5277808308601379\n",
      "Loss: 0.46233728528022766\n",
      "Loss: 0.6047827005386353\n",
      "Loss: 0.46890440583229065\n",
      "Loss: 0.42225590348243713\n",
      "Loss: 0.5332657694816589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [18:09<00:57, 57.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6126670241355896\n",
      "Training for epoch 19/20 completed.\n",
      "Loss: 0.5819835066795349\n",
      "Loss: 0.3393446207046509\n",
      "Loss: 0.4014557898044586\n",
      "Loss: 0.48826828598976135\n",
      "Loss: 0.3481905162334442\n",
      "Loss: 0.5199215412139893\n",
      "Loss: 0.3674403429031372\n",
      "Loss: 0.4801744520664215\n",
      "Loss: 0.4589276909828186\n",
      "Loss: 0.40401801466941833\n",
      "Loss: 0.4250420033931732\n",
      "Loss: 0.4739600718021393\n",
      "Loss: 0.42321306467056274\n",
      "Loss: 0.4779113531112671\n",
      "Loss: 0.4708516597747803\n",
      "Loss: 0.4043266177177429\n",
      "Loss: 0.45678529143333435\n",
      "Loss: 0.3687330484390259\n",
      "Loss: 0.487093061208725\n",
      "Loss: 0.38777753710746765\n",
      "Loss: 0.45918211340904236\n",
      "Loss: 0.4636353552341461\n",
      "Loss: 0.5059917569160461\n",
      "Loss: 0.4799322485923767\n",
      "Loss: 0.4955994486808777\n",
      "Loss: 0.4503340721130371\n",
      "Loss: 0.4498043656349182\n",
      "Loss: 0.41796061396598816\n",
      "Loss: 0.4137883484363556\n",
      "Loss: 0.37119805812835693\n",
      "Loss: 0.38375282287597656\n",
      "Loss: 0.5257906913757324\n",
      "Loss: 0.2793300747871399\n",
      "Loss: 0.3580341041088104\n",
      "Loss: 0.3538447916507721\n",
      "Loss: 0.4970168471336365\n",
      "Loss: 0.4973238408565521\n",
      "Loss: 0.5422578454017639\n",
      "Loss: 0.5728247165679932\n",
      "Loss: 0.4568363428115845\n",
      "Loss: 0.4655429422855377\n",
      "Loss: 0.41805118322372437\n",
      "Loss: 0.3986613154411316\n",
      "Loss: 0.4242023229598999\n",
      "Loss: 0.4306904077529907\n",
      "Loss: 0.4805833697319031\n",
      "Loss: 0.42058926820755005\n",
      "Loss: 0.3038800060749054\n",
      "Loss: 0.5311791896820068\n",
      "Loss: 0.5645330548286438\n",
      "Loss: 0.5657634735107422\n",
      "Loss: 0.3994722068309784\n",
      "Loss: 0.4679601490497589\n",
      "Loss: 0.49736061692237854\n",
      "Loss: 0.5231390595436096\n",
      "Loss: 0.40971842408180237\n",
      "Loss: 0.3627161383628845\n",
      "Loss: 0.46256929636001587\n",
      "Loss: 0.44714921712875366\n",
      "Loss: 0.37300947308540344\n",
      "Loss: 0.4599447250366211\n",
      "Loss: 0.44181278347969055\n",
      "Loss: 0.40931597352027893\n",
      "Loss: 0.5596245527267456\n",
      "Loss: 0.45814794301986694\n",
      "Loss: 0.551138699054718\n",
      "Loss: 0.48335686326026917\n",
      "Loss: 0.5255025625228882\n",
      "Loss: 0.47335901856422424\n",
      "Loss: 0.42940324544906616\n",
      "Loss: 0.5323011875152588\n",
      "Loss: 0.5706731677055359\n",
      "Loss: 0.4656701683998108\n",
      "Loss: 0.3233652710914612\n",
      "Loss: 0.536270797252655\n",
      "Loss: 0.5282104015350342\n",
      "Loss: 0.4548534154891968\n",
      "Loss: 0.5149663090705872\n",
      "Loss: 0.6316546201705933\n",
      "Loss: 0.47921666502952576\n",
      "Loss: 0.4406853914260864\n",
      "Loss: 0.5111107230186462\n",
      "Loss: 0.49284905195236206\n",
      "Loss: 0.5018677115440369\n",
      "Loss: 0.4430343210697174\n",
      "Loss: 0.3912985622882843\n",
      "Loss: 0.502740204334259\n",
      "Loss: 0.48531574010849\n",
      "Loss: 0.45039233565330505\n",
      "Loss: 0.5259428024291992\n",
      "Loss: 0.34957653284072876\n",
      "Loss: 0.3823128640651703\n",
      "Loss: 0.5459646582603455\n",
      "Loss: 0.5339919328689575\n",
      "Loss: 0.5926873683929443\n",
      "Loss: 0.31637436151504517\n",
      "Loss: 0.517314076423645\n",
      "Loss: 0.5932877063751221\n",
      "Loss: 0.4512121379375458\n",
      "Loss: 0.4898619055747986\n",
      "Loss: 0.3860880732536316\n",
      "Loss: 0.4684700071811676\n",
      "Loss: 0.2628490924835205\n",
      "Loss: 0.32696837186813354\n",
      "Loss: 0.31259480118751526\n",
      "Loss: 0.5614705085754395\n",
      "Loss: 0.49914851784706116\n",
      "Loss: 0.5581100583076477\n",
      "Loss: 0.5244373083114624\n",
      "Loss: 0.4732425808906555\n",
      "Loss: 0.4333787262439728\n",
      "Loss: 0.3630412220954895\n",
      "Loss: 0.4952308237552643\n",
      "Loss: 0.35105636715888977\n",
      "Loss: 0.4100203216075897\n",
      "Loss: 0.4945055842399597\n",
      "Loss: 0.3601323962211609\n",
      "Loss: 0.39843156933784485\n",
      "Loss: 0.4348563253879547\n",
      "Loss: 0.5703933238983154\n",
      "Loss: 0.3051917850971222\n",
      "Loss: 0.4584728479385376\n",
      "Loss: 0.4989120364189148\n",
      "Loss: 0.4113323390483856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [19:07<00:00, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5843541622161865\n",
      "Training for epoch 20/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    print(f\"Training for epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "    # Commented out - quicker\n",
    "    #val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'image_captioning_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "plW8XdpVwzCC",
    "outputId": "89c8a971-ad5a-4387-c743-27f072321f30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_caption(image, model, vocab, device):\n",
    "\n",
    "    model.eval()\n",
    "    print(image.shape)\n",
    "    image = image.unsqueeze(0).to(device) # unsqueezing for encapsulating it inside a batch\n",
    "    print(image.shape)\n",
    "    features = model.encoder(image)\n",
    "\n",
    "    # Generate caption\n",
    "    caption = ['<bos>']\n",
    "    for _ in range(50):  # Maximum caption length\n",
    "        input_caption = torch.tensor([vocab[token] for token in caption]).unsqueeze(0).to(device)\n",
    "        outputs = model.decoder(features, input_caption)\n",
    "        _, predicted = outputs.max(2)  # outputs.shape = (batch,seq_len,vocab_size), vocab_size needed because we need to calculate each word's probabilty and pick the best of them\n",
    "        predicted_word = vocab.get_itos()[predicted[0, -1].item()] # get the first batch (only one), last predicted word in lstm(next word) convert it to string instead of an id\n",
    "        caption.append(predicted_word)\n",
    "        if predicted_word == '<eos>':\n",
    "            break\n",
    "    print(caption)\n",
    "    return ' '.join(caption[1:-1])  # Removing <bos> and <eos>\n",
    "\n",
    "# Load trained model and generate a caption\n",
    "model.load_state_dict(torch.load('image_captioning_model.pth'))\n",
    "#image = Image.open(\"path_to_image.jpg\")  # Replace with your image path\n",
    "#caption = generate_caption(image, model, train_dataset.vocab, device)\n",
    "#print(f\"Generated Caption: {caption}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6QsDeXs4wzCD"
   },
   "outputs": [],
   "source": [
    "def generate_captions_for_coco(val_loader,model,vocab, max_length= 50, num_samples=5):\n",
    "    all_captions = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, image_ids,captions) in enumerate(val_loader):\n",
    "            #image_ids = targets['image_id']\n",
    "            images = images.to(device)\n",
    "            for image_id, image in zip(image_ids,images):\n",
    "              generated_caption = generate_caption(image, model, vocab, device)\n",
    "              print(f\"type(generated_caption) = {type(generated_caption)} , {type(image_id)}\")\n",
    "              all_captions[image_id] = generated_caption\n",
    "              print(f\"Generated Caption for Image {image_id}: {generated_caption}\")\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "    print(all_captions)\n",
    "    return all_captions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JEXBUDkRwzCD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 210502: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 298396: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 187513: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'sitting', 'in', 'a', 'car', 'holding', 'a', 'dog', 'and', 'reading', 'a', 'book', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 228214: a man is sitting in a car holding a dog and reading a book .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "{179765: 'a motorcycle parked in a parking lot with a helmet on the seat .', 190236: 'a large black cat sits inside of an empty bathtub .', 331352: 'a toilet with a hello kitty seat sitting in a room .', 517069: 'a man is riding a bike down a road .', 182417: 'a computer desk with a triple monitor computer setup .', 46378: 'a dog standing up near a car parked in the street .', 93437: 'a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .', 172330: 'a motorcycle parked in a parking lot with a helmet on the seat .', 472678: 'a computer desk with a computer monitor , a keyboard and a cup of coffee .', 314251: 'a man is riding a motorcycle on a race tracks .', 223747: 'a dog with a helmet and sunglasses in the sidecar of a motorcycle .', 109976: 'a kitchen with a refrigerator a sink and a stove', 12667: 'a cat laying in a purse with a funny saying .', 482917: 'a man standing in a large mixing of food', 534605: 'a man is riding a motorcycle on a race tracks .', 289393: 'a dog standing up near a car looking ahead .', 561256: 'a man is cleaning a toilet in a bathroom .', 338325: 'a large passenger jet flying off of a runway next to a hotel .', 65485: 'a red car parked in front of a parking meter .', 226662: 'a motorcycle parked in a parking lot with a helmet on the seat .', 11511: 'a motorcycle parked in a parking lot with a helmet on the seat .', 221754: 'a car that appears to have hit a trolley', 249025: 'a black and white cat curls up in a large mixing bowl .', 255965: 'a cat laying in a purse with a funny saying .', 51598: 'a bathroom with a large mirror a sink and a bath tub', 445846: 'a kitchen with a refrigerator a sink and a stove', 192871: 'a cat laying in a purse with a funny saying .', 365642: 'a man is riding a bike down a road .', 393569: 'a bathroom with a sink and a toilet .', 116479: 'a bathroom with a sink and a toilet .', 63740: 'a kitchen with a refrigerator a sink and a stove', 570736: 'a bathroom with a sink and a toilet .', 492937: 'a motorcycle parked in a parking lot with a helmet on the seat .', 117425: 'a man with a knife and sharpener instructing a group of women .', 159977: 'a giraffe standing on a dirt floor with rocks and trees in the background', 232538: 'a large boat full of men is sitting on a cart', 177934: 'a motorcycle parked in a parking lot with a helmet on the seat .', 96549: 'a large jetliner flying over a traffic filled street .', 469192: 'a large group of sheep are grazing in a field .', 44652: 'a large jetliner flying over a traffic filled street .', 210502: 'a large boat full of men is sitting on a cart', 298396: 'a kitchen with a refrigerator a sink and a stove', 187513: 'a bathroom with a large mirror a sink and a bath tub', 552883: 'a bathroom with a large mirror a sink and a bath tub', 228214: 'a man is sitting in a car holding a dog and reading a book .'}\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "<pycocotools.coco.COCO object at 0x7f0183441c00>\n",
      "Generated Captions Image IDs: dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "Ground Truth Image IDs: [397133, 37777, 252219, 87038, 174482, 403385, 6818, 480985, 458054, 331352, 296649, 386912, 502136, 491497, 184791, 348881, 289393, 522713, 181666, 17627, 143931, 303818, 463730, 460347, 322864, 226111, 153299, 308394, 456496, 58636, 41888, 184321, 565778, 297343, 336587, 122745, 219578, 555705, 443303, 500663, 418281, 25560, 403817, 85329, 329323, 239274, 286994, 511321, 314294, 233771, 475779, 301867, 312421, 185250, 356427, 572517, 270244, 516316, 125211, 562121, 360661, 16228, 382088, 266409, 430961, 80671, 577539, 104612, 476258, 448365, 35197, 349860, 180135, 486438, 400573, 109798, 370677, 238866, 369370, 502737, 515579, 515445, 173383, 438862, 180560, 347693, 39956, 321214, 474028, 66523, 355257, 142092, 63154, 199551, 239347, 514508, 473237, 228144, 206027, 78915, 551215, 544519, 96493, 23899, 340175, 578500, 366141, 57597, 559842, 434230, 428454, 399462, 261061, 168330, 383384, 342006, 217285, 236412, 524456, 153343, 95786, 326541, 213086, 231339, 508730, 550426, 368294, 171190, 301135, 580294, 494869, 33638, 329219, 34873, 186980, 127182, 356387, 367680, 263796, 117425, 365387, 487583, 504711, 363840, 214720, 379453, 311295, 29393, 278848, 166391, 48153, 459153, 295713, 223130, 273132, 198960, 344059, 410428, 87875, 450758, 458790, 460160, 458109, 30675, 566524, 338428, 545826, 166277, 269314, 476415, 292082, 360137, 122046, 352684, 512836, 8021, 107226, 84477, 562243, 181859, 177015, 292236, 121506, 288042, 453860, 500257, 113403, 125062, 375015, 334719, 134112, 283520, 31269, 319721, 165351, 347265, 414170, 231508, 389381, 118921, 21503, 785, 300842, 105014, 261982, 34205, 99242, 314709, 460494, 339442, 541055, 409475, 464786, 378605, 331817, 218091, 578545, 363207, 372577, 212166, 172571, 294831, 84431, 323355, 355325, 100582, 555412, 4495, 9483, 326082, 398237, 507223, 31050, 239537, 340930, 11813, 281414, 537991, 284282, 321333, 521282, 108026, 243204, 177935, 38829, 397327, 501523, 555050, 376442, 187243, 356347, 293044, 560279, 42276, 534827, 190756, 482917, 300659, 199977, 442480, 384350, 383621, 189828, 412894, 537153, 361103, 392722, 338560, 264535, 295231, 154947, 212559, 458755, 104782, 315257, 130599, 227187, 151662, 461275, 523811, 456559, 101068, 140640, 516708, 544605, 385190, 338986, 53994, 61171, 314034, 291490, 152740, 24919, 79837, 21903, 564133, 337055, 110638, 34139, 80340, 83113, 173033, 255664, 72813, 545129, 546011, 121031, 172547, 369081, 509131, 578922, 464089, 453708, 177714, 459887, 155179, 261116, 396274, 29640, 141328, 308430, 43314, 273715, 456303, 406611, 475064, 466567, 137246, 15079, 296284, 226147, 226903, 127517, 162092, 131379, 366611, 263969, 551439, 474167, 159458, 554735, 99428, 386352, 173004, 311394, 578489, 189310, 491366, 448076, 293804, 312237, 221291, 141821, 410650, 199310, 323151, 89648, 219283, 471869, 520264, 111179, 151000, 100624, 332570, 57238, 502732, 135561, 8277, 173044, 168458, 512194, 370042, 189436, 533958, 117645, 221708, 202228, 403565, 211042, 492878, 441586, 547816, 306733, 530099, 312278, 97679, 564127, 251065, 3845, 138819, 205834, 348708, 166521, 485802, 99054, 22969, 570539, 278353, 158548, 461405, 176606, 44699, 559956, 268996, 11197, 483667, 448810, 724, 51961, 375278, 302165, 131131, 98839, 402992, 465675, 240754, 21167, 148730, 384468, 253742, 186873, 82180, 446522, 552902, 125405, 110211, 16010, 64462, 314182, 248980, 68387, 429281, 345466, 352900, 118367, 113235, 311303, 163640, 370999, 1490, 329456, 570471, 88269, 260470, 193494, 252776, 201072, 18150, 337498, 521405, 518770, 201646, 36936, 59044, 172946, 234607, 532690, 323895, 384670, 50326, 205542, 217957, 162035, 415727, 46252, 182021, 231747, 90284, 286553, 488736, 63602, 383386, 450686, 5060, 286523, 120420, 579655, 117908, 550322, 322844, 218362, 213224, 223747, 297578, 458992, 78266, 164602, 440475, 101762, 557501, 203317, 368940, 569917, 144798, 284623, 520301, 127987, 63740, 36494, 210032, 488270, 67180, 281179, 64359, 126226, 190923, 150265, 216739, 38048, 354829, 525155, 163314, 259571, 561679, 236166, 153529, 473015, 379800, 253835, 34071, 36861, 569565, 219271, 205647, 460841, 123131, 334006, 511599, 229858, 174004, 519764, 137576, 87470, 9769, 558114, 205776, 163257, 475678, 85478, 318080, 361551, 236784, 92839, 42296, 560266, 486479, 127955, 307658, 417465, 342971, 11760, 69106, 70158, 176634, 281447, 552371, 361919, 560256, 138115, 114871, 374369, 123213, 123321, 15278, 357742, 439854, 465836, 414385, 131556, 322724, 320664, 481390, 109916, 276434, 579635, 295316, 571313, 183127, 115898, 146358, 329542, 189752, 290163, 91406, 322352, 223959, 326248, 218439, 453722, 293625, 411817, 546964, 215259, 573094, 560011, 38576, 147729, 579307, 154425, 432898, 404923, 130586, 163057, 7511, 67406, 290179, 248752, 54593, 116208, 340697, 450303, 494427, 137294, 410880, 311180, 91654, 181796, 2431, 349184, 298396, 472046, 74058, 58029, 134096, 111951, 103585, 210273, 352584, 446651, 194875, 52017, 336309, 227478, 339870, 80666, 33707, 327601, 255749, 8762, 526392, 535578, 580757, 165039, 148719, 108440, 489842, 579818, 423229, 323828, 166287, 101420, 334555, 196759, 411665, 61418, 526751, 24021, 277020, 47828, 183716, 271997, 8532, 94336, 390555, 250282, 68409, 2299, 11051, 66038, 360960, 360097, 421455, 504589, 464522, 454750, 509735, 23034, 141671, 506656, 272566, 45728, 424551, 341719, 72795, 78959, 417285, 2157, 43816, 455555, 535306, 30504, 93353, 530052, 473118, 91779, 283113, 226130, 97278, 567640, 532493, 45550, 156643, 430056, 410456, 441286, 279541, 885, 378284, 156076, 143572, 229849, 39551, 56344, 193348, 16958, 572678, 106235, 341681, 83172, 343524, 395801, 388056, 259690, 235836, 343218, 205105, 513283, 176446, 371677, 308531, 497599, 455352, 236914, 232684, 415238, 290843, 519522, 144784, 167486, 392228, 488673, 191013, 80057, 570169, 224807, 163562, 136355, 492362, 102707, 232563, 10977, 51598, 32285, 520910, 131273, 206411, 472375, 481404, 471991, 17436, 177934, 165518, 571718, 459467, 135673, 134886, 485895, 287545, 577182, 289222, 372819, 310072, 87144, 430875, 60347, 42070, 420916, 453584, 296224, 122606, 311909, 579893, 284296, 221017, 315001, 439715, 284991, 389566, 78843, 122927, 225532, 13659, 153568, 395633, 419096, 203488, 361268, 466125, 414795, 508101, 253386, 222991, 530854, 351810, 338624, 138492, 263463, 226592, 378454, 20059, 227686, 476215, 297698, 247917, 439522, 479448, 424721, 26690, 558854, 176901, 334767, 301563, 86755, 194471, 420281, 533206, 99810, 334483, 89670, 482275, 404805, 2261, 425702, 36844, 12576, 361238, 108253, 319935, 3934, 29596, 47740, 77460, 14439, 571893, 447314, 181303, 58350, 26465, 246968, 536947, 76731, 286182, 433980, 561366, 380913, 32887, 517687, 213035, 399205, 349837, 350002, 131431, 356248, 334399, 57150, 363666, 507235, 169996, 226417, 481573, 56127, 123480, 274687, 164637, 178028, 493286, 348216, 345027, 571804, 140658, 102644, 581615, 279887, 230008, 284698, 102356, 456394, 323709, 452122, 579158, 525322, 33114, 8690, 381639, 217614, 284445, 468124, 187144, 273198, 95843, 417779, 447342, 166563, 490125, 561009, 183675, 290248, 532058, 214200, 578093, 369751, 429011, 301061, 105264, 267434, 370711, 25393, 471087, 106757, 183648, 358525, 49269, 79144, 519688, 431727, 130699, 215245, 91921, 218424, 473974, 405249, 235784, 521540, 537506, 119445, 507015, 173830, 356498, 435081, 18575, 373315, 227765, 13546, 67310, 125936, 389109, 322211, 184384, 426329, 128476, 414034, 450488, 99182, 51738, 99039, 75456, 134882, 442323, 232489, 351823, 65736, 1000, 379842, 13923, 559543, 185890, 357978, 129492, 261097, 410510, 39951, 306700, 146457, 214224, 332845, 255483, 222455, 187271, 462629, 544565, 369771, 35963, 289516, 334309, 452084, 301718, 429598, 165257, 93437, 413552, 62025, 17379, 176778, 104572, 90108, 157124, 89556, 266206, 86220, 508602, 10363, 17178, 507975, 314177, 313182, 538364, 149406, 180383, 402433, 449996, 168619, 209613, 103548, 469652, 15338, 512564, 336658, 568439, 372317, 476704, 260266, 106048, 177893, 479099, 269196, 315450, 171050, 243867, 263594, 147725, 88432, 272364, 138979, 519491, 100283, 563653, 345361, 113051, 286708, 475732, 108244, 121153, 23230, 73702, 86483, 521141, 61268, 393093, 493566, 191471, 11122, 198510, 126592, 416269, 133567, 521052, 332318, 186296, 415990, 187236, 271728, 460147, 200667, 77595, 278463, 190140, 476810, 540280, 126216, 32901, 407960, 84270, 267191, 422836, 493613, 217948, 317024, 463522, 213547, 456015, 547886, 124975, 378453, 69356, 162415, 274708, 377113, 79651, 104669, 439994, 430377, 512776, 95155, 184978, 199055, 431848, 333772, 128699, 121591, 176799, 424521, 254016, 523807, 73946, 230819, 82715, 85195, 435299, 50828, 27696, 62808, 497344, 361147, 541123, 163611, 10707, 409630, 343706, 199395, 514797, 486104, 514586, 279774, 474078, 872, 32038, 261732, 12120, 346638, 306139, 534601, 288391, 564091, 531771, 280930, 113867, 159282, 97585, 349678, 384136, 173057, 475572, 549136, 405691, 228214, 183709, 57672, 138639, 110884, 462614, 283785, 523175, 139099, 467511, 59920, 291791, 343934, 273551, 513580, 213816, 194832, 77396, 101787, 221754, 522751, 566436, 503841, 274272, 305343, 127092, 507797, 146498, 315492, 482477, 297396, 369675, 151857, 505638, 475387, 70254, 539143, 508917, 448410, 316054, 201148, 231169, 511999, 488664, 444879, 287874, 297022, 407083, 212226, 394206, 220858, 244411, 289741, 453166, 6894, 133631, 279927, 561335, 161032, 415748, 318908, 460927, 139883, 437239, 348243, 382111, 317433, 132408, 191288, 260106, 100510, 441442, 140270, 553990, 97924, 331799, 326542, 250766, 23781, 576566, 327306, 567825, 485972, 378873, 94944, 151051, 93717, 394510, 83531, 18193, 160728, 92177, 74200, 1425, 234779, 485130, 43435, 403584, 40757, 35062, 342128, 35279, 503755, 24610, 320642, 322895, 104666, 97337, 235778, 547144, 541952, 494759, 409542, 427055, 119995, 159112, 369323, 127270, 413247, 179653, 400922, 300039, 259597, 297084, 168337, 419974, 226408, 173302, 237928, 54654, 167898, 152771, 117914, 309391, 480944, 568690, 382122, 234807, 554291, 60835, 213935, 502599, 425221, 224119, 417043, 393282, 78032, 472030, 537964, 542423, 344909, 140556, 277051, 82696, 189698, 407518, 310622, 19109, 361571, 206994, 523241, 67616, 258793, 433774, 413395, 469067, 559099, 311789, 201025, 448256, 549390, 401991, 201418, 385997, 545730, 364102, 13291, 440336, 148783, 325306, 488251, 229601, 427160, 437205, 62554, 434204, 138954, 289417, 776, 470121, 309467, 473121, 327605, 451084, 22479, 243148, 249786, 581062, 185950, 44195, 499109, 478136, 451150, 148957, 251119, 107554, 449661, 364126, 384651, 354307, 483531, 170191, 201426, 179487, 445999, 91500, 405970, 290771, 426836, 557916, 99024, 305309, 311928, 384949, 196141, 136915, 533816, 522889, 548246, 37988, 555009, 418961, 325838, 527427, 74256, 154644, 17714, 474039, 153782, 21465, 84664, 286908, 381587, 461751, 308799, 466986, 239627, 229358, 61471, 170893, 465179, 466085, 567197, 498286, 437392, 153217, 206487, 565012, 563603, 394611, 211069, 455085, 282046, 542856, 12062, 360325, 427500, 15517, 375763, 213605, 270705, 544811, 436551, 389532, 39670, 429718, 563604, 162366, 496722, 124636, 551815, 78565, 116439, 492992, 107851, 274219, 105923, 325031, 166664, 166642, 143961, 304545, 212573, 225670, 575357, 186422, 319369, 26941, 252716, 64868, 205324, 447313, 172977, 560880, 449406, 491613, 48555, 61584, 244099, 460682, 481159, 28809, 50679, 10764, 537827, 329827, 161820, 116362, 500270, 308165, 125245, 544444, 378244, 90956, 313562, 258388, 273711, 358195, 3553, 253819, 278705, 187990, 51938, 188296, 45090, 396729, 347174, 341196, 439525, 329455, 302990, 262587, 117719, 127476, 499313, 309678, 113720, 107339, 468501, 511760, 361730, 427077, 203931, 555972, 69795, 577735, 325527, 465718, 285349, 322163, 346968, 229216, 563882, 199681, 313130, 294163, 176232, 407403, 562843, 483999, 58705, 216497, 323263, 506310, 248334, 400803, 422706, 7574, 542089, 53505, 500464, 78823, 527220, 178982, 332455, 408696, 144300, 7816, 152120, 308631, 517523, 5477, 15272, 391375, 442661, 69138, 104619, 432553, 548267, 315187, 76417, 196843, 138550, 244019, 439623, 343315, 46804, 340451, 480842, 436883, 546556, 459500, 98497, 338718, 228771, 50165, 158956, 311883, 270386, 240767, 100723, 431896, 129062, 442456, 79229, 188439, 151480, 46872, 219485, 532575, 489014, 289229, 281929, 257896, 203580, 493284, 28449, 179174, 393115, 370813, 442746, 236592, 116589, 369541, 122969, 381971, 236730, 396863, 576052, 344888, 51712, 480275, 282037, 476770, 220764, 493799, 312720, 568981, 461009, 143998, 546626, 563648, 532855, 38210, 563349, 311950, 10583, 250901, 74457, 190007, 177357, 185292, 493864, 102820, 51976, 381360, 304812, 333237, 74733, 258883, 55950, 175251, 467176, 368212, 190637, 300341, 445792, 239318, 47769, 1503, 284743, 65798, 312192, 154705, 192904, 132375, 384661, 341828, 282296, 322959, 546976, 52996, 522007, 423123, 570736, 45596, 232649, 70774, 172330, 123585, 455981, 193926, 192699, 560312, 44652, 498857, 575187, 319607, 302452, 201934, 58393, 353180, 423519, 461573, 516804, 441468, 277005, 484893, 32811, 130386, 417876, 173183, 89271, 56545, 221213, 534639, 560371, 42178, 106281, 570664, 412887, 131938, 540928, 563702, 445722, 115885, 496597, 237864, 389316, 21604, 267940, 255536, 455157, 486112, 259625, 103723, 530162, 273232, 292330, 266981, 184611, 513484, 17029, 163118, 547502, 90003, 6954, 128654, 459195, 481582, 227898, 188465, 411530, 191761, 542127, 386277, 148707, 130579, 451043, 434459, 552842, 447522, 190841, 38678, 34257, 161799, 350148, 87476, 490515, 445602, 37689, 400044, 210230, 468505, 551822, 80273, 193429, 530146, 69224, 120853, 256518, 517056, 187362, 21879, 252701, 398203, 518326, 463802, 96427, 189775, 376900, 301421, 494913, 509824, 186282, 68765, 359540, 427997, 340894, 425925, 174371, 28285, 168883, 207538, 376856, 51326, 391648, 377670, 349480, 328030, 372718, 368982, 356424, 496571, 30828, 512476, 232348, 365766, 445658, 552883, 492077, 383606, 561256, 357737, 354072, 289992, 209747, 365642, 104803, 410878, 27982, 149222, 48924, 341058, 140420, 466339, 459634, 488385, 566042, 520009, 362682, 357501, 98261, 396518, 65288, 207728, 410712, 298697, 106881, 290293, 474164, 356612, 435206, 106389, 300913, 416837, 49810, 63552, 565962, 112798, 217219, 61960, 565989, 410612, 382030, 477689, 258541, 268375, 423506, 510329, 139872, 308328, 339823, 55150, 89880, 82807, 323799, 104603, 312586, 352582, 250758, 166747, 12748, 79014, 279769, 60886, 8844, 108495, 438955, 421060, 7977, 489924, 231822, 15597, 528314, 401250, 72281, 111207, 129812, 336209, 558213, 492968, 23359, 63047, 377814, 426376, 364884, 132544, 327592, 108503, 243199, 567011, 483050, 121586, 292024, 302030, 104424, 563281, 325483, 324258, 277197, 532901, 46031, 189820, 195754, 315219, 559348, 276804, 427256, 434479, 208363, 87742, 486040, 206218, 482970, 326970, 478420, 411754, 369503, 802, 456662, 525286, 330554, 530457, 375078, 500716, 411938, 257169, 173091, 418062, 91615, 489339, 302760, 489091, 383443, 268831, 23666, 6213, 560474, 380706, 304560, 312340, 175387, 184762, 136715, 553094, 479912, 214205, 495054, 167540, 543528, 424776, 162858, 255917, 232538, 13348, 545594, 303908, 420472, 76416, 531036, 98392, 142472, 516143, 42628, 369442, 523194, 213593, 151657, 495146, 134722, 184400, 478286, 217400, 252332, 519338, 352491, 377882, 64495, 197528, 222863, 313454, 229221, 20571, 4134, 230362, 162543, 7108, 215072, 223955, 269316, 1818, 391290, 479596, 132931, 153669, 434548, 556158, 157138, 407002, 439290, 493442, 559160, 186042, 516871, 443844, 359833, 188592, 71877, 419408, 125472, 428111, 145665, 551780, 581206, 532481, 398742, 279730, 528399, 54605, 430286, 497628, 248400, 63965, 498807, 475191, 97994, 316404, 467315, 261535, 203864, 371749, 549674, 344621, 356432, 382743, 357888, 124442, 93261, 57725, 474344, 264968, 357430, 369757, 167353, 88345, 371699, 6771, 273712, 545100, 66886, 526256, 240250, 344614, 522638, 537802, 435205, 428867, 146155, 485844, 508370, 311081, 577932, 409358, 474786, 187513, 67213, 342295, 102331, 37670, 243495, 190236, 389812, 456292, 553776, 491090, 169076, 139871, 374052, 319534, 205282, 79188, 577862, 460967, 183104, 181816, 52007, 300155, 283318, 335800, 49259, 278749, 505565, 419882, 550939, 502229, 333956, 401862, 366199, 155291, 267169, 566282, 455872, 146363, 67534, 408120, 250619, 132796, 47585, 11699, 198489, 9448, 30494, 367082, 96960, 309938, 283412, 320632, 221693, 82986, 25139, 252216, 348488, 406570, 470952, 50149, 506279, 271471, 172935, 447465, 397351, 33104, 161781, 288762, 313783, 466256, 24567, 480936, 364557, 257624, 450100, 10995, 1993, 149770, 240023, 292446, 117744, 271402, 122962, 289059, 488166, 371042, 406129, 327701, 541664, 575081, 458663, 144984, 540962, 74646, 7784, 22705, 187734, 546717, 294162, 492110, 477805, 160556, 462643, 554838, 505789, 243034, 58655, 265518, 66706, 336053, 386134, 173371, 210520, 458768, 144333, 237316, 402473, 261888, 201775, 135670, 223789, 515266, 107087, 141597, 309495, 206135, 480021, 472678, 187249, 133087, 130826, 537053, 551350, 558558, 500477, 373353, 375493, 494188, 299720, 324818, 221155, 502910, 196754, 91619, 232646, 234757, 280325, 184338, 417085, 15497, 60823, 344268, 81594, 416991, 286503, 562207, 556765, 433374, 182805, 229997, 297830, 539962, 409198, 291619, 330396, 17115, 49761, 268729, 241677, 356261, 275392, 88265, 119452, 205333, 5529, 327780, 186929, 197658, 231527, 388903, 573258, 231097, 106266, 130613, 107094, 400082, 336356, 457559, 142238, 416343, 5193, 242060, 479953, 409211, 127530, 223182, 362716, 321790, 463174, 152686, 126137, 183391, 444142, 273760, 170474, 287347, 179642, 382009, 75612, 383842, 154358, 463918, 449579, 186345, 527215, 283717, 468965, 262227, 405279, 528578, 216296, 248616, 482487, 402334, 19742, 300233, 7818, 216419, 484978, 147205, 25394, 550714, 453302, 464476, 11149, 382734, 259640, 163258, 336232, 17207, 394328, 244833, 393569, 136772, 8211, 31817, 363875, 488075, 366884, 18737, 498709, 551794, 575205, 361142, 118515, 546829, 94326, 306136, 209222, 221281, 112634, 474881, 224200, 88848, 29397, 389684, 527616, 151516, 500613, 344611, 252294, 1353, 185472, 259854, 15751, 57149, 127135, 155341, 492284, 389451, 365745, 478474, 172648, 399764, 425390, 396580, 151938, 232244, 411953, 580197, 491757, 114049, 320743, 167128, 453001, 292155, 521259, 88485, 81766, 376278, 22892, 127263, 464872, 562443, 242724, 206838, 60770, 129054, 380203, 367818, 54931, 550471, 554328, 470779, 32735, 407298, 463542, 455267, 544052, 384666, 43581, 54592, 256868, 230983, 92053, 35682, 368684, 61333, 49759, 232692, 180101, 468577, 44877, 386879, 229111, 139684, 492905, 579970, 242934, 407868, 293200, 433515, 549738, 466416, 2153, 50638, 5001, 207585, 256407, 426253, 249180, 35326, 398377, 48564, 336628, 553731, 73533, 164363, 468233, 125572, 170595, 295797, 262631, 335954, 347335, 305609, 546219, 180751, 191845, 507081, 129113, 407614, 415194, 228436, 350833, 286907, 482719, 532129, 386457, 463037, 110359, 383676, 215723, 279145, 261161, 545407, 490413, 171298, 443498, 486046, 282912, 506454, 448448, 365655, 464824, 165713, 222458, 180011, 334521, 182441, 161128, 492282, 514376, 572462, 236845, 385205, 515025, 135872, 125072, 118594, 406417, 531495, 391144, 210708, 568814, 472298, 6763, 474170, 407943, 180296, 181969, 343803, 361180, 151962, 262938, 364166, 350488, 298251, 51309, 400794, 308793, 561889, 280779, 3501, 52591, 458325, 83540, 213255, 29675, 36539, 430973, 109992, 395903, 204329, 331604, 121673, 312489, 521509, 549055, 464358, 180878, 32570, 334530, 376206, 515350, 50943, 460333, 312552, 436315, 24144, 509699, 489764, 308587, 208423, 553669, 36678, 270474, 62355, 25424, 269121, 351331, 132329, 486573, 335081, 398652, 320706, 125129, 292488, 22623, 119516, 269866, 498463, 64574, 459272, 292060, 40471, 480122, 97022, 525083, 84241, 361621, 186632, 446574, 210855, 488592, 365207, 110042, 346703, 185802, 529966, 144003, 50896, 1761, 400367, 463199, 392933, 350023, 527960, 142585, 574425, 449909, 128051, 286849, 373705, 548780, 499768, 293071, 101780, 222235, 509008, 157098, 275791, 270297, 115118, 198915, 192716, 90155, 344816, 130566, 137727, 256195, 193162, 219440, 580418, 577976, 231831, 14888, 4795, 316015, 119828, 357941, 312213, 1675, 39769, 503823, 172877, 310862, 427649, 383921, 20333, 477288, 420230, 451090, 12280, 57027, 108864, 405972, 294855, 125952, 400815, 437351, 251572, 194506, 153229, 482800, 25057, 481413, 113354, 546823, 290833, 372307, 189078, 575500, 463283, 562197, 194940, 127494, 61658, 304180, 452784, 330818, 426203, 84492, 132703, 326462, 245311, 328117, 374083, 95707, 463842, 332351, 10092, 551804, 402615, 166165, 410496, 357903, 500565, 365385, 570456, 395701, 372466, 125778, 24027, 530470, 370375, 328430, 562581, 451435, 75393, 345397, 94157, 105455, 348012, 173008, 262682, 507893, 227044, 167122, 154718, 479126, 504074, 180792, 490936, 445846, 197870, 332901, 445675, 287291, 525600, 504580, 347544, 255718, 528524, 90208, 240049, 537355, 434247, 542776, 117525, 268000, 6040, 49060, 159684, 500423, 463647, 146825, 328683, 459396, 119038, 494634, 378139, 41635, 396205, 180487, 421757, 370478, 149568, 377368, 200961, 243075, 367195, 562561, 269113, 259097, 64499, 201676, 121242, 427655, 191614, 304291, 500478, 509014, 90891, 434297, 474854, 501005, 38118, 350388, 19221, 473406, 161879, 65350, 148662, 255912, 41990, 175535, 297427, 577864, 287959, 162732, 4765, 380711, 7278, 516318, 60102, 22935, 292908, 209530, 565597, 57232, 345385, 266892, 345252, 197022, 360393, 515828, 429761, 569059, 160666, 294783, 563267, 568584, 335658, 580410, 568710, 414676, 134322, 85911, 425227, 116068, 370270, 408774, 357816, 462031, 223738, 457884, 563470, 506707, 27620, 51610, 182202, 60449, 42889, 322968, 546475, 302882, 363188, 498747, 228981, 316666, 251824, 175443, 64084, 177489, 450202, 445834, 30213, 452793, 481386, 565045, 350122, 491071, 241319, 537812, 228942, 65485, 482100, 408112, 84752, 281693, 21839, 155451, 32941, 517069, 453841, 571943, 478862, 320554, 433243, 186637, 22755, 283037, 562448, 244379, 545219, 322829, 344029, 542625, 359937, 566758, 369812, 565563, 101022, 357060, 335177, 471023, 556498, 25181, 308391, 76625, 57244, 82085, 116825, 110784, 393226, 430073, 258911, 171611, 329447, 223188, 203639, 161875, 18770, 397303, 330790, 144932, 368961, 369037, 210388, 32861, 203546, 222299, 414261, 521231, 547519, 355240, 504635, 239857, 445439, 38825, 319184, 336265, 568213, 163951, 217753, 409424, 376307, 567740, 216516, 551660, 191580, 576031, 404249, 572620, 561958, 491130, 534041, 283268, 526197, 350679, 244181, 574520, 122672, 199442, 391722, 190648, 210915, 356505, 375469, 468245, 112298, 133244, 325347, 376093, 195842, 454067, 305317, 94185, 383339, 253433, 288430, 12639, 510095, 128748, 160864, 5586, 12670, 508312, 537270, 14038, 73326, 25386, 106563, 156292, 249129, 338905, 512929, 25986, 32334, 22371, 530836, 437898, 295809, 424162, 212453, 287714, 242287, 363784, 259830, 262440, 492937, 351362, 376284, 267903, 484760, 3661, 210502, 376365, 570782, 572956, 466835, 293245, 571264, 462756, 183500, 109900, 477441, 245102, 237984, 137950, 290592, 307074, 110282, 395575, 211674, 338191, 28993, 124798, 443969, 428562, 502336, 297681, 25593, 409268, 1268, 227399, 546659, 303863, 571008, 186624, 572303, 283038, 230450, 568147, 246454, 401446, 432468, 161609, 329319, 398810, 174231, 387148, 364297, 209972, 270883, 379533, 245915, 114884, 155571, 347456, 263860, 346232, 85665, 377239, 47819, 132622, 222317, 338901, 298738, 273642, 170278, 20247, 325991, 102805, 34452, 356968, 15956, 98633, 196442, 378515, 535253, 84031, 190853, 410934, 236308, 362520, 463527, 295138, 438907, 245320, 416885, 187585, 34417, 553221, 344795, 300276, 189451, 25228, 193674, 27972, 265777, 441491, 372349, 455937, 182162, 471893, 543581, 115870, 189475, 520871, 166478, 136600, 195918, 428280, 248631, 355610, 280918, 581317, 512330, 243344, 120572, 284764, 157767, 268378, 156278, 170099, 529568, 575970, 241602, 570834, 292997, 240940, 474095, 32817, 203389, 204186, 222118, 509260, 239041, 90631, 187745, 235252, 452891, 387387, 253002, 198928, 364322, 343496, 147338, 117374, 82846, 276720, 46497, 333697, 11615, 275727, 241297, 323751, 14380, 368038, 477623, 458702, 114907, 133778, 311392, 520531, 78420, 224093, 97230, 330369, 271116, 440171, 166768, 514979, 413689, 53624, 313588, 310980, 200252, 235241, 9378, 357459, 533493, 227482, 214753, 226883, 118209, 529105, 377486, 308545, 454798, 6614, 290081, 496954, 99053, 3255, 549167, 132116, 335427, 31093, 30785, 74860, 527695, 361506, 365521, 288862, 18519, 560178, 119911, 350405, 425906, 157601, 138241, 383337, 449603, 275058, 359677, 512985, 170613, 239717, 326174, 432085, 48396, 82765, 471756, 220584, 79031, 513524, 274460, 274066, 278973, 320696, 485071, 71451, 342186, 202445, 133418, 522156, 274411, 394559, 64523, 62692, 359219, 512657, 556193, 156924, 164883, 470173, 302107, 133969, 246308, 138856, 207306, 565877, 161642, 117197, 247806, 245173, 304396, 567886, 85089, 233370, 554002, 465129, 45229, 438774, 523100, 224051, 61108, 505169, 431140, 536343, 147518, 58539, 418696, 181542, 146667, 3156, 297147, 455716, 44590, 129756, 163746, 335529, 543043, 459757, 94751, 284725, 266082, 105912, 568290, 460379, 484404, 233727, 419201, 366178, 264335, 384513, 176037, 167902, 126107, 250205, 259382, 578236, 311190, 477118, 558421, 172856, 524742, 530466, 84650, 526706, 19924, 365098, 528980, 16598, 67315, 416256, 179392, 257566, 127660, 575243, 449432, 461036, 7088, 165500, 508586, 468632, 13774, 509656, 335450, 581781, 56288, 499031, 457262, 574823, 50331, 299355, 209757, 464144, 402118, 496409, 538458, 396200, 242946, 460929, 289938, 303893, 399296, 125257, 164969, 145597, 135604, 225405, 455301, 505451, 231879, 429623, 222735, 431693, 37740, 327617, 124659, 415741, 489611, 86582, 234366, 322944, 154339, 553664, 111036, 437110, 351096, 31296, 462576, 266768, 5600, 105335, 436617, 404678, 267537, 297353, 398905, 2532, 319696, 338304, 182611, 395180, 514914, 472623, 267670, 442009, 9772, 56350, 182417, 7386, 272416, 534605, 179765, 433204, 245448, 213445, 224724, 163155, 255965, 1532, 377723, 354753, 351559, 165336, 293474, 384616, 552612, 333069, 431876, 404568, 284279, 511076, 547383, 482585, 528977, 421834, 464251, 343976, 126110, 276024, 507667, 467776, 405306, 212800, 491867, 535156, 451308, 309484, 417249, 390826, 190753, 154004, 462904, 263966, 353051, 199236, 265816, 18491, 227491, 91495, 283070, 516601, 296634, 298994, 451714, 292415, 407825, 170670, 377635, 192964, 450559, 422886, 407650, 167572, 39785, 177539, 245651, 378116, 213422, 52507, 68286, 179214, 393056, 80932, 92091, 482319, 435208, 515077, 289960, 357238, 471789, 576654, 95862, 491464, 281409, 254516, 224337, 452515, 404922, 340015, 273493, 211120, 53909, 499266, 446005, 150930, 60899, 130465, 470773, 375430, 484351, 541634, 233238, 559513, 412362, 70739, 210299, 78748, 565776, 175364, 441247, 402346, 25096, 527750, 109055, 558073, 370818, 227511, 491213, 263474, 288062, 200839, 469192, 328959, 325114, 12667, 249025, 214192, 42102, 145620, 229747, 567432, 571857, 88218, 553511, 528862, 190676, 170545, 269942, 269682, 109441, 1584, 289586, 79034, 140583, 26926, 499775, 153632, 523782, 285788, 53529, 42888, 72852, 153527, 276707, 184324, 127624, 522940, 460229, 364587, 212072, 192607, 52565, 525247, 424545, 416758, 4395, 490470, 296657, 354547, 262048, 519208, 270402, 250127, 549930, 112626, 285, 573391, 447200, 261036, 269932, 426297, 68933, 47571, 23126, 242678, 229948, 451879, 158660, 59598, 485480, 6012, 13201, 243989, 44260, 581357, 476119, 287667, 527784, 179898, 349152, 187055, 493334, 318455, 520659, 465430, 209829, 329080, 190307, 200421, 551820, 254368, 146489, 438304, 33368, 513041, 225757, 369310, 324614, 302536, 31735, 465549, 404839, 232088, 318138, 378099, 154431, 148620, 394677, 463690, 570756, 299553, 281687, 303713, 521956, 323496, 348481, 119365, 577584, 273420, 388927, 439773, 308193, 424135, 297562, 123633, 286660, 88040, 404484, 489305, 491216, 226984, 222825, 507037, 384850, 34760, 260925, 96001, 574702, 245764, 246963, 534664, 26564, 408830, 537241, 272136, 22396, 132587, 225184, 441553, 55072, 277584, 550349, 289659, 62353, 193717, 565607, 210394, 41488, 514540, 65455, 532530, 374727, 484029, 402519, 309452, 424975, 323571, 500826, 368456, 501023, 235857, 81394, 264441, 241326, 272049, 377946, 78426, 260261, 399560, 392818, 442822, 170955, 346905, 172617, 281759, 534270, 231088, 44068, 159311, 479155, 100238, 45070, 469828, 136334, 185599, 407574, 239773, 112378, 527029, 128658, 516038, 538236, 479732, 449312, 535523, 419379, 417608, 426795, 529762, 197004, 405195, 455448, 529939, 390246, 548524, 431568, 39480, 493905, 120584, 55528, 128148, 183049, 139077, 416451, 533145, 402765, 255165, 527528, 459809, 538067, 17959, 298904, 447088, 262487, 470924, 421923, 178469, 362434, 70229, 106330, 545007, 520077, 454404, 194716, 202001, 155051, 565469, 79588, 395343, 541773, 455597, 262895, 433915, 540502, 172083, 251140, 541291, 105249, 323202, 550797, 226662, 142324, 352618, 205514, 205401, 144706, 221502, 520324, 491470, 454661, 183246, 303305, 97988, 179265, 338625, 5992, 186938, 203294, 2923, 47010, 406997, 185157, 402096, 353518, 356169, 475365, 550084, 225946, 553339, 463618, 200152, 148999, 414133, 193884, 475484, 455219, 198805, 41633, 133233, 359135, 80949, 167067, 150224, 136633, 490171, 462728, 493772, 356125, 476514, 526728, 509403, 484296, 244592, 387098, 188906, 192670, 324715, 567898, 270677, 291551, 293858, 523957, 89078, 322574, 344100, 84674, 246883, 142971, 54164, 335328, 453040, 462371, 365095, 536038, 241668, 65074, 415882, 238013, 571598, 419601, 473821, 84362, 474293, 256775, 506004, 270908, 379332, 193743, 331317, 215778, 145020, 172396, 419653, 73153, 560911, 263425, 24243, 544306, 135890, 60363, 142620, 66771, 66817, 370486, 17899, 109976, 66841, 98018, 301376, 47121, 289343, 68078, 327769, 92124, 368335, 457848, 578792, 2149, 275749, 192871, 468925, 276284, 85376, 196185, 71711, 423798, 288584, 98716, 66561, 217060, 531707, 569030, 94871, 15746, 390301, 39484, 273617, 288685, 76261, 176847, 542073, 494863, 307598, 505942, 309173, 304365, 14473, 396338, 416330, 14831, 572408, 125806, 90062, 512648, 505573, 160772, 88250, 441543, 293300, 511398, 93965, 163290, 572900, 134856, 267933, 40036, 576955, 185473, 465585, 81738, 442463, 450399, 516173, 224222, 270122, 148739, 371552, 47801, 249550, 569972, 317999, 416534, 121744, 257865, 324927, 80022, 556000, 257370, 39477, 23751, 573008, 403122, 438876, 412286, 147415, 179112, 261318, 410487, 168593, 372260, 536073, 31749, 546826, 310200, 2685, 417632, 244750, 29187, 343466, 248111, 173799, 307145, 519569, 557258, 360564, 308466, 551304, 114770, 234413, 165681, 267300, 147740, 485237, 208901, 404479, 504000, 96549, 110721, 438017, 405205, 134689, 89697, 349302, 16502, 550691, 452321, 233567, 413404, 321887, 345261, 147498, 509451, 509719, 169169, 119233, 439593, 124277, 426268, 133000, 565153, 235399, 189806, 129416, 519039, 518213, 365208, 450075, 60932, 473219, 152214, 309964, 399655, 80153, 177861, 194216, 308753, 119088, 71756, 577149, 564280, 85823, 364636, 402783, 113589, 167240, 419312, 425361, 352760, 579900, 569825, 92660, 466602, 128112, 96825, 562229, 157365, 15254, 221872, 515577, 53626, 376112, 343937, 530975, 495448, 120777, 535858, 530624, 7795, 263403, 167159, 568195, 318238, 491008, 396526, 385719, 172595, 328601, 76468, 373382, 554156, 530820, 400161, 383838, 498032, 479248, 181753, 415716, 27186, 366225, 379441, 15660, 39914, 304404, 570688, 236599, 450439, 429690, 248112, 166166, 427034, 170116, 410735, 52413, 397354, 579321, 44279, 157807, 256941, 279278, 255401, 555597, 455624, 376310, 5503, 322429, 143556, 392481, 404128, 497568, 500049, 161044, 144114, 248810, 296969, 11511, 396903, 17905, 372203, 189226, 27768, 350607, 418959, 204871, 88462, 99114, 449198, 475150, 320232, 581100, 6723, 289594, 476491, 31322, 278006, 314914, 337987, 249643, 578967, 247838, 131444, 261796, 312549, 135410, 573626, 306582, 426372, 147745, 154000, 535094, 286422, 357081, 458223, 311518, 445248, 170739, 281754, 112110, 341094, 161978, 517832, 521819, 303499, 448263, 559547, 109118, 174123, 366711, 13597, 579091, 209142, 70048, 106912, 276055, 548555, 257084, 154087, 217872, 513567, 304817, 164115, 341973, 554595, 540932, 46048, 59635, 289415, 162581, 139, 33221, 334417, 276285, 237071, 85772, 25603, 158744, 474021, 506178, 159399, 521719, 193245, 163117, 224675, 109827, 89296, 320490, 160012, 312263, 363461, 154213, 365886, 203629, 180798, 446207, 233139, 215114, 175438, 150638, 429530, 95069, 161397, 569700, 231237, 419098, 237517, 579070, 78404, 482436, 485424, 435880, 425226, 276018, 426166, 292005, 33854, 52412, 523229, 484415, 68093, 299887, 394199, 481567, 405432, 314251, 260657, 290619, 214869, 256192, 41872, 208208, 98520, 388258, 26204, 296317, 234526, 202339, 238039, 459437, 355817, 351530, 569273, 357748, 20107, 415536, 423617, 84170, 564336, 509258, 104119, 42563, 66135, 27932, 488710, 363072, 469246, 234660, 430871, 140203, 434996, 18833, 231580, 350003, 409867, 33109, 58111, 295420, 343076, 50006, 443426, 460683, 265108, 540466, 503855, 275198, 58384, 554579, 71226, 183437, 9891, 347930, 389933, 22192, 493019, 491683, 52462, 504439, 347370, 2587, 60855, 210030, 293794, 498919, 153797, 358427, 169356, 378673, 284106, 223090, 263068, 319617, 297595, 253452, 451693, 575815, 403353, 296222, 382125, 495732, 110449, 367386, 319100, 507575, 492758, 57760, 16439, 43737, 292225, 171788, 504389, 411774, 181499, 192191, 433192, 506933, 1296, 444275, 512248, 117492, 145591, 356531, 376322, 379476, 68833, 211825, 229311, 351609, 368900, 384808, 291634, 222094, 206271, 348045, 329614, 89761, 267351, 435003, 131138, 248314, 508482, 46378, 129135, 293324, 156071, 446206, 166509, 87244, 438269, 249219, 474452, 338532, 157847, 134034, 166259, 267946, 489046, 347163, 210099, 353970, 416170, 574315, 328286, 156372, 463849, 423944, 133645, 222559, 188689, 100428, 163682, 157213, 287527, 388846, 557672, 48504, 465180, 213033, 329041, 110972, 520707, 423104, 291861, 515982, 129945, 128598, 257478, 194746, 213171, 559707, 309655, 324158, 2473, 68628, 447611, 398438, 142790, 449190, 393469, 345941, 420069, 227985, 231125, 216636, 277689, 92939, 468332, 9914, 16451, 31620, 420840, 422670, 451571, 213830, 19432, 79969, 485027, 385029, 307172, 521717, 140076, 182155, 532761, 468954, 19786, 458410, 66635, 383289, 294695, 143068, 367228, 140929, 476787, 182923, 430048, 426241, 226058, 321118, 78170, 112997, 345356, 334977, 459954, 404191, 501368, 67896, 7888, 183965, 578871, 442161, 74209, 176857, 361586, 2592, 382696, 412531, 579902, 125850, 338219, 226171, 360951, 446117, 437514, 22589, 575372, 280710, 195045, 152465, 327890, 230166, 351589, 17031, 534673, 239843, 49091, 176701, 358923, 475904, 539445, 100274, 82812, 104198, 76547, 479030, 573943, 347664, 524280, 18837, 153011, 533536, 51008, 155145, 245576, 491725, 50811, 543300, 207844, 92416, 526103, 133343, 81061, 540414, 23023, 359855, 402774, 412240, 350019, 500211, 496854, 328238, 52891, 140286, 481480, 508639, 45472, 6471, 548506, 197388, 139260, 312406, 356428, 110999, 562818, 529122, 349594, 66926, 521601, 355677, 255824, 447917, 6460, 245026, 272148, 231549, 191672, 437331, 177213, 397279, 179285, 511453, 9400, 171757, 565853, 89045, 343149, 218997, 377393, 60507, 548339, 473869, 74092, 390902, 513688, 414340, 20553, 465822, 530061, 36660, 285047, 215644, 14007, 537672, 76211, 242411, 376478, 80413, 218249, 122166, 543047, 66231, 122217, 447169, 129322, 507473, 565391, 229659, 545958, 524850, 116479, 457078, 131386, 469174, 288882, 115946, 436738, 226802, 291664, 340272, 397639, 566923, 148508, 404601, 326627, 440508, 396568, 79408, 286507, 23937, 261706, 350054, 297085, 570448, 416104, 287649, 347254, 458255, 29984, 535608, 389315, 440507, 178618, 471450, 555005, 289702, 501243, 424642, 331280, 193181, 398028, 236721, 303566, 253695, 377588, 346707, 342397, 164885, 431545, 516677, 387916, 251537, 146831, 20992, 439426, 414638, 459662, 523033, 214703, 482735, 140987, 42528, 353027, 137106, 47112, 32081, 177065, 516916, 151629, 453341, 171740, 296231, 374545, 511647, 263679, 224664, 414673, 39405, 32610, 433103, 529528, 376264, 101884, 370900, 528705, 50844, 174018, 9590, 18380, 16249, 281032, 199771, 294350, 293390, 414510, 416745, 197796, 136033, 55002, 454978, 389804, 371529, 555012, 423971, 35770, 266400, 38070, 427338, 102411, 321557, 270066, 524108, 499622, 342367, 338325, 456865, 254814, 306893, 359781, 152870, 55167, 284762, 162130, 377575, 5037, 147223, 269632, 333402, 497867, 133819, 395388, 2006, 55299, 118405, 482978, 200162, 135902, 155443, 572555, 60090, 95899, 177383, 220732, 574810, 178744, 206025, 502168, 60052, 94852, 442306, 145781, 233033, 295478, 115245, 286458, 511384, 532071, 54123, 299609, 80659, 303653, 451144, 386210, 85682, 465806, 166426, 13004, 216277, 343453, 149375, 397681, 304984, 7991, 196009, 157390, 165831, 438226, 561465, 393014, 46463, 119677, 313034, 255747, 561223, 563758, 206579, 451155, 150417, 263644, 88970, 98853, 31217, 194724, 19402, 109313, 539883, 233825, 31248, 236426, 577959, 140840, 86956, 356094, 374982, 161861, 276921, 121497, 355169, 73118, 424349, 159791, 189213, 282298, 31118, 318114, 157756, 557884, 314264, 161008, 569976, 331569, 243626, 368752, 333745, 370208, 55022, 557172, 85576, 192047, 466156, 111086, 564023, 69213, 292456, 453634, 155154, 13177, 37751, 531134, 502347, 159977, 88951, 429109, 320425, 471567, 235057, 150726, 334371, 271457, 8899, 212895, 285894, 54967, 128372, 301981, 404534, 79565, 374551, 499181, 93154, 100489, 447789, 14226, 475223, 149622, 180188, 440617, 376625, 15440, 433134, 478393, 387383, 205289, 522393, 80274, 520832, 250137, 82821, 248284, 158945, 210789, 230993, 121417, 341469, 206831, 453981, 519611, 235064, 308476, 305695, 185409, 104455, 401244, 331075, 355905, 328337, 377497, 7281, 50380, 439180, 513181, 371472, 280891, 54628, 157928, 203095, 17182, 150649, 562059, 407524, 306437, 116206, 393838, 229553, 171382, 94614, 172649, 252507, 326128, 214539, 51314, 556873, 417911, 81988, 554266, 8629, 161925, 64898, 547854, 33005, 388215, 111609, 64718, 546325, 82688, 367569, 209753, 531135, 447187, 311002, 458045, 246436, 440184, 85157, 256916, 504415, 246522, 446703, 367095, 529148, 480212, 442993, 71938, 136466, 28452, 581482, 217425, 140439, 151820, 260105, 127394, 238410, 166918, 290768, 357567, 237118, 343561, 195165, 23272, 464689, 360943, 410221, 245513, 445365, 59386, 279714, 507042, 314541, 341921, 186449, 547336, 226154, 394275, 229753, 261712, 19042, 534394, 322610, 263299, 236690, 252559, 50145, 467848, 572388, 272212, 377000, 198641, 181421, 477227, 119641, 40083, 244496, 565624, 549220, 442836, 428218, 574297, 61747, 553788, 153510, 456143, 157418, 345469, 533855, 389197, 422998, 632, 477955, 128675, 402720, 179141, 353096, 13729, 391140, 157046, 384527, 478721, 33759, 98287, 158227, 407646, 220310, 512403, 168974, 552775, 394940, 15335]\n",
      "gts.keys():  dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "coco_results.keys():  dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 2696 tokens at 39480.90 tokens per second.\n",
      "PTBTokenizer tokenized 576 tokens at 10368.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 498, 'reflen': 469, 'guess': [498, 453, 408, 363], 'correct': [227, 71, 14, 6]}\n",
      "ratio: 1.0618336886970963\n",
      "Bleu_1: 0.456\n",
      "Bleu_2: 0.267\n",
      "Bleu_3: 0.135\n",
      "Bleu_4: 0.080\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [1.347 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.512 s\n",
      "SPICE: 0.056\n",
      "Evaluation Metrics: {'Bleu_1': 0.45582329317177545, 'Bleu_2': 0.26728730404406575, 'Bleu_3': 0.13483671952061507, 'Bleu_4': 0.07978427257672112, 'METEOR': 0.13071145719065927, 'ROUGE_L': 0.34994471888266043, 'CIDEr': 0.2622720325163794, 'SPICE': 0.05623738523704123}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_captioning_model(generated_captions, coco_annotation_file=val_annotations_path,coco_image_dir=val_images_path):\n",
    "    \"\"\"\n",
    "    Evaluate the image captioning model using COCO evaluation metrics: BLEU, METEOR, ROUGE, CIDEr.\n",
    "\n",
    "    Parameters:\n",
    "        generated_captions (dict): Dictionary of generated captions with image_ids as keys.\n",
    "        coco_annotation_file (str): Path to COCO annotations file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing BLEU, METEOR, ROUGE, CIDEr scores.\n",
    "    \"\"\"\n",
    "    # Load the COCO dataset annotations (reference captions)\n",
    "    coco = COCO(coco_annotation_file)\n",
    "\n",
    "    # Create a dictionary for the generated captions (image_id -> caption)\n",
    "    coco_results = [{'image_id': image_id, 'caption': caption} for image_id, caption in generated_captions.items()]\n",
    "\n",
    "\n",
    "    # Save the generated captions in a temporary file\n",
    "    with open('generated_captions.json', 'w') as f:\n",
    "        json.dump(coco_results, f)\n",
    "\n",
    "    # Load the results into COCO's evaluation API\n",
    "    coco_results = coco.loadRes('generated_captions.json')\n",
    "    print(coco_results)\n",
    "    print(\"Generated Captions Image IDs:\", generated_captions.keys())\n",
    "    print(\"Ground Truth Image IDs:\", coco.getImgIds())\n",
    "\n",
    "\n",
    "    # since we filtered the images to contain only first 1000 images, lets filter the metric\n",
    "    all_image_ids = coco.getImgIds()\n",
    "    filtered_image_ids = [image_id for image_id in generated_captions.keys()]\n",
    "\n",
    "    # we need to revise the filtered version of the actual annotations\n",
    "    gts = {}\n",
    "    for image_id in filtered_image_ids:\n",
    "        caption_ids = coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = coco.loadAnns(caption_ids)\n",
    "        gts[image_id] = [annotation['caption'] for annotation in annotations]\n",
    "\n",
    "\n",
    "    # Set up the evaluation\n",
    "    print(\"gts.keys(): \",gts.keys())\n",
    "    print(\"coco_results.keys(): \", generated_captions.keys())\n",
    "    #assert(gts.keys() == coco_results.keys())\n",
    "\n",
    "    coco_eval = COCOEvalCap(coco, coco_results)\n",
    "    coco_eval.params['image_id'] = filtered_image_ids\n",
    "    coco_eval.evaluate()\n",
    "\n",
    "    # Extract and return the metrics (BLEU, METEOR, ROUGE, CIDEr)\n",
    "    metrics = coco_eval.eval\n",
    "    return metrics\n",
    "\n",
    "generated_captions = generate_captions_for_coco(val_loader,model,vocabulary)\n",
    "# Evaluate the generated captions\n",
    "metrics = evaluate_captioning_model(generated_captions)\n",
    "\n",
    "\n",
    "print(\"Evaluation Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'toilet', 'with', 'a', 'hello', 'kitty', 'seat', 'sitting', 'in', 'a', 'room', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 331352: a toilet with a hello kitty seat sitting in a room .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 517069: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'black', 'cat', 'sits', 'inside', 'of', 'an', 'empty', 'bathtub', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 190236: a large black cat sits inside of an empty bathtub .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 179765: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 534605: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 12667: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'with', 'a', 'helmet', 'and', 'sunglasses', 'in', 'the', 'sidecar', 'of', 'a', 'motorcycle', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 223747: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 109976: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'triple', 'monitor', 'computer', 'setup', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 182417: a computer desk with a triple monitor computer setup .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 172330: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'standing', 'in', 'a', 'large', 'mixing', 'of', 'food', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 482917: a man standing in a large mixing of food\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'passenger', 'jet', 'flying', 'off', 'of', 'a', 'runway', 'next', 'to', 'a', 'hotel', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 338325: a large passenger jet flying off of a runway next to a hotel .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 226662: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'woman', 'in', 'a', 'red', 'flowered', 'shawl', 'sits', 'at', 'a', 'table', 'while', 'a', 'man', 'wearing', 'jeans', 'is', 'in', 'the', 'kitchen', 'looking', 'at', 'her', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 93437: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'parked', 'in', 'the', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 46378: a dog standing up near a car parked in the street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'computer', 'desk', 'with', 'a', 'computer', 'monitor', ',', 'a', 'keyboard', 'and', 'a', 'cup', 'of', 'coffee', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 472678: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'dog', 'standing', 'up', 'near', 'a', 'car', 'looking', 'ahead', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 289393: a dog standing up near a car looking ahead .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 255965: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'red', 'car', 'parked', 'in', 'front', 'of', 'a', 'parking', 'meter', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 65485: a red car parked in front of a parking meter .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'bike', 'down', 'a', 'road', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 365642: a man is riding a bike down a road .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'cleaning', 'a', 'toilet', 'in', 'a', 'bathroom', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 561256: a man is cleaning a toilet in a bathroom .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 51598: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 11511: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'riding', 'a', 'motorcycle', 'on', 'a', 'race', 'tracks', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 314251: a man is riding a motorcycle on a race tracks .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 393569: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'cat', 'laying', 'in', 'a', 'purse', 'with', 'a', 'funny', 'saying', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 192871: a cat laying in a purse with a funny saying .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'black', 'and', 'white', 'cat', 'curls', 'up', 'in', 'a', 'large', 'mixing', 'bowl', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 249025: a black and white cat curls up in a large mixing bowl .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 63740: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 492937: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'giraffe', 'standing', 'on', 'a', 'dirt', 'floor', 'with', 'rocks', 'and', 'trees', 'in', 'the', 'background', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 159977: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 445846: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'with', 'a', 'knife', 'and', 'sharpener', 'instructing', 'a', 'group', 'of', 'women', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 117425: a man with a knife and sharpener instructing a group of women .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'motorcycle', 'parked', 'in', 'a', 'parking', 'lot', 'with', 'a', 'helmet', 'on', 'the', 'seat', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 177934: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 210502: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'kitchen', 'with', 'a', 'refrigerator', 'a', 'sink', 'and', 'a', 'stove', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 298396: a kitchen with a refrigerator a sink and a stove\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 187513: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'boat', 'full', 'of', 'men', 'is', 'sitting', 'on', 'a', 'cart', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 232538: a large boat full of men is sitting on a cart\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'group', 'of', 'sheep', 'are', 'grazing', 'in', 'a', 'field', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 469192: a large group of sheep are grazing in a field .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 96549: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'large', 'jetliner', 'flying', 'over', 'a', 'traffic', 'filled', 'street', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 44652: a large jetliner flying over a traffic filled street .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 570736: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'sink', 'and', 'a', 'toilet', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 116479: a bathroom with a sink and a toilet .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'man', 'is', 'sitting', 'in', 'a', 'car', 'holding', 'a', 'dog', 'and', 'reading', 'a', 'book', '.', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 228214: a man is sitting in a car holding a dog and reading a book .\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'bathroom', 'with', 'a', 'large', 'mirror', 'a', 'sink', 'and', 'a', 'bath', 'tub', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 552883: a bathroom with a large mirror a sink and a bath tub\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "['<bos>', 'a', 'car', 'that', 'appears', 'to', 'have', 'hit', 'a', 'trolley', '<eos>']\n",
      "type(generated_caption) = <class 'str'> , <class 'int'>\n",
      "Generated Caption for Image 221754: a car that appears to have hit a trolley\n",
      "{179765: 'a motorcycle parked in a parking lot with a helmet on the seat .', 190236: 'a large black cat sits inside of an empty bathtub .', 331352: 'a toilet with a hello kitty seat sitting in a room .', 517069: 'a man is riding a bike down a road .', 182417: 'a computer desk with a triple monitor computer setup .', 46378: 'a dog standing up near a car parked in the street .', 93437: 'a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .', 172330: 'a motorcycle parked in a parking lot with a helmet on the seat .', 472678: 'a computer desk with a computer monitor , a keyboard and a cup of coffee .', 314251: 'a man is riding a motorcycle on a race tracks .', 223747: 'a dog with a helmet and sunglasses in the sidecar of a motorcycle .', 109976: 'a kitchen with a refrigerator a sink and a stove', 12667: 'a cat laying in a purse with a funny saying .', 482917: 'a man standing in a large mixing of food', 534605: 'a man is riding a motorcycle on a race tracks .', 289393: 'a dog standing up near a car looking ahead .', 561256: 'a man is cleaning a toilet in a bathroom .', 338325: 'a large passenger jet flying off of a runway next to a hotel .', 65485: 'a red car parked in front of a parking meter .', 226662: 'a motorcycle parked in a parking lot with a helmet on the seat .', 11511: 'a motorcycle parked in a parking lot with a helmet on the seat .', 221754: 'a car that appears to have hit a trolley', 249025: 'a black and white cat curls up in a large mixing bowl .', 255965: 'a cat laying in a purse with a funny saying .', 51598: 'a bathroom with a large mirror a sink and a bath tub', 445846: 'a kitchen with a refrigerator a sink and a stove', 192871: 'a cat laying in a purse with a funny saying .', 365642: 'a man is riding a bike down a road .', 393569: 'a bathroom with a sink and a toilet .', 116479: 'a bathroom with a sink and a toilet .', 63740: 'a kitchen with a refrigerator a sink and a stove', 570736: 'a bathroom with a sink and a toilet .', 492937: 'a motorcycle parked in a parking lot with a helmet on the seat .', 117425: 'a man with a knife and sharpener instructing a group of women .', 159977: 'a giraffe standing on a dirt floor with rocks and trees in the background', 232538: 'a large boat full of men is sitting on a cart', 177934: 'a motorcycle parked in a parking lot with a helmet on the seat .', 96549: 'a large jetliner flying over a traffic filled street .', 469192: 'a large group of sheep are grazing in a field .', 44652: 'a large jetliner flying over a traffic filled street .', 210502: 'a large boat full of men is sitting on a cart', 298396: 'a kitchen with a refrigerator a sink and a stove', 187513: 'a bathroom with a large mirror a sink and a bath tub', 552883: 'a bathroom with a large mirror a sink and a bath tub', 228214: 'a man is sitting in a car holding a dog and reading a book .'}\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "<pycocotools.coco.COCO object at 0x7f013ef5d4b0>\n",
      "Generated Captions Image IDs: dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "Ground Truth Image IDs: [397133, 37777, 252219, 87038, 174482, 403385, 6818, 480985, 458054, 331352, 296649, 386912, 502136, 491497, 184791, 348881, 289393, 522713, 181666, 17627, 143931, 303818, 463730, 460347, 322864, 226111, 153299, 308394, 456496, 58636, 41888, 184321, 565778, 297343, 336587, 122745, 219578, 555705, 443303, 500663, 418281, 25560, 403817, 85329, 329323, 239274, 286994, 511321, 314294, 233771, 475779, 301867, 312421, 185250, 356427, 572517, 270244, 516316, 125211, 562121, 360661, 16228, 382088, 266409, 430961, 80671, 577539, 104612, 476258, 448365, 35197, 349860, 180135, 486438, 400573, 109798, 370677, 238866, 369370, 502737, 515579, 515445, 173383, 438862, 180560, 347693, 39956, 321214, 474028, 66523, 355257, 142092, 63154, 199551, 239347, 514508, 473237, 228144, 206027, 78915, 551215, 544519, 96493, 23899, 340175, 578500, 366141, 57597, 559842, 434230, 428454, 399462, 261061, 168330, 383384, 342006, 217285, 236412, 524456, 153343, 95786, 326541, 213086, 231339, 508730, 550426, 368294, 171190, 301135, 580294, 494869, 33638, 329219, 34873, 186980, 127182, 356387, 367680, 263796, 117425, 365387, 487583, 504711, 363840, 214720, 379453, 311295, 29393, 278848, 166391, 48153, 459153, 295713, 223130, 273132, 198960, 344059, 410428, 87875, 450758, 458790, 460160, 458109, 30675, 566524, 338428, 545826, 166277, 269314, 476415, 292082, 360137, 122046, 352684, 512836, 8021, 107226, 84477, 562243, 181859, 177015, 292236, 121506, 288042, 453860, 500257, 113403, 125062, 375015, 334719, 134112, 283520, 31269, 319721, 165351, 347265, 414170, 231508, 389381, 118921, 21503, 785, 300842, 105014, 261982, 34205, 99242, 314709, 460494, 339442, 541055, 409475, 464786, 378605, 331817, 218091, 578545, 363207, 372577, 212166, 172571, 294831, 84431, 323355, 355325, 100582, 555412, 4495, 9483, 326082, 398237, 507223, 31050, 239537, 340930, 11813, 281414, 537991, 284282, 321333, 521282, 108026, 243204, 177935, 38829, 397327, 501523, 555050, 376442, 187243, 356347, 293044, 560279, 42276, 534827, 190756, 482917, 300659, 199977, 442480, 384350, 383621, 189828, 412894, 537153, 361103, 392722, 338560, 264535, 295231, 154947, 212559, 458755, 104782, 315257, 130599, 227187, 151662, 461275, 523811, 456559, 101068, 140640, 516708, 544605, 385190, 338986, 53994, 61171, 314034, 291490, 152740, 24919, 79837, 21903, 564133, 337055, 110638, 34139, 80340, 83113, 173033, 255664, 72813, 545129, 546011, 121031, 172547, 369081, 509131, 578922, 464089, 453708, 177714, 459887, 155179, 261116, 396274, 29640, 141328, 308430, 43314, 273715, 456303, 406611, 475064, 466567, 137246, 15079, 296284, 226147, 226903, 127517, 162092, 131379, 366611, 263969, 551439, 474167, 159458, 554735, 99428, 386352, 173004, 311394, 578489, 189310, 491366, 448076, 293804, 312237, 221291, 141821, 410650, 199310, 323151, 89648, 219283, 471869, 520264, 111179, 151000, 100624, 332570, 57238, 502732, 135561, 8277, 173044, 168458, 512194, 370042, 189436, 533958, 117645, 221708, 202228, 403565, 211042, 492878, 441586, 547816, 306733, 530099, 312278, 97679, 564127, 251065, 3845, 138819, 205834, 348708, 166521, 485802, 99054, 22969, 570539, 278353, 158548, 461405, 176606, 44699, 559956, 268996, 11197, 483667, 448810, 724, 51961, 375278, 302165, 131131, 98839, 402992, 465675, 240754, 21167, 148730, 384468, 253742, 186873, 82180, 446522, 552902, 125405, 110211, 16010, 64462, 314182, 248980, 68387, 429281, 345466, 352900, 118367, 113235, 311303, 163640, 370999, 1490, 329456, 570471, 88269, 260470, 193494, 252776, 201072, 18150, 337498, 521405, 518770, 201646, 36936, 59044, 172946, 234607, 532690, 323895, 384670, 50326, 205542, 217957, 162035, 415727, 46252, 182021, 231747, 90284, 286553, 488736, 63602, 383386, 450686, 5060, 286523, 120420, 579655, 117908, 550322, 322844, 218362, 213224, 223747, 297578, 458992, 78266, 164602, 440475, 101762, 557501, 203317, 368940, 569917, 144798, 284623, 520301, 127987, 63740, 36494, 210032, 488270, 67180, 281179, 64359, 126226, 190923, 150265, 216739, 38048, 354829, 525155, 163314, 259571, 561679, 236166, 153529, 473015, 379800, 253835, 34071, 36861, 569565, 219271, 205647, 460841, 123131, 334006, 511599, 229858, 174004, 519764, 137576, 87470, 9769, 558114, 205776, 163257, 475678, 85478, 318080, 361551, 236784, 92839, 42296, 560266, 486479, 127955, 307658, 417465, 342971, 11760, 69106, 70158, 176634, 281447, 552371, 361919, 560256, 138115, 114871, 374369, 123213, 123321, 15278, 357742, 439854, 465836, 414385, 131556, 322724, 320664, 481390, 109916, 276434, 579635, 295316, 571313, 183127, 115898, 146358, 329542, 189752, 290163, 91406, 322352, 223959, 326248, 218439, 453722, 293625, 411817, 546964, 215259, 573094, 560011, 38576, 147729, 579307, 154425, 432898, 404923, 130586, 163057, 7511, 67406, 290179, 248752, 54593, 116208, 340697, 450303, 494427, 137294, 410880, 311180, 91654, 181796, 2431, 349184, 298396, 472046, 74058, 58029, 134096, 111951, 103585, 210273, 352584, 446651, 194875, 52017, 336309, 227478, 339870, 80666, 33707, 327601, 255749, 8762, 526392, 535578, 580757, 165039, 148719, 108440, 489842, 579818, 423229, 323828, 166287, 101420, 334555, 196759, 411665, 61418, 526751, 24021, 277020, 47828, 183716, 271997, 8532, 94336, 390555, 250282, 68409, 2299, 11051, 66038, 360960, 360097, 421455, 504589, 464522, 454750, 509735, 23034, 141671, 506656, 272566, 45728, 424551, 341719, 72795, 78959, 417285, 2157, 43816, 455555, 535306, 30504, 93353, 530052, 473118, 91779, 283113, 226130, 97278, 567640, 532493, 45550, 156643, 430056, 410456, 441286, 279541, 885, 378284, 156076, 143572, 229849, 39551, 56344, 193348, 16958, 572678, 106235, 341681, 83172, 343524, 395801, 388056, 259690, 235836, 343218, 205105, 513283, 176446, 371677, 308531, 497599, 455352, 236914, 232684, 415238, 290843, 519522, 144784, 167486, 392228, 488673, 191013, 80057, 570169, 224807, 163562, 136355, 492362, 102707, 232563, 10977, 51598, 32285, 520910, 131273, 206411, 472375, 481404, 471991, 17436, 177934, 165518, 571718, 459467, 135673, 134886, 485895, 287545, 577182, 289222, 372819, 310072, 87144, 430875, 60347, 42070, 420916, 453584, 296224, 122606, 311909, 579893, 284296, 221017, 315001, 439715, 284991, 389566, 78843, 122927, 225532, 13659, 153568, 395633, 419096, 203488, 361268, 466125, 414795, 508101, 253386, 222991, 530854, 351810, 338624, 138492, 263463, 226592, 378454, 20059, 227686, 476215, 297698, 247917, 439522, 479448, 424721, 26690, 558854, 176901, 334767, 301563, 86755, 194471, 420281, 533206, 99810, 334483, 89670, 482275, 404805, 2261, 425702, 36844, 12576, 361238, 108253, 319935, 3934, 29596, 47740, 77460, 14439, 571893, 447314, 181303, 58350, 26465, 246968, 536947, 76731, 286182, 433980, 561366, 380913, 32887, 517687, 213035, 399205, 349837, 350002, 131431, 356248, 334399, 57150, 363666, 507235, 169996, 226417, 481573, 56127, 123480, 274687, 164637, 178028, 493286, 348216, 345027, 571804, 140658, 102644, 581615, 279887, 230008, 284698, 102356, 456394, 323709, 452122, 579158, 525322, 33114, 8690, 381639, 217614, 284445, 468124, 187144, 273198, 95843, 417779, 447342, 166563, 490125, 561009, 183675, 290248, 532058, 214200, 578093, 369751, 429011, 301061, 105264, 267434, 370711, 25393, 471087, 106757, 183648, 358525, 49269, 79144, 519688, 431727, 130699, 215245, 91921, 218424, 473974, 405249, 235784, 521540, 537506, 119445, 507015, 173830, 356498, 435081, 18575, 373315, 227765, 13546, 67310, 125936, 389109, 322211, 184384, 426329, 128476, 414034, 450488, 99182, 51738, 99039, 75456, 134882, 442323, 232489, 351823, 65736, 1000, 379842, 13923, 559543, 185890, 357978, 129492, 261097, 410510, 39951, 306700, 146457, 214224, 332845, 255483, 222455, 187271, 462629, 544565, 369771, 35963, 289516, 334309, 452084, 301718, 429598, 165257, 93437, 413552, 62025, 17379, 176778, 104572, 90108, 157124, 89556, 266206, 86220, 508602, 10363, 17178, 507975, 314177, 313182, 538364, 149406, 180383, 402433, 449996, 168619, 209613, 103548, 469652, 15338, 512564, 336658, 568439, 372317, 476704, 260266, 106048, 177893, 479099, 269196, 315450, 171050, 243867, 263594, 147725, 88432, 272364, 138979, 519491, 100283, 563653, 345361, 113051, 286708, 475732, 108244, 121153, 23230, 73702, 86483, 521141, 61268, 393093, 493566, 191471, 11122, 198510, 126592, 416269, 133567, 521052, 332318, 186296, 415990, 187236, 271728, 460147, 200667, 77595, 278463, 190140, 476810, 540280, 126216, 32901, 407960, 84270, 267191, 422836, 493613, 217948, 317024, 463522, 213547, 456015, 547886, 124975, 378453, 69356, 162415, 274708, 377113, 79651, 104669, 439994, 430377, 512776, 95155, 184978, 199055, 431848, 333772, 128699, 121591, 176799, 424521, 254016, 523807, 73946, 230819, 82715, 85195, 435299, 50828, 27696, 62808, 497344, 361147, 541123, 163611, 10707, 409630, 343706, 199395, 514797, 486104, 514586, 279774, 474078, 872, 32038, 261732, 12120, 346638, 306139, 534601, 288391, 564091, 531771, 280930, 113867, 159282, 97585, 349678, 384136, 173057, 475572, 549136, 405691, 228214, 183709, 57672, 138639, 110884, 462614, 283785, 523175, 139099, 467511, 59920, 291791, 343934, 273551, 513580, 213816, 194832, 77396, 101787, 221754, 522751, 566436, 503841, 274272, 305343, 127092, 507797, 146498, 315492, 482477, 297396, 369675, 151857, 505638, 475387, 70254, 539143, 508917, 448410, 316054, 201148, 231169, 511999, 488664, 444879, 287874, 297022, 407083, 212226, 394206, 220858, 244411, 289741, 453166, 6894, 133631, 279927, 561335, 161032, 415748, 318908, 460927, 139883, 437239, 348243, 382111, 317433, 132408, 191288, 260106, 100510, 441442, 140270, 553990, 97924, 331799, 326542, 250766, 23781, 576566, 327306, 567825, 485972, 378873, 94944, 151051, 93717, 394510, 83531, 18193, 160728, 92177, 74200, 1425, 234779, 485130, 43435, 403584, 40757, 35062, 342128, 35279, 503755, 24610, 320642, 322895, 104666, 97337, 235778, 547144, 541952, 494759, 409542, 427055, 119995, 159112, 369323, 127270, 413247, 179653, 400922, 300039, 259597, 297084, 168337, 419974, 226408, 173302, 237928, 54654, 167898, 152771, 117914, 309391, 480944, 568690, 382122, 234807, 554291, 60835, 213935, 502599, 425221, 224119, 417043, 393282, 78032, 472030, 537964, 542423, 344909, 140556, 277051, 82696, 189698, 407518, 310622, 19109, 361571, 206994, 523241, 67616, 258793, 433774, 413395, 469067, 559099, 311789, 201025, 448256, 549390, 401991, 201418, 385997, 545730, 364102, 13291, 440336, 148783, 325306, 488251, 229601, 427160, 437205, 62554, 434204, 138954, 289417, 776, 470121, 309467, 473121, 327605, 451084, 22479, 243148, 249786, 581062, 185950, 44195, 499109, 478136, 451150, 148957, 251119, 107554, 449661, 364126, 384651, 354307, 483531, 170191, 201426, 179487, 445999, 91500, 405970, 290771, 426836, 557916, 99024, 305309, 311928, 384949, 196141, 136915, 533816, 522889, 548246, 37988, 555009, 418961, 325838, 527427, 74256, 154644, 17714, 474039, 153782, 21465, 84664, 286908, 381587, 461751, 308799, 466986, 239627, 229358, 61471, 170893, 465179, 466085, 567197, 498286, 437392, 153217, 206487, 565012, 563603, 394611, 211069, 455085, 282046, 542856, 12062, 360325, 427500, 15517, 375763, 213605, 270705, 544811, 436551, 389532, 39670, 429718, 563604, 162366, 496722, 124636, 551815, 78565, 116439, 492992, 107851, 274219, 105923, 325031, 166664, 166642, 143961, 304545, 212573, 225670, 575357, 186422, 319369, 26941, 252716, 64868, 205324, 447313, 172977, 560880, 449406, 491613, 48555, 61584, 244099, 460682, 481159, 28809, 50679, 10764, 537827, 329827, 161820, 116362, 500270, 308165, 125245, 544444, 378244, 90956, 313562, 258388, 273711, 358195, 3553, 253819, 278705, 187990, 51938, 188296, 45090, 396729, 347174, 341196, 439525, 329455, 302990, 262587, 117719, 127476, 499313, 309678, 113720, 107339, 468501, 511760, 361730, 427077, 203931, 555972, 69795, 577735, 325527, 465718, 285349, 322163, 346968, 229216, 563882, 199681, 313130, 294163, 176232, 407403, 562843, 483999, 58705, 216497, 323263, 506310, 248334, 400803, 422706, 7574, 542089, 53505, 500464, 78823, 527220, 178982, 332455, 408696, 144300, 7816, 152120, 308631, 517523, 5477, 15272, 391375, 442661, 69138, 104619, 432553, 548267, 315187, 76417, 196843, 138550, 244019, 439623, 343315, 46804, 340451, 480842, 436883, 546556, 459500, 98497, 338718, 228771, 50165, 158956, 311883, 270386, 240767, 100723, 431896, 129062, 442456, 79229, 188439, 151480, 46872, 219485, 532575, 489014, 289229, 281929, 257896, 203580, 493284, 28449, 179174, 393115, 370813, 442746, 236592, 116589, 369541, 122969, 381971, 236730, 396863, 576052, 344888, 51712, 480275, 282037, 476770, 220764, 493799, 312720, 568981, 461009, 143998, 546626, 563648, 532855, 38210, 563349, 311950, 10583, 250901, 74457, 190007, 177357, 185292, 493864, 102820, 51976, 381360, 304812, 333237, 74733, 258883, 55950, 175251, 467176, 368212, 190637, 300341, 445792, 239318, 47769, 1503, 284743, 65798, 312192, 154705, 192904, 132375, 384661, 341828, 282296, 322959, 546976, 52996, 522007, 423123, 570736, 45596, 232649, 70774, 172330, 123585, 455981, 193926, 192699, 560312, 44652, 498857, 575187, 319607, 302452, 201934, 58393, 353180, 423519, 461573, 516804, 441468, 277005, 484893, 32811, 130386, 417876, 173183, 89271, 56545, 221213, 534639, 560371, 42178, 106281, 570664, 412887, 131938, 540928, 563702, 445722, 115885, 496597, 237864, 389316, 21604, 267940, 255536, 455157, 486112, 259625, 103723, 530162, 273232, 292330, 266981, 184611, 513484, 17029, 163118, 547502, 90003, 6954, 128654, 459195, 481582, 227898, 188465, 411530, 191761, 542127, 386277, 148707, 130579, 451043, 434459, 552842, 447522, 190841, 38678, 34257, 161799, 350148, 87476, 490515, 445602, 37689, 400044, 210230, 468505, 551822, 80273, 193429, 530146, 69224, 120853, 256518, 517056, 187362, 21879, 252701, 398203, 518326, 463802, 96427, 189775, 376900, 301421, 494913, 509824, 186282, 68765, 359540, 427997, 340894, 425925, 174371, 28285, 168883, 207538, 376856, 51326, 391648, 377670, 349480, 328030, 372718, 368982, 356424, 496571, 30828, 512476, 232348, 365766, 445658, 552883, 492077, 383606, 561256, 357737, 354072, 289992, 209747, 365642, 104803, 410878, 27982, 149222, 48924, 341058, 140420, 466339, 459634, 488385, 566042, 520009, 362682, 357501, 98261, 396518, 65288, 207728, 410712, 298697, 106881, 290293, 474164, 356612, 435206, 106389, 300913, 416837, 49810, 63552, 565962, 112798, 217219, 61960, 565989, 410612, 382030, 477689, 258541, 268375, 423506, 510329, 139872, 308328, 339823, 55150, 89880, 82807, 323799, 104603, 312586, 352582, 250758, 166747, 12748, 79014, 279769, 60886, 8844, 108495, 438955, 421060, 7977, 489924, 231822, 15597, 528314, 401250, 72281, 111207, 129812, 336209, 558213, 492968, 23359, 63047, 377814, 426376, 364884, 132544, 327592, 108503, 243199, 567011, 483050, 121586, 292024, 302030, 104424, 563281, 325483, 324258, 277197, 532901, 46031, 189820, 195754, 315219, 559348, 276804, 427256, 434479, 208363, 87742, 486040, 206218, 482970, 326970, 478420, 411754, 369503, 802, 456662, 525286, 330554, 530457, 375078, 500716, 411938, 257169, 173091, 418062, 91615, 489339, 302760, 489091, 383443, 268831, 23666, 6213, 560474, 380706, 304560, 312340, 175387, 184762, 136715, 553094, 479912, 214205, 495054, 167540, 543528, 424776, 162858, 255917, 232538, 13348, 545594, 303908, 420472, 76416, 531036, 98392, 142472, 516143, 42628, 369442, 523194, 213593, 151657, 495146, 134722, 184400, 478286, 217400, 252332, 519338, 352491, 377882, 64495, 197528, 222863, 313454, 229221, 20571, 4134, 230362, 162543, 7108, 215072, 223955, 269316, 1818, 391290, 479596, 132931, 153669, 434548, 556158, 157138, 407002, 439290, 493442, 559160, 186042, 516871, 443844, 359833, 188592, 71877, 419408, 125472, 428111, 145665, 551780, 581206, 532481, 398742, 279730, 528399, 54605, 430286, 497628, 248400, 63965, 498807, 475191, 97994, 316404, 467315, 261535, 203864, 371749, 549674, 344621, 356432, 382743, 357888, 124442, 93261, 57725, 474344, 264968, 357430, 369757, 167353, 88345, 371699, 6771, 273712, 545100, 66886, 526256, 240250, 344614, 522638, 537802, 435205, 428867, 146155, 485844, 508370, 311081, 577932, 409358, 474786, 187513, 67213, 342295, 102331, 37670, 243495, 190236, 389812, 456292, 553776, 491090, 169076, 139871, 374052, 319534, 205282, 79188, 577862, 460967, 183104, 181816, 52007, 300155, 283318, 335800, 49259, 278749, 505565, 419882, 550939, 502229, 333956, 401862, 366199, 155291, 267169, 566282, 455872, 146363, 67534, 408120, 250619, 132796, 47585, 11699, 198489, 9448, 30494, 367082, 96960, 309938, 283412, 320632, 221693, 82986, 25139, 252216, 348488, 406570, 470952, 50149, 506279, 271471, 172935, 447465, 397351, 33104, 161781, 288762, 313783, 466256, 24567, 480936, 364557, 257624, 450100, 10995, 1993, 149770, 240023, 292446, 117744, 271402, 122962, 289059, 488166, 371042, 406129, 327701, 541664, 575081, 458663, 144984, 540962, 74646, 7784, 22705, 187734, 546717, 294162, 492110, 477805, 160556, 462643, 554838, 505789, 243034, 58655, 265518, 66706, 336053, 386134, 173371, 210520, 458768, 144333, 237316, 402473, 261888, 201775, 135670, 223789, 515266, 107087, 141597, 309495, 206135, 480021, 472678, 187249, 133087, 130826, 537053, 551350, 558558, 500477, 373353, 375493, 494188, 299720, 324818, 221155, 502910, 196754, 91619, 232646, 234757, 280325, 184338, 417085, 15497, 60823, 344268, 81594, 416991, 286503, 562207, 556765, 433374, 182805, 229997, 297830, 539962, 409198, 291619, 330396, 17115, 49761, 268729, 241677, 356261, 275392, 88265, 119452, 205333, 5529, 327780, 186929, 197658, 231527, 388903, 573258, 231097, 106266, 130613, 107094, 400082, 336356, 457559, 142238, 416343, 5193, 242060, 479953, 409211, 127530, 223182, 362716, 321790, 463174, 152686, 126137, 183391, 444142, 273760, 170474, 287347, 179642, 382009, 75612, 383842, 154358, 463918, 449579, 186345, 527215, 283717, 468965, 262227, 405279, 528578, 216296, 248616, 482487, 402334, 19742, 300233, 7818, 216419, 484978, 147205, 25394, 550714, 453302, 464476, 11149, 382734, 259640, 163258, 336232, 17207, 394328, 244833, 393569, 136772, 8211, 31817, 363875, 488075, 366884, 18737, 498709, 551794, 575205, 361142, 118515, 546829, 94326, 306136, 209222, 221281, 112634, 474881, 224200, 88848, 29397, 389684, 527616, 151516, 500613, 344611, 252294, 1353, 185472, 259854, 15751, 57149, 127135, 155341, 492284, 389451, 365745, 478474, 172648, 399764, 425390, 396580, 151938, 232244, 411953, 580197, 491757, 114049, 320743, 167128, 453001, 292155, 521259, 88485, 81766, 376278, 22892, 127263, 464872, 562443, 242724, 206838, 60770, 129054, 380203, 367818, 54931, 550471, 554328, 470779, 32735, 407298, 463542, 455267, 544052, 384666, 43581, 54592, 256868, 230983, 92053, 35682, 368684, 61333, 49759, 232692, 180101, 468577, 44877, 386879, 229111, 139684, 492905, 579970, 242934, 407868, 293200, 433515, 549738, 466416, 2153, 50638, 5001, 207585, 256407, 426253, 249180, 35326, 398377, 48564, 336628, 553731, 73533, 164363, 468233, 125572, 170595, 295797, 262631, 335954, 347335, 305609, 546219, 180751, 191845, 507081, 129113, 407614, 415194, 228436, 350833, 286907, 482719, 532129, 386457, 463037, 110359, 383676, 215723, 279145, 261161, 545407, 490413, 171298, 443498, 486046, 282912, 506454, 448448, 365655, 464824, 165713, 222458, 180011, 334521, 182441, 161128, 492282, 514376, 572462, 236845, 385205, 515025, 135872, 125072, 118594, 406417, 531495, 391144, 210708, 568814, 472298, 6763, 474170, 407943, 180296, 181969, 343803, 361180, 151962, 262938, 364166, 350488, 298251, 51309, 400794, 308793, 561889, 280779, 3501, 52591, 458325, 83540, 213255, 29675, 36539, 430973, 109992, 395903, 204329, 331604, 121673, 312489, 521509, 549055, 464358, 180878, 32570, 334530, 376206, 515350, 50943, 460333, 312552, 436315, 24144, 509699, 489764, 308587, 208423, 553669, 36678, 270474, 62355, 25424, 269121, 351331, 132329, 486573, 335081, 398652, 320706, 125129, 292488, 22623, 119516, 269866, 498463, 64574, 459272, 292060, 40471, 480122, 97022, 525083, 84241, 361621, 186632, 446574, 210855, 488592, 365207, 110042, 346703, 185802, 529966, 144003, 50896, 1761, 400367, 463199, 392933, 350023, 527960, 142585, 574425, 449909, 128051, 286849, 373705, 548780, 499768, 293071, 101780, 222235, 509008, 157098, 275791, 270297, 115118, 198915, 192716, 90155, 344816, 130566, 137727, 256195, 193162, 219440, 580418, 577976, 231831, 14888, 4795, 316015, 119828, 357941, 312213, 1675, 39769, 503823, 172877, 310862, 427649, 383921, 20333, 477288, 420230, 451090, 12280, 57027, 108864, 405972, 294855, 125952, 400815, 437351, 251572, 194506, 153229, 482800, 25057, 481413, 113354, 546823, 290833, 372307, 189078, 575500, 463283, 562197, 194940, 127494, 61658, 304180, 452784, 330818, 426203, 84492, 132703, 326462, 245311, 328117, 374083, 95707, 463842, 332351, 10092, 551804, 402615, 166165, 410496, 357903, 500565, 365385, 570456, 395701, 372466, 125778, 24027, 530470, 370375, 328430, 562581, 451435, 75393, 345397, 94157, 105455, 348012, 173008, 262682, 507893, 227044, 167122, 154718, 479126, 504074, 180792, 490936, 445846, 197870, 332901, 445675, 287291, 525600, 504580, 347544, 255718, 528524, 90208, 240049, 537355, 434247, 542776, 117525, 268000, 6040, 49060, 159684, 500423, 463647, 146825, 328683, 459396, 119038, 494634, 378139, 41635, 396205, 180487, 421757, 370478, 149568, 377368, 200961, 243075, 367195, 562561, 269113, 259097, 64499, 201676, 121242, 427655, 191614, 304291, 500478, 509014, 90891, 434297, 474854, 501005, 38118, 350388, 19221, 473406, 161879, 65350, 148662, 255912, 41990, 175535, 297427, 577864, 287959, 162732, 4765, 380711, 7278, 516318, 60102, 22935, 292908, 209530, 565597, 57232, 345385, 266892, 345252, 197022, 360393, 515828, 429761, 569059, 160666, 294783, 563267, 568584, 335658, 580410, 568710, 414676, 134322, 85911, 425227, 116068, 370270, 408774, 357816, 462031, 223738, 457884, 563470, 506707, 27620, 51610, 182202, 60449, 42889, 322968, 546475, 302882, 363188, 498747, 228981, 316666, 251824, 175443, 64084, 177489, 450202, 445834, 30213, 452793, 481386, 565045, 350122, 491071, 241319, 537812, 228942, 65485, 482100, 408112, 84752, 281693, 21839, 155451, 32941, 517069, 453841, 571943, 478862, 320554, 433243, 186637, 22755, 283037, 562448, 244379, 545219, 322829, 344029, 542625, 359937, 566758, 369812, 565563, 101022, 357060, 335177, 471023, 556498, 25181, 308391, 76625, 57244, 82085, 116825, 110784, 393226, 430073, 258911, 171611, 329447, 223188, 203639, 161875, 18770, 397303, 330790, 144932, 368961, 369037, 210388, 32861, 203546, 222299, 414261, 521231, 547519, 355240, 504635, 239857, 445439, 38825, 319184, 336265, 568213, 163951, 217753, 409424, 376307, 567740, 216516, 551660, 191580, 576031, 404249, 572620, 561958, 491130, 534041, 283268, 526197, 350679, 244181, 574520, 122672, 199442, 391722, 190648, 210915, 356505, 375469, 468245, 112298, 133244, 325347, 376093, 195842, 454067, 305317, 94185, 383339, 253433, 288430, 12639, 510095, 128748, 160864, 5586, 12670, 508312, 537270, 14038, 73326, 25386, 106563, 156292, 249129, 338905, 512929, 25986, 32334, 22371, 530836, 437898, 295809, 424162, 212453, 287714, 242287, 363784, 259830, 262440, 492937, 351362, 376284, 267903, 484760, 3661, 210502, 376365, 570782, 572956, 466835, 293245, 571264, 462756, 183500, 109900, 477441, 245102, 237984, 137950, 290592, 307074, 110282, 395575, 211674, 338191, 28993, 124798, 443969, 428562, 502336, 297681, 25593, 409268, 1268, 227399, 546659, 303863, 571008, 186624, 572303, 283038, 230450, 568147, 246454, 401446, 432468, 161609, 329319, 398810, 174231, 387148, 364297, 209972, 270883, 379533, 245915, 114884, 155571, 347456, 263860, 346232, 85665, 377239, 47819, 132622, 222317, 338901, 298738, 273642, 170278, 20247, 325991, 102805, 34452, 356968, 15956, 98633, 196442, 378515, 535253, 84031, 190853, 410934, 236308, 362520, 463527, 295138, 438907, 245320, 416885, 187585, 34417, 553221, 344795, 300276, 189451, 25228, 193674, 27972, 265777, 441491, 372349, 455937, 182162, 471893, 543581, 115870, 189475, 520871, 166478, 136600, 195918, 428280, 248631, 355610, 280918, 581317, 512330, 243344, 120572, 284764, 157767, 268378, 156278, 170099, 529568, 575970, 241602, 570834, 292997, 240940, 474095, 32817, 203389, 204186, 222118, 509260, 239041, 90631, 187745, 235252, 452891, 387387, 253002, 198928, 364322, 343496, 147338, 117374, 82846, 276720, 46497, 333697, 11615, 275727, 241297, 323751, 14380, 368038, 477623, 458702, 114907, 133778, 311392, 520531, 78420, 224093, 97230, 330369, 271116, 440171, 166768, 514979, 413689, 53624, 313588, 310980, 200252, 235241, 9378, 357459, 533493, 227482, 214753, 226883, 118209, 529105, 377486, 308545, 454798, 6614, 290081, 496954, 99053, 3255, 549167, 132116, 335427, 31093, 30785, 74860, 527695, 361506, 365521, 288862, 18519, 560178, 119911, 350405, 425906, 157601, 138241, 383337, 449603, 275058, 359677, 512985, 170613, 239717, 326174, 432085, 48396, 82765, 471756, 220584, 79031, 513524, 274460, 274066, 278973, 320696, 485071, 71451, 342186, 202445, 133418, 522156, 274411, 394559, 64523, 62692, 359219, 512657, 556193, 156924, 164883, 470173, 302107, 133969, 246308, 138856, 207306, 565877, 161642, 117197, 247806, 245173, 304396, 567886, 85089, 233370, 554002, 465129, 45229, 438774, 523100, 224051, 61108, 505169, 431140, 536343, 147518, 58539, 418696, 181542, 146667, 3156, 297147, 455716, 44590, 129756, 163746, 335529, 543043, 459757, 94751, 284725, 266082, 105912, 568290, 460379, 484404, 233727, 419201, 366178, 264335, 384513, 176037, 167902, 126107, 250205, 259382, 578236, 311190, 477118, 558421, 172856, 524742, 530466, 84650, 526706, 19924, 365098, 528980, 16598, 67315, 416256, 179392, 257566, 127660, 575243, 449432, 461036, 7088, 165500, 508586, 468632, 13774, 509656, 335450, 581781, 56288, 499031, 457262, 574823, 50331, 299355, 209757, 464144, 402118, 496409, 538458, 396200, 242946, 460929, 289938, 303893, 399296, 125257, 164969, 145597, 135604, 225405, 455301, 505451, 231879, 429623, 222735, 431693, 37740, 327617, 124659, 415741, 489611, 86582, 234366, 322944, 154339, 553664, 111036, 437110, 351096, 31296, 462576, 266768, 5600, 105335, 436617, 404678, 267537, 297353, 398905, 2532, 319696, 338304, 182611, 395180, 514914, 472623, 267670, 442009, 9772, 56350, 182417, 7386, 272416, 534605, 179765, 433204, 245448, 213445, 224724, 163155, 255965, 1532, 377723, 354753, 351559, 165336, 293474, 384616, 552612, 333069, 431876, 404568, 284279, 511076, 547383, 482585, 528977, 421834, 464251, 343976, 126110, 276024, 507667, 467776, 405306, 212800, 491867, 535156, 451308, 309484, 417249, 390826, 190753, 154004, 462904, 263966, 353051, 199236, 265816, 18491, 227491, 91495, 283070, 516601, 296634, 298994, 451714, 292415, 407825, 170670, 377635, 192964, 450559, 422886, 407650, 167572, 39785, 177539, 245651, 378116, 213422, 52507, 68286, 179214, 393056, 80932, 92091, 482319, 435208, 515077, 289960, 357238, 471789, 576654, 95862, 491464, 281409, 254516, 224337, 452515, 404922, 340015, 273493, 211120, 53909, 499266, 446005, 150930, 60899, 130465, 470773, 375430, 484351, 541634, 233238, 559513, 412362, 70739, 210299, 78748, 565776, 175364, 441247, 402346, 25096, 527750, 109055, 558073, 370818, 227511, 491213, 263474, 288062, 200839, 469192, 328959, 325114, 12667, 249025, 214192, 42102, 145620, 229747, 567432, 571857, 88218, 553511, 528862, 190676, 170545, 269942, 269682, 109441, 1584, 289586, 79034, 140583, 26926, 499775, 153632, 523782, 285788, 53529, 42888, 72852, 153527, 276707, 184324, 127624, 522940, 460229, 364587, 212072, 192607, 52565, 525247, 424545, 416758, 4395, 490470, 296657, 354547, 262048, 519208, 270402, 250127, 549930, 112626, 285, 573391, 447200, 261036, 269932, 426297, 68933, 47571, 23126, 242678, 229948, 451879, 158660, 59598, 485480, 6012, 13201, 243989, 44260, 581357, 476119, 287667, 527784, 179898, 349152, 187055, 493334, 318455, 520659, 465430, 209829, 329080, 190307, 200421, 551820, 254368, 146489, 438304, 33368, 513041, 225757, 369310, 324614, 302536, 31735, 465549, 404839, 232088, 318138, 378099, 154431, 148620, 394677, 463690, 570756, 299553, 281687, 303713, 521956, 323496, 348481, 119365, 577584, 273420, 388927, 439773, 308193, 424135, 297562, 123633, 286660, 88040, 404484, 489305, 491216, 226984, 222825, 507037, 384850, 34760, 260925, 96001, 574702, 245764, 246963, 534664, 26564, 408830, 537241, 272136, 22396, 132587, 225184, 441553, 55072, 277584, 550349, 289659, 62353, 193717, 565607, 210394, 41488, 514540, 65455, 532530, 374727, 484029, 402519, 309452, 424975, 323571, 500826, 368456, 501023, 235857, 81394, 264441, 241326, 272049, 377946, 78426, 260261, 399560, 392818, 442822, 170955, 346905, 172617, 281759, 534270, 231088, 44068, 159311, 479155, 100238, 45070, 469828, 136334, 185599, 407574, 239773, 112378, 527029, 128658, 516038, 538236, 479732, 449312, 535523, 419379, 417608, 426795, 529762, 197004, 405195, 455448, 529939, 390246, 548524, 431568, 39480, 493905, 120584, 55528, 128148, 183049, 139077, 416451, 533145, 402765, 255165, 527528, 459809, 538067, 17959, 298904, 447088, 262487, 470924, 421923, 178469, 362434, 70229, 106330, 545007, 520077, 454404, 194716, 202001, 155051, 565469, 79588, 395343, 541773, 455597, 262895, 433915, 540502, 172083, 251140, 541291, 105249, 323202, 550797, 226662, 142324, 352618, 205514, 205401, 144706, 221502, 520324, 491470, 454661, 183246, 303305, 97988, 179265, 338625, 5992, 186938, 203294, 2923, 47010, 406997, 185157, 402096, 353518, 356169, 475365, 550084, 225946, 553339, 463618, 200152, 148999, 414133, 193884, 475484, 455219, 198805, 41633, 133233, 359135, 80949, 167067, 150224, 136633, 490171, 462728, 493772, 356125, 476514, 526728, 509403, 484296, 244592, 387098, 188906, 192670, 324715, 567898, 270677, 291551, 293858, 523957, 89078, 322574, 344100, 84674, 246883, 142971, 54164, 335328, 453040, 462371, 365095, 536038, 241668, 65074, 415882, 238013, 571598, 419601, 473821, 84362, 474293, 256775, 506004, 270908, 379332, 193743, 331317, 215778, 145020, 172396, 419653, 73153, 560911, 263425, 24243, 544306, 135890, 60363, 142620, 66771, 66817, 370486, 17899, 109976, 66841, 98018, 301376, 47121, 289343, 68078, 327769, 92124, 368335, 457848, 578792, 2149, 275749, 192871, 468925, 276284, 85376, 196185, 71711, 423798, 288584, 98716, 66561, 217060, 531707, 569030, 94871, 15746, 390301, 39484, 273617, 288685, 76261, 176847, 542073, 494863, 307598, 505942, 309173, 304365, 14473, 396338, 416330, 14831, 572408, 125806, 90062, 512648, 505573, 160772, 88250, 441543, 293300, 511398, 93965, 163290, 572900, 134856, 267933, 40036, 576955, 185473, 465585, 81738, 442463, 450399, 516173, 224222, 270122, 148739, 371552, 47801, 249550, 569972, 317999, 416534, 121744, 257865, 324927, 80022, 556000, 257370, 39477, 23751, 573008, 403122, 438876, 412286, 147415, 179112, 261318, 410487, 168593, 372260, 536073, 31749, 546826, 310200, 2685, 417632, 244750, 29187, 343466, 248111, 173799, 307145, 519569, 557258, 360564, 308466, 551304, 114770, 234413, 165681, 267300, 147740, 485237, 208901, 404479, 504000, 96549, 110721, 438017, 405205, 134689, 89697, 349302, 16502, 550691, 452321, 233567, 413404, 321887, 345261, 147498, 509451, 509719, 169169, 119233, 439593, 124277, 426268, 133000, 565153, 235399, 189806, 129416, 519039, 518213, 365208, 450075, 60932, 473219, 152214, 309964, 399655, 80153, 177861, 194216, 308753, 119088, 71756, 577149, 564280, 85823, 364636, 402783, 113589, 167240, 419312, 425361, 352760, 579900, 569825, 92660, 466602, 128112, 96825, 562229, 157365, 15254, 221872, 515577, 53626, 376112, 343937, 530975, 495448, 120777, 535858, 530624, 7795, 263403, 167159, 568195, 318238, 491008, 396526, 385719, 172595, 328601, 76468, 373382, 554156, 530820, 400161, 383838, 498032, 479248, 181753, 415716, 27186, 366225, 379441, 15660, 39914, 304404, 570688, 236599, 450439, 429690, 248112, 166166, 427034, 170116, 410735, 52413, 397354, 579321, 44279, 157807, 256941, 279278, 255401, 555597, 455624, 376310, 5503, 322429, 143556, 392481, 404128, 497568, 500049, 161044, 144114, 248810, 296969, 11511, 396903, 17905, 372203, 189226, 27768, 350607, 418959, 204871, 88462, 99114, 449198, 475150, 320232, 581100, 6723, 289594, 476491, 31322, 278006, 314914, 337987, 249643, 578967, 247838, 131444, 261796, 312549, 135410, 573626, 306582, 426372, 147745, 154000, 535094, 286422, 357081, 458223, 311518, 445248, 170739, 281754, 112110, 341094, 161978, 517832, 521819, 303499, 448263, 559547, 109118, 174123, 366711, 13597, 579091, 209142, 70048, 106912, 276055, 548555, 257084, 154087, 217872, 513567, 304817, 164115, 341973, 554595, 540932, 46048, 59635, 289415, 162581, 139, 33221, 334417, 276285, 237071, 85772, 25603, 158744, 474021, 506178, 159399, 521719, 193245, 163117, 224675, 109827, 89296, 320490, 160012, 312263, 363461, 154213, 365886, 203629, 180798, 446207, 233139, 215114, 175438, 150638, 429530, 95069, 161397, 569700, 231237, 419098, 237517, 579070, 78404, 482436, 485424, 435880, 425226, 276018, 426166, 292005, 33854, 52412, 523229, 484415, 68093, 299887, 394199, 481567, 405432, 314251, 260657, 290619, 214869, 256192, 41872, 208208, 98520, 388258, 26204, 296317, 234526, 202339, 238039, 459437, 355817, 351530, 569273, 357748, 20107, 415536, 423617, 84170, 564336, 509258, 104119, 42563, 66135, 27932, 488710, 363072, 469246, 234660, 430871, 140203, 434996, 18833, 231580, 350003, 409867, 33109, 58111, 295420, 343076, 50006, 443426, 460683, 265108, 540466, 503855, 275198, 58384, 554579, 71226, 183437, 9891, 347930, 389933, 22192, 493019, 491683, 52462, 504439, 347370, 2587, 60855, 210030, 293794, 498919, 153797, 358427, 169356, 378673, 284106, 223090, 263068, 319617, 297595, 253452, 451693, 575815, 403353, 296222, 382125, 495732, 110449, 367386, 319100, 507575, 492758, 57760, 16439, 43737, 292225, 171788, 504389, 411774, 181499, 192191, 433192, 506933, 1296, 444275, 512248, 117492, 145591, 356531, 376322, 379476, 68833, 211825, 229311, 351609, 368900, 384808, 291634, 222094, 206271, 348045, 329614, 89761, 267351, 435003, 131138, 248314, 508482, 46378, 129135, 293324, 156071, 446206, 166509, 87244, 438269, 249219, 474452, 338532, 157847, 134034, 166259, 267946, 489046, 347163, 210099, 353970, 416170, 574315, 328286, 156372, 463849, 423944, 133645, 222559, 188689, 100428, 163682, 157213, 287527, 388846, 557672, 48504, 465180, 213033, 329041, 110972, 520707, 423104, 291861, 515982, 129945, 128598, 257478, 194746, 213171, 559707, 309655, 324158, 2473, 68628, 447611, 398438, 142790, 449190, 393469, 345941, 420069, 227985, 231125, 216636, 277689, 92939, 468332, 9914, 16451, 31620, 420840, 422670, 451571, 213830, 19432, 79969, 485027, 385029, 307172, 521717, 140076, 182155, 532761, 468954, 19786, 458410, 66635, 383289, 294695, 143068, 367228, 140929, 476787, 182923, 430048, 426241, 226058, 321118, 78170, 112997, 345356, 334977, 459954, 404191, 501368, 67896, 7888, 183965, 578871, 442161, 74209, 176857, 361586, 2592, 382696, 412531, 579902, 125850, 338219, 226171, 360951, 446117, 437514, 22589, 575372, 280710, 195045, 152465, 327890, 230166, 351589, 17031, 534673, 239843, 49091, 176701, 358923, 475904, 539445, 100274, 82812, 104198, 76547, 479030, 573943, 347664, 524280, 18837, 153011, 533536, 51008, 155145, 245576, 491725, 50811, 543300, 207844, 92416, 526103, 133343, 81061, 540414, 23023, 359855, 402774, 412240, 350019, 500211, 496854, 328238, 52891, 140286, 481480, 508639, 45472, 6471, 548506, 197388, 139260, 312406, 356428, 110999, 562818, 529122, 349594, 66926, 521601, 355677, 255824, 447917, 6460, 245026, 272148, 231549, 191672, 437331, 177213, 397279, 179285, 511453, 9400, 171757, 565853, 89045, 343149, 218997, 377393, 60507, 548339, 473869, 74092, 390902, 513688, 414340, 20553, 465822, 530061, 36660, 285047, 215644, 14007, 537672, 76211, 242411, 376478, 80413, 218249, 122166, 543047, 66231, 122217, 447169, 129322, 507473, 565391, 229659, 545958, 524850, 116479, 457078, 131386, 469174, 288882, 115946, 436738, 226802, 291664, 340272, 397639, 566923, 148508, 404601, 326627, 440508, 396568, 79408, 286507, 23937, 261706, 350054, 297085, 570448, 416104, 287649, 347254, 458255, 29984, 535608, 389315, 440507, 178618, 471450, 555005, 289702, 501243, 424642, 331280, 193181, 398028, 236721, 303566, 253695, 377588, 346707, 342397, 164885, 431545, 516677, 387916, 251537, 146831, 20992, 439426, 414638, 459662, 523033, 214703, 482735, 140987, 42528, 353027, 137106, 47112, 32081, 177065, 516916, 151629, 453341, 171740, 296231, 374545, 511647, 263679, 224664, 414673, 39405, 32610, 433103, 529528, 376264, 101884, 370900, 528705, 50844, 174018, 9590, 18380, 16249, 281032, 199771, 294350, 293390, 414510, 416745, 197796, 136033, 55002, 454978, 389804, 371529, 555012, 423971, 35770, 266400, 38070, 427338, 102411, 321557, 270066, 524108, 499622, 342367, 338325, 456865, 254814, 306893, 359781, 152870, 55167, 284762, 162130, 377575, 5037, 147223, 269632, 333402, 497867, 133819, 395388, 2006, 55299, 118405, 482978, 200162, 135902, 155443, 572555, 60090, 95899, 177383, 220732, 574810, 178744, 206025, 502168, 60052, 94852, 442306, 145781, 233033, 295478, 115245, 286458, 511384, 532071, 54123, 299609, 80659, 303653, 451144, 386210, 85682, 465806, 166426, 13004, 216277, 343453, 149375, 397681, 304984, 7991, 196009, 157390, 165831, 438226, 561465, 393014, 46463, 119677, 313034, 255747, 561223, 563758, 206579, 451155, 150417, 263644, 88970, 98853, 31217, 194724, 19402, 109313, 539883, 233825, 31248, 236426, 577959, 140840, 86956, 356094, 374982, 161861, 276921, 121497, 355169, 73118, 424349, 159791, 189213, 282298, 31118, 318114, 157756, 557884, 314264, 161008, 569976, 331569, 243626, 368752, 333745, 370208, 55022, 557172, 85576, 192047, 466156, 111086, 564023, 69213, 292456, 453634, 155154, 13177, 37751, 531134, 502347, 159977, 88951, 429109, 320425, 471567, 235057, 150726, 334371, 271457, 8899, 212895, 285894, 54967, 128372, 301981, 404534, 79565, 374551, 499181, 93154, 100489, 447789, 14226, 475223, 149622, 180188, 440617, 376625, 15440, 433134, 478393, 387383, 205289, 522393, 80274, 520832, 250137, 82821, 248284, 158945, 210789, 230993, 121417, 341469, 206831, 453981, 519611, 235064, 308476, 305695, 185409, 104455, 401244, 331075, 355905, 328337, 377497, 7281, 50380, 439180, 513181, 371472, 280891, 54628, 157928, 203095, 17182, 150649, 562059, 407524, 306437, 116206, 393838, 229553, 171382, 94614, 172649, 252507, 326128, 214539, 51314, 556873, 417911, 81988, 554266, 8629, 161925, 64898, 547854, 33005, 388215, 111609, 64718, 546325, 82688, 367569, 209753, 531135, 447187, 311002, 458045, 246436, 440184, 85157, 256916, 504415, 246522, 446703, 367095, 529148, 480212, 442993, 71938, 136466, 28452, 581482, 217425, 140439, 151820, 260105, 127394, 238410, 166918, 290768, 357567, 237118, 343561, 195165, 23272, 464689, 360943, 410221, 245513, 445365, 59386, 279714, 507042, 314541, 341921, 186449, 547336, 226154, 394275, 229753, 261712, 19042, 534394, 322610, 263299, 236690, 252559, 50145, 467848, 572388, 272212, 377000, 198641, 181421, 477227, 119641, 40083, 244496, 565624, 549220, 442836, 428218, 574297, 61747, 553788, 153510, 456143, 157418, 345469, 533855, 389197, 422998, 632, 477955, 128675, 402720, 179141, 353096, 13729, 391140, 157046, 384527, 478721, 33759, 98287, 158227, 407646, 220310, 512403, 168974, 552775, 394940, 15335]\n",
      "gts.keys():  dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "coco_results.keys():  dict_keys([179765, 190236, 331352, 517069, 182417, 46378, 93437, 172330, 472678, 314251, 223747, 109976, 12667, 482917, 534605, 289393, 561256, 338325, 65485, 226662, 11511, 221754, 249025, 255965, 51598, 445846, 192871, 365642, 393569, 116479, 63740, 570736, 492937, 117425, 159977, 232538, 177934, 96549, 469192, 44652, 210502, 298396, 187513, 552883, 228214])\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 2696 tokens at 46768.05 tokens per second.\n",
      "PTBTokenizer tokenized 576 tokens at 13652.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 498, 'reflen': 469, 'guess': [498, 453, 408, 363], 'correct': [227, 71, 14, 6]}\n",
      "ratio: 1.0618336886970963\n",
      "Bleu_1: 0.456\n",
      "Bleu_2: 0.267\n",
      "Bleu_3: 0.135\n",
      "Bleu_4: 0.080\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 814.4 ms\n",
      "SPICE: 0.056\n",
      "Evaluation Metrics: {'Bleu_1': 0.45582329317177545, 'Bleu_2': 0.26728730404406575, 'Bleu_3': 0.13483671952061507, 'Bleu_4': 0.07978427257672112, 'METEOR': 0.13071145719065927, 'ROUGE_L': 0.34994471888266043, 'CIDEr': 0.2622720325163794, 'SPICE': 0.05623738523704123}\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Image path: ./coco/val2017/000000179765.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "Image path: ./coco/val2017/000000190236.jpg\n",
      "Generated Caption: a large black cat sits inside of an empty bathtub .\n",
      "Image path: ./coco/val2017/000000331352.jpg\n",
      "Generated Caption: a toilet with a hello kitty seat sitting in a room .\n",
      "Image path: ./coco/val2017/000000517069.jpg\n",
      "Generated Caption: a man is riding a bike down a road .\n",
      "Image path: ./coco/val2017/000000182417.jpg\n",
      "Generated Caption: a computer desk with a triple monitor computer setup .\n",
      "Image path: ./coco/val2017/000000046378.jpg\n",
      "Generated Caption: a dog standing up near a car parked in the street .\n",
      "Image path: ./coco/val2017/000000093437.jpg\n",
      "Generated Caption: a woman in a red flowered shawl sits at a table while a man wearing jeans is in the kitchen looking at her .\n",
      "Image path: ./coco/val2017/000000172330.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "Image path: ./coco/val2017/000000472678.jpg\n",
      "Generated Caption: a computer desk with a computer monitor , a keyboard and a cup of coffee .\n",
      "Image path: ./coco/val2017/000000314251.jpg\n",
      "Generated Caption: a man is riding a motorcycle on a race tracks .\n",
      "Image path: ./coco/val2017/000000223747.jpg\n",
      "Generated Caption: a dog with a helmet and sunglasses in the sidecar of a motorcycle .\n",
      "Image path: ./coco/val2017/000000109976.jpg\n",
      "Generated Caption: a kitchen with a refrigerator a sink and a stove\n",
      "Image path: ./coco/val2017/000000012667.jpg\n",
      "Generated Caption: a cat laying in a purse with a funny saying .\n",
      "Image path: ./coco/val2017/000000482917.jpg\n",
      "Generated Caption: a man standing in a large mixing of food\n",
      "Image path: ./coco/val2017/000000534605.jpg\n",
      "Generated Caption: a man is riding a motorcycle on a race tracks .\n",
      "Image path: ./coco/val2017/000000289393.jpg\n",
      "Generated Caption: a dog standing up near a car looking ahead .\n",
      "Image path: ./coco/val2017/000000561256.jpg\n",
      "Generated Caption: a man is cleaning a toilet in a bathroom .\n",
      "Image path: ./coco/val2017/000000338325.jpg\n",
      "Generated Caption: a large passenger jet flying off of a runway next to a hotel .\n",
      "Image path: ./coco/val2017/000000065485.jpg\n",
      "Generated Caption: a red car parked in front of a parking meter .\n",
      "Image path: ./coco/val2017/000000226662.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "Image path: ./coco/val2017/000000011511.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "Image path: ./coco/val2017/000000221754.jpg\n",
      "Generated Caption: a car that appears to have hit a trolley\n",
      "Image path: ./coco/val2017/000000249025.jpg\n",
      "Generated Caption: a black and white cat curls up in a large mixing bowl .\n",
      "Image path: ./coco/val2017/000000255965.jpg\n",
      "Generated Caption: a cat laying in a purse with a funny saying .\n",
      "Image path: ./coco/val2017/000000051598.jpg\n",
      "Generated Caption: a bathroom with a large mirror a sink and a bath tub\n",
      "Image path: ./coco/val2017/000000445846.jpg\n",
      "Generated Caption: a kitchen with a refrigerator a sink and a stove\n",
      "Image path: ./coco/val2017/000000192871.jpg\n",
      "Generated Caption: a cat laying in a purse with a funny saying .\n",
      "Image path: ./coco/val2017/000000365642.jpg\n",
      "Generated Caption: a man is riding a bike down a road .\n",
      "Image path: ./coco/val2017/000000393569.jpg\n",
      "Generated Caption: a bathroom with a sink and a toilet .\n",
      "Image path: ./coco/val2017/000000116479.jpg\n",
      "Generated Caption: a bathroom with a sink and a toilet .\n",
      "Image path: ./coco/val2017/000000063740.jpg\n",
      "Generated Caption: a kitchen with a refrigerator a sink and a stove\n",
      "Image path: ./coco/val2017/000000570736.jpg\n",
      "Generated Caption: a bathroom with a sink and a toilet .\n",
      "Image path: ./coco/val2017/000000492937.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12412/2048777166.py:87: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(8, 8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path: ./coco/val2017/000000117425.jpg\n",
      "Generated Caption: a man with a knife and sharpener instructing a group of women .\n",
      "Image path: ./coco/val2017/000000159977.jpg\n",
      "Generated Caption: a giraffe standing on a dirt floor with rocks and trees in the background\n",
      "Image path: ./coco/val2017/000000232538.jpg\n",
      "Generated Caption: a large boat full of men is sitting on a cart\n",
      "Image path: ./coco/val2017/000000177934.jpg\n",
      "Generated Caption: a motorcycle parked in a parking lot with a helmet on the seat .\n",
      "Image path: ./coco/val2017/000000096549.jpg\n",
      "Generated Caption: a large jetliner flying over a traffic filled street .\n",
      "Image path: ./coco/val2017/000000469192.jpg\n",
      "Generated Caption: a large group of sheep are grazing in a field .\n",
      "Image path: ./coco/val2017/000000044652.jpg\n",
      "Generated Caption: a large jetliner flying over a traffic filled street .\n",
      "Image path: ./coco/val2017/000000210502.jpg\n",
      "Generated Caption: a large boat full of men is sitting on a cart\n",
      "Image path: ./coco/val2017/000000298396.jpg\n",
      "Generated Caption: a kitchen with a refrigerator a sink and a stove\n",
      "Image path: ./coco/val2017/000000187513.jpg\n",
      "Generated Caption: a bathroom with a large mirror a sink and a bath tub\n",
      "Image path: ./coco/val2017/000000552883.jpg\n",
      "Generated Caption: a bathroom with a large mirror a sink and a bath tub\n",
      "Image path: ./coco/val2017/000000228214.jpg\n",
      "Generated Caption: a man is sitting in a car holding a dog and reading a book .\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def evaluate_captioning_model(generated_captions, coco_annotation_file=val_annotations_path, coco_image_dir=val_images_path):\n",
    "    \"\"\"\n",
    "    Evaluate the image captioning model using COCO evaluation metrics: BLEU, METEOR, ROUGE, CIDEr.\n",
    "\n",
    "    Parameters:\n",
    "        generated_captions (dict): Dictionary of generated captions with image_ids as keys.\n",
    "        coco_annotation_file (str): Path to COCO annotations file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing BLEU, METEOR, ROUGE, CIDEr scores.\n",
    "    \"\"\"\n",
    "    # Load the COCO dataset annotations (reference captions)\n",
    "    coco = COCO(coco_annotation_file)\n",
    "\n",
    "    # Create a dictionary for the generated captions (image_id -> caption)\n",
    "    coco_results = [{'image_id': image_id, 'caption': caption} for image_id, caption in generated_captions.items()]\n",
    "\n",
    "    # Save the generated captions in a temporary file\n",
    "    with open('generated_captions.json', 'w') as f:\n",
    "        json.dump(coco_results, f)\n",
    "\n",
    "    # Load the results into COCO's evaluation API\n",
    "    coco_results = coco.loadRes('generated_captions.json')\n",
    "    print(coco_results)\n",
    "    print(\"Generated Captions Image IDs:\", generated_captions.keys())\n",
    "    print(\"Ground Truth Image IDs:\", coco.getImgIds())\n",
    "\n",
    "    # Filter the image IDs for evaluation\n",
    "    filtered_image_ids = [image_id for image_id in generated_captions.keys()]\n",
    "\n",
    "    # Get the reference annotations for evaluation\n",
    "    gts = {}\n",
    "    for image_id in filtered_image_ids:\n",
    "        caption_ids = coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = coco.loadAnns(caption_ids)\n",
    "        gts[image_id] = [annotation['caption'] for annotation in annotations]\n",
    "\n",
    "    # Set up the evaluation\n",
    "    print(\"gts.keys(): \", gts.keys())\n",
    "    print(\"coco_results.keys(): \", generated_captions.keys())\n",
    "\n",
    "    coco_eval = COCOEvalCap(coco, coco_results)\n",
    "    coco_eval.params['image_id'] = filtered_image_ids\n",
    "    coco_eval.evaluate()\n",
    "\n",
    "    # Extract and return the metrics (BLEU, METEOR, ROUGE, CIDEr)\n",
    "    metrics = coco_eval.eval\n",
    "    return metrics\n",
    "\n",
    "def show_images_with_captions(generated_captions, coco_annotation_file, coco_image_dir):\n",
    "    \"\"\"\n",
    "    Display images with their generated captions.\n",
    "\n",
    "    Parameters:\n",
    "        generated_captions (dict): Dictionary of generated captions with image_ids as keys.\n",
    "        coco_annotation_file (str): Path to COCO annotations file.\n",
    "        coco_image_dir (str): Path to the directory containing COCO images.\n",
    "    \"\"\"\n",
    "    # Load the COCO dataset annotations\n",
    "    coco = COCO(coco_annotation_file)\n",
    "\n",
    "    for image_id, caption in generated_captions.items():\n",
    "        # Get image information from COCO\n",
    "        try:\n",
    "            image_info = coco.loadImgs(image_id)[0]\n",
    "            image_path = f\"{coco_image_dir}/{image_info['file_name']}\"\n",
    "            print(f\"Image path: {image_path}\")  # Debug: Print the image path\n",
    "        except KeyError:\n",
    "            print(f\"Image ID {image_id} not found in the dataset.\")\n",
    "            continue\n",
    "\n",
    "        # Load and display the image using PIL and matplotlib\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image file not found at {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Print the caption\n",
    "        print(f\"Generated Caption: {caption}\")\n",
    "\n",
    "        # Display the image\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Generated Caption: {caption}\", fontsize=14, wrap=True)\n",
    "        plt.show()\n",
    "\n",
    "# Generate captions for COCO validation images\n",
    "generated_captions = generate_captions_for_coco(val_loader, model, vocabulary)\n",
    "\n",
    "# Evaluate the generated captions\n",
    "metrics = evaluate_captioning_model(generated_captions)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Display images and their captions\n",
    "show_images_with_captions(generated_captions, val_annotations_path, val_images_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
